'use strict'

const require$$5 = require('fs/promises')
const require$$2$2 = require('path')
const require$$5$1 = require('module')
const require$$0 = require('url')
const require$$0$3 = require('url')
const require$$0$2 = require('fs')
const require$$4 = require('fs')
const require$$0$1 = require('events')
const require$$1$2 = require('stream')
const require$$2$1 = require('string_decoder')
const require$$1$4 = require('path')
const require$$0$4 = require('child_process')
const require$$1$5 = require('os')
const require$$1$3 = require('fs/promises')
const require$$1$6 = require('os')
const require$$1$7 = require('path/win32')
const require$$0$5 = require('module')
const require$$0$6 = require('process')

let lib$a
let hasRequiredLib$a
function requireLib$a() {
  if (hasRequiredLib$a) {
    return lib$a
  }
  hasRequiredLib$a = 1
  const INDENT = Symbol.for('indent')
  const NEWLINE = Symbol.for('newline')
  const DEFAULT_NEWLINE = '\n'
  const DEFAULT_INDENT = '  '
  const BOM = /^\uFEFF/

  // only respect indentation if we got a line break, otherwise squash it
  // things other than objects and arrays aren't indented, so ignore those
  // Important: in both of these regexps, the $1 capture group is the newline
  // or undefined, and the $2 capture group is the indent, or undefined.
  const FORMAT = /^\s*[{[]((?:\r?\n)+)([\s\t]*)/
  const EMPTY = /^(?:\{\}|\[\])((?:\r?\n)+)?$/

  // Node 20 puts single quotes around the token and a comma after it
  const UNEXPECTED_TOKEN = /^Unexpected token '?(.)'?(,)? /i
  const hexify = char => {
    const h = char.charCodeAt(0).toString(16).toUpperCase()
    return `0x${h.length % 2 ? '0' : ''}${h}`
  }

  // Remove byte order marker. This catches EF BB BF (the UTF-8 BOM)
  // because the buffer-to-string conversion in `fs.readFileSync()`
  // translates it to FEFF, the UTF-16 BOM.
  const stripBOM = txt => String(txt).replace(BOM, '')
  const makeParsedError = (msg, parsing, position = 0) => ({
    message: `${msg} while parsing ${parsing}`,
    position
  })
  const parseError = (e, txt, context = 20) => {
    let msg = e.message
    if (!txt) {
      return makeParsedError(msg, 'empty string')
    }
    const badTokenMatch = msg.match(UNEXPECTED_TOKEN)
    const badIndexMatch = msg.match(/ position\s+(\d+)/i)
    if (badTokenMatch) {
      msg = msg.replace(
        UNEXPECTED_TOKEN,
        `Unexpected token ${JSON.stringify(badTokenMatch[1])} (${hexify(badTokenMatch[1])})$2 `
      )
    }
    let errIdx
    if (badIndexMatch) {
      errIdx = +badIndexMatch[1]
    } /* istanbul ignore next - doesnt happen in Node 22 */ else if (
      msg.match(/^Unexpected end of JSON.*/i)
    ) {
      errIdx = txt.length - 1
    }
    if (errIdx == null) {
      return makeParsedError(msg, `'${txt.slice(0, context * 2)}'`)
    }
    const start = errIdx <= context ? 0 : errIdx - context
    const end = errIdx + context >= txt.length ? txt.length : errIdx + context
    const slice = `${start ? '...' : ''}${txt.slice(start, end)}${end === txt.length ? '' : '...'}`
    return makeParsedError(
      msg,
      `${txt === slice ? '' : 'near '}${JSON.stringify(slice)}`,
      errIdx
    )
  }
  class JSONParseError extends SyntaxError {
    constructor(er, txt, context, caller) {
      const metadata = parseError(er, txt, context)
      super(metadata.message)
      Object.assign(this, metadata)
      this.code = 'EJSONPARSE'
      this.systemError = er
      Error.captureStackTrace(this, caller || this.constructor)
    }
    get name() {
      return this.constructor.name
    }
    set name(n) {}
    get [Symbol.toStringTag]() {
      return this.constructor.name
    }
  }
  const parseJson = (txt, reviver) => {
    const result = JSON.parse(txt, reviver)
    if (result && typeof result === 'object') {
      // get the indentation so that we can save it back nicely
      // if the file starts with {" then we have an indent of '', ie, none
      // otherwise, pick the indentation of the next line after the first \n If the
      // pattern doesn't match, then it means no indentation. JSON.stringify ignores
      // symbols, so this is reasonably safe. if the string is '{}' or '[]', then
      // use the default 2-space indent.
      const match = txt.match(EMPTY) || txt.match(FORMAT) || [null, '', '']
      result[NEWLINE] = match[1] ?? DEFAULT_NEWLINE
      result[INDENT] = match[2] ?? DEFAULT_INDENT
    }
    return result
  }
  const parseJsonError = (raw, reviver, context) => {
    const txt = stripBOM(raw)
    try {
      return parseJson(txt, reviver)
    } catch (e) {
      if (typeof raw !== 'string' && !Buffer.isBuffer(raw)) {
        const msg =
          Array.isArray(raw) && raw.length === 0
            ? 'an empty array'
            : String(raw)
        throw Object.assign(new TypeError(`Cannot parse ${msg}`), {
          code: 'EJSONPARSE',
          systemError: e
        })
      }
      throw new JSONParseError(e, txt, context, parseJsonError)
    }
  }
  lib$a = parseJsonError
  parseJsonError.JSONParseError = JSONParseError
  parseJsonError.noExceptions = (raw, reviver) => {
    try {
      return parseJson(stripBOM(raw), reviver)
    } catch {
      // no exceptions
    }
  }
  return lib$a
}

let updateDependencies_1
let hasRequiredUpdateDependencies
function requireUpdateDependencies() {
  if (hasRequiredUpdateDependencies) {
    return updateDependencies_1
  }
  hasRequiredUpdateDependencies = 1
  const depTypes = new Set([
    'dependencies',
    'optionalDependencies',
    'devDependencies',
    'peerDependencies'
  ])

  // sort alphabetically all types of deps for a given package
  const orderDeps = content => {
    for (const type of depTypes) {
      if (content && content[type]) {
        content[type] = Object.keys(content[type])
          .sort((a, b) => a.localeCompare(b, 'en'))
          .reduce((res, key) => {
            res[key] = content[type][key]
            return res
          }, {})
      }
    }
    return content
  }
  const updateDependencies = ({ content, originalContent }) => {
    const pkg = orderDeps({
      ...content
    })

    // optionalDependencies don't need to be repeated in two places
    if (pkg.dependencies) {
      if (pkg.optionalDependencies) {
        for (const name of Object.keys(pkg.optionalDependencies)) {
          delete pkg.dependencies[name]
        }
      }
    }
    const result = {
      ...originalContent
    }

    // loop through all types of dependencies and update package json pkg
    for (const type of depTypes) {
      if (pkg[type]) {
        result[type] = pkg[type]
      }

      // prune empty type props from resulting object
      const emptyDepType =
        pkg[type] &&
        typeof pkg === 'object' &&
        Object.keys(pkg[type]).length === 0
      if (emptyDepType) {
        delete result[type]
      }
    }

    // if original package.json had dep in peerDeps AND deps, preserve that.
    const { dependencies: origProd, peerDependencies: origPeer } =
      originalContent || {}
    const { peerDependencies: newPeer } = result
    if (origProd && origPeer && newPeer) {
      // we have original prod/peer deps, and new peer deps
      // copy over any that were in both in the original
      for (const name of Object.keys(origPeer)) {
        if (origProd[name] !== undefined && newPeer[name] !== undefined) {
          result.dependencies = result.dependencies || {}
          result.dependencies[name] = newPeer[name]
        }
      }
    }
    return result
  }
  updateDependencies.knownKeys = depTypes
  updateDependencies_1 = updateDependencies
  return updateDependencies_1
}

let updateScripts_1
let hasRequiredUpdateScripts
function requireUpdateScripts() {
  if (hasRequiredUpdateScripts) {
    return updateScripts_1
  }
  hasRequiredUpdateScripts = 1
  const updateScripts = ({ content, originalContent = {} }) => {
    const newScripts = content.scripts
    if (!newScripts) {
      return originalContent
    }

    // validate scripts content being appended
    const hasInvalidScripts = () =>
      Object.entries(newScripts).some(
        ([key, value]) => typeof key !== 'string' || typeof value !== 'string'
      )
    if (hasInvalidScripts()) {
      throw Object.assign(
        new TypeError(
          'package.json scripts should be a key-value pair of strings.'
        ),
        {
          code: 'ESCRIPTSINVALID'
        }
      )
    }
    return {
      ...originalContent,
      scripts: {
        ...newScripts
      }
    }
  }
  updateScripts_1 = updateScripts
  return updateScripts_1
}

let updateWorkspaces_1
let hasRequiredUpdateWorkspaces
function requireUpdateWorkspaces() {
  if (hasRequiredUpdateWorkspaces) {
    return updateWorkspaces_1
  }
  hasRequiredUpdateWorkspaces = 1
  const updateWorkspaces = ({ content, originalContent = {} }) => {
    const newWorkspaces = content.workspaces
    if (!newWorkspaces) {
      return originalContent
    }

    // validate workspaces content being appended
    const hasInvalidWorkspaces = () =>
      newWorkspaces.some(w => !(typeof w === 'string'))
    if (!newWorkspaces.length || hasInvalidWorkspaces()) {
      throw Object.assign(
        new TypeError('workspaces should be an array of strings.'),
        {
          code: 'EWORKSPACESINVALID'
        }
      )
    }
    return {
      ...originalContent,
      workspaces: [...newWorkspaces]
    }
  }
  updateWorkspaces_1 = updateWorkspaces
  return updateWorkspaces_1
}

let debug_1
let hasRequiredDebug
function requireDebug() {
  if (hasRequiredDebug) {
    return debug_1
  }
  hasRequiredDebug = 1
  const debug =
    typeof process === 'object' &&
    process.env &&
    process.env.NODE_DEBUG &&
    /\bsemver\b/i.test(process.env.NODE_DEBUG)
      ? (...args) => console.error('SEMVER', ...args)
      : () => {}
  debug_1 = debug
  return debug_1
}

let constants
let hasRequiredConstants
function requireConstants() {
  if (hasRequiredConstants) {
    return constants
  }
  hasRequiredConstants = 1

  // Note: this is the semver.org version of the spec that it implements
  // Not necessarily the package version of this code.
  const SEMVER_SPEC_VERSION = '2.0.0'
  const MAX_LENGTH = 256
  const MAX_SAFE_INTEGER =
    Number.MAX_SAFE_INTEGER || /* istanbul ignore next */ 9007199254740991

  // Max safe segment length for coercion.
  const MAX_SAFE_COMPONENT_LENGTH = 16

  // Max safe length for a build identifier. The max length minus 6 characters for
  // the shortest version with a build 0.0.0+BUILD.
  const MAX_SAFE_BUILD_LENGTH = MAX_LENGTH - 6
  const RELEASE_TYPES = [
    'major',
    'premajor',
    'minor',
    'preminor',
    'patch',
    'prepatch',
    'prerelease'
  ]
  constants = {
    MAX_LENGTH,
    MAX_SAFE_COMPONENT_LENGTH,
    MAX_SAFE_BUILD_LENGTH,
    MAX_SAFE_INTEGER,
    RELEASE_TYPES,
    SEMVER_SPEC_VERSION,
    FLAG_INCLUDE_PRERELEASE: 0b001,
    FLAG_LOOSE: 0b010
  }
  return constants
}

const re = { exports: {} }

let hasRequiredRe
function requireRe() {
  if (hasRequiredRe) {
    return re.exports
  }
  hasRequiredRe = 1
  ;(function (module, exports) {
    const { MAX_SAFE_COMPONENT_LENGTH, MAX_SAFE_BUILD_LENGTH, MAX_LENGTH } =
      requireConstants()
    const debug = requireDebug()
    exports = module.exports = {}

    // The actual regexps go on exports.re
    const re = (exports.re = [])
    const safeRe = (exports.safeRe = [])
    const src = (exports.src = [])
    const safeSrc = (exports.safeSrc = [])
    const t = (exports.t = {})
    let R = 0
    const LETTERDASHNUMBER = '[a-zA-Z0-9-]'

    // Replace some greedy regex tokens to prevent regex dos issues. These regex are
    // used internally via the safeRe object since all inputs in this library get
    // normalized first to trim and collapse all extra whitespace. The original
    // regexes are exported for userland consumption and lower level usage. A
    // future breaking change could export the safer regex only with a note that
    // all input should have extra whitespace removed.
    const safeRegexReplacements = [
      ['\\s', 1],
      ['\\d', MAX_LENGTH],
      [LETTERDASHNUMBER, MAX_SAFE_BUILD_LENGTH]
    ]
    const makeSafeRegex = value => {
      for (const [token, max] of safeRegexReplacements) {
        value = value
          .split(`${token}*`)
          .join(`${token}{0,${max}}`)
          .split(`${token}+`)
          .join(`${token}{1,${max}}`)
      }
      return value
    }
    const createToken = (name, value, isGlobal) => {
      const safe = makeSafeRegex(value)
      const index = R++
      debug(name, index, value)
      t[name] = index
      src[index] = value
      safeSrc[index] = safe
      re[index] = new RegExp(value, isGlobal ? 'g' : undefined)
      safeRe[index] = new RegExp(safe, isGlobal ? 'g' : undefined)
    }

    // The following Regular Expressions can be used for tokenizing,
    // validating, and parsing SemVer version strings.

    // ## Numeric Identifier
    // A single `0`, or a non-zero digit followed by zero or more digits.

    createToken('NUMERICIDENTIFIER', '0|[1-9]\\d*')
    createToken('NUMERICIDENTIFIERLOOSE', '\\d+')

    // ## Non-numeric Identifier
    // Zero or more digits, followed by a letter or hyphen, and then zero or
    // more letters, digits, or hyphens.

    createToken('NONNUMERICIDENTIFIER', `\\d*[a-zA-Z-]${LETTERDASHNUMBER}*`)

    // ## Main Version
    // Three dot-separated numeric identifiers.

    createToken(
      'MAINVERSION',
      `(${src[t.NUMERICIDENTIFIER]})\\.` +
        `(${src[t.NUMERICIDENTIFIER]})\\.` +
        `(${src[t.NUMERICIDENTIFIER]})`
    )
    createToken(
      'MAINVERSIONLOOSE',
      `(${src[t.NUMERICIDENTIFIERLOOSE]})\\.` +
        `(${src[t.NUMERICIDENTIFIERLOOSE]})\\.` +
        `(${src[t.NUMERICIDENTIFIERLOOSE]})`
    )

    // ## Pre-release Version Identifier
    // A numeric identifier, or a non-numeric identifier.
    // Non-numberic identifiers include numberic identifiers but can be longer.
    // Therefore non-numberic identifiers must go first.

    createToken(
      'PRERELEASEIDENTIFIER',
      `(?:${src[t.NONNUMERICIDENTIFIER]}|${src[t.NUMERICIDENTIFIER]})`
    )
    createToken(
      'PRERELEASEIDENTIFIERLOOSE',
      `(?:${src[t.NONNUMERICIDENTIFIER]}|${src[t.NUMERICIDENTIFIERLOOSE]})`
    )

    // ## Pre-release Version
    // Hyphen, followed by one or more dot-separated pre-release version
    // identifiers.

    createToken(
      'PRERELEASE',
      `(?:-(${src[t.PRERELEASEIDENTIFIER]}(?:\\.${src[t.PRERELEASEIDENTIFIER]})*))`
    )
    createToken(
      'PRERELEASELOOSE',
      `(?:-?(${src[t.PRERELEASEIDENTIFIERLOOSE]}(?:\\.${src[t.PRERELEASEIDENTIFIERLOOSE]})*))`
    )

    // ## Build Metadata Identifier
    // Any combination of digits, letters, or hyphens.

    createToken('BUILDIDENTIFIER', `${LETTERDASHNUMBER}+`)

    // ## Build Metadata
    // Plus sign, followed by one or more period-separated build metadata
    // identifiers.

    createToken(
      'BUILD',
      `(?:\\+(${src[t.BUILDIDENTIFIER]}(?:\\.${src[t.BUILDIDENTIFIER]})*))`
    )

    // ## Full Version String
    // A main version, followed optionally by a pre-release version and
    // build metadata.

    // Note that the only major, minor, patch, and pre-release sections of
    // the version string are capturing groups.  The build metadata is not a
    // capturing group, because it should not ever be used in version
    // comparison.

    createToken(
      'FULLPLAIN',
      `v?${src[t.MAINVERSION]}${src[t.PRERELEASE]}?${src[t.BUILD]}?`
    )
    createToken('FULL', `^${src[t.FULLPLAIN]}$`)

    // like full, but allows v1.2.3 and =1.2.3, which people do sometimes.
    // also, 1.0.0alpha1 (prerelease without the hyphen) which is pretty
    // common in the npm registry.
    createToken(
      'LOOSEPLAIN',
      `[v=\\s]*${src[t.MAINVERSIONLOOSE]}${src[t.PRERELEASELOOSE]}?${src[t.BUILD]}?`
    )
    createToken('LOOSE', `^${src[t.LOOSEPLAIN]}$`)
    createToken('GTLT', '((?:<|>)?=?)')

    // Something like "2.*" or "1.2.x".
    // Note that "x.x" is a valid xRange identifer, meaning "any version"
    // Only the first item is strictly required.
    createToken(
      'XRANGEIDENTIFIERLOOSE',
      `${src[t.NUMERICIDENTIFIERLOOSE]}|x|X|\\*`
    )
    createToken('XRANGEIDENTIFIER', `${src[t.NUMERICIDENTIFIER]}|x|X|\\*`)
    createToken(
      'XRANGEPLAIN',
      `[v=\\s]*(${src[t.XRANGEIDENTIFIER]})` +
        `(?:\\.(${src[t.XRANGEIDENTIFIER]})` +
        `(?:\\.(${src[t.XRANGEIDENTIFIER]})` +
        `(?:${src[t.PRERELEASE]})?${src[t.BUILD]}?` +
        `)?)?`
    )
    createToken(
      'XRANGEPLAINLOOSE',
      `[v=\\s]*(${src[t.XRANGEIDENTIFIERLOOSE]})` +
        `(?:\\.(${src[t.XRANGEIDENTIFIERLOOSE]})` +
        `(?:\\.(${src[t.XRANGEIDENTIFIERLOOSE]})` +
        `(?:${src[t.PRERELEASELOOSE]})?${src[t.BUILD]}?` +
        `)?)?`
    )
    createToken('XRANGE', `^${src[t.GTLT]}\\s*${src[t.XRANGEPLAIN]}$`)
    createToken('XRANGELOOSE', `^${src[t.GTLT]}\\s*${src[t.XRANGEPLAINLOOSE]}$`)

    // Coercion.
    // Extract anything that could conceivably be a part of a valid semver
    createToken(
      'COERCEPLAIN',
      `${'(^|[^\\d])' + '(\\d{1,'}${MAX_SAFE_COMPONENT_LENGTH}})` +
        `(?:\\.(\\d{1,${MAX_SAFE_COMPONENT_LENGTH}}))?` +
        `(?:\\.(\\d{1,${MAX_SAFE_COMPONENT_LENGTH}}))?`
    )
    createToken('COERCE', `${src[t.COERCEPLAIN]}(?:$|[^\\d])`)
    createToken(
      'COERCEFULL',
      src[t.COERCEPLAIN] +
        `(?:${src[t.PRERELEASE]})?` +
        `(?:${src[t.BUILD]})?` +
        `(?:$|[^\\d])`
    )
    createToken('COERCERTL', src[t.COERCE], true)
    createToken('COERCERTLFULL', src[t.COERCEFULL], true)

    // Tilde ranges.
    // Meaning is "reasonably at or greater than"
    createToken('LONETILDE', '(?:~>?)')
    createToken('TILDETRIM', `(\\s*)${src[t.LONETILDE]}\\s+`, true)
    exports.tildeTrimReplace = '$1~'
    createToken('TILDE', `^${src[t.LONETILDE]}${src[t.XRANGEPLAIN]}$`)
    createToken('TILDELOOSE', `^${src[t.LONETILDE]}${src[t.XRANGEPLAINLOOSE]}$`)

    // Caret ranges.
    // Meaning is "at least and backwards compatible with"
    createToken('LONECARET', '(?:\\^)')
    createToken('CARETTRIM', `(\\s*)${src[t.LONECARET]}\\s+`, true)
    exports.caretTrimReplace = '$1^'
    createToken('CARET', `^${src[t.LONECARET]}${src[t.XRANGEPLAIN]}$`)
    createToken('CARETLOOSE', `^${src[t.LONECARET]}${src[t.XRANGEPLAINLOOSE]}$`)

    // A simple gt/lt/eq thing, or just "" to indicate "any version"
    createToken(
      'COMPARATORLOOSE',
      `^${src[t.GTLT]}\\s*(${src[t.LOOSEPLAIN]})$|^$`
    )
    createToken('COMPARATOR', `^${src[t.GTLT]}\\s*(${src[t.FULLPLAIN]})$|^$`)

    // An expression to strip any whitespace between the gtlt and the thing
    // it modifies, so that `> 1.2.3` ==> `>1.2.3`
    createToken(
      'COMPARATORTRIM',
      `(\\s*)${src[t.GTLT]}\\s*(${src[t.LOOSEPLAIN]}|${src[t.XRANGEPLAIN]})`,
      true
    )
    exports.comparatorTrimReplace = '$1$2$3'

    // Something like `1.2.3 - 1.2.4`
    // Note that these all use the loose form, because they'll be
    // checked against either the strict or loose comparator form
    // later.
    createToken(
      'HYPHENRANGE',
      `^\\s*(${src[t.XRANGEPLAIN]})` +
        `\\s+-\\s+` +
        `(${src[t.XRANGEPLAIN]})` +
        `\\s*$`
    )
    createToken(
      'HYPHENRANGELOOSE',
      `^\\s*(${src[t.XRANGEPLAINLOOSE]})` +
        `\\s+-\\s+` +
        `(${src[t.XRANGEPLAINLOOSE]})` +
        `\\s*$`
    )

    // Star ranges basically just allow anything at all.
    createToken('STAR', '(<|>)?=?\\s*\\*')
    // >=0.0.0 is like a star
    createToken('GTE0', '^\\s*>=\\s*0\\.0\\.0\\s*$')
    createToken('GTE0PRE', '^\\s*>=\\s*0\\.0\\.0-0\\s*$')
  })(re, re.exports)
  return re.exports
}

let parseOptions_1
let hasRequiredParseOptions
function requireParseOptions() {
  if (hasRequiredParseOptions) {
    return parseOptions_1
  }
  hasRequiredParseOptions = 1

  // parse out just the options we care about
  const looseOption = Object.freeze({
    loose: true
  })
  const emptyOpts = Object.freeze({})
  const parseOptions = options => {
    if (!options) {
      return emptyOpts
    }
    if (typeof options !== 'object') {
      return looseOption
    }
    return options
  }
  parseOptions_1 = parseOptions
  return parseOptions_1
}

let identifiers
let hasRequiredIdentifiers
function requireIdentifiers() {
  if (hasRequiredIdentifiers) {
    return identifiers
  }
  hasRequiredIdentifiers = 1
  const numeric = /^[0-9]+$/
  const compareIdentifiers = (a, b) => {
    const anum = numeric.test(a)
    const bnum = numeric.test(b)
    if (anum && bnum) {
      a = +a
      b = +b
    }
    return a === b ? 0 : anum && !bnum ? -1 : bnum && !anum ? 1 : a < b ? -1 : 1
  }
  const rcompareIdentifiers = (a, b) => compareIdentifiers(b, a)
  identifiers = {
    compareIdentifiers,
    rcompareIdentifiers
  }
  return identifiers
}

let semver$1
let hasRequiredSemver$1
function requireSemver$1() {
  if (hasRequiredSemver$1) {
    return semver$1
  }
  hasRequiredSemver$1 = 1
  const debug = requireDebug()
  const { MAX_LENGTH, MAX_SAFE_INTEGER } = requireConstants()
  const { safeRe: re, t } = requireRe()
  const parseOptions = requireParseOptions()
  const { compareIdentifiers } = requireIdentifiers()
  class SemVer {
    constructor(version, options) {
      options = parseOptions(options)
      if (version instanceof SemVer) {
        if (
          version.loose === !!options.loose &&
          version.includePrerelease === !!options.includePrerelease
        ) {
          return version
        } else {
          version = version.version
        }
      } else if (typeof version !== 'string') {
        throw new TypeError(
          `Invalid version. Must be a string. Got type "${typeof version}".`
        )
      }
      if (version.length > MAX_LENGTH) {
        throw new TypeError(`version is longer than ${MAX_LENGTH} characters`)
      }
      debug('SemVer', version, options)
      this.options = options
      this.loose = !!options.loose
      // this isn't actually relevant for versions, but keep it so that we
      // don't run into trouble passing this.options around.
      this.includePrerelease = !!options.includePrerelease
      const m = version.trim().match(options.loose ? re[t.LOOSE] : re[t.FULL])
      if (!m) {
        throw new TypeError(`Invalid Version: ${version}`)
      }
      this.raw = version

      // these are actually numbers
      this.major = +m[1]
      this.minor = +m[2]
      this.patch = +m[3]
      if (this.major > MAX_SAFE_INTEGER || this.major < 0) {
        throw new TypeError('Invalid major version')
      }
      if (this.minor > MAX_SAFE_INTEGER || this.minor < 0) {
        throw new TypeError('Invalid minor version')
      }
      if (this.patch > MAX_SAFE_INTEGER || this.patch < 0) {
        throw new TypeError('Invalid patch version')
      }

      // numberify any prerelease numeric ids
      if (!m[4]) {
        this.prerelease = []
      } else {
        this.prerelease = m[4].split('.').map(id => {
          if (/^[0-9]+$/.test(id)) {
            const num = +id
            if (num >= 0 && num < MAX_SAFE_INTEGER) {
              return num
            }
          }
          return id
        })
      }
      this.build = m[5] ? m[5].split('.') : []
      this.format()
    }
    format() {
      this.version = `${this.major}.${this.minor}.${this.patch}`
      if (this.prerelease.length) {
        this.version += `-${this.prerelease.join('.')}`
      }
      return this.version
    }
    toString() {
      return this.version
    }
    compare(other) {
      debug('SemVer.compare', this.version, this.options, other)
      if (!(other instanceof SemVer)) {
        if (typeof other === 'string' && other === this.version) {
          return 0
        }
        other = new SemVer(other, this.options)
      }
      if (other.version === this.version) {
        return 0
      }
      return this.compareMain(other) || this.comparePre(other)
    }
    compareMain(other) {
      if (!(other instanceof SemVer)) {
        other = new SemVer(other, this.options)
      }
      return (
        compareIdentifiers(this.major, other.major) ||
        compareIdentifiers(this.minor, other.minor) ||
        compareIdentifiers(this.patch, other.patch)
      )
    }
    comparePre(other) {
      if (!(other instanceof SemVer)) {
        other = new SemVer(other, this.options)
      }

      // NOT having a prerelease is > having one
      if (this.prerelease.length && !other.prerelease.length) {
        return -1
      } else if (!this.prerelease.length && other.prerelease.length) {
        return 1
      } else if (!this.prerelease.length && !other.prerelease.length) {
        return 0
      }
      let i = 0
      do {
        const a = this.prerelease[i]
        const b = other.prerelease[i]
        debug('prerelease compare', i, a, b)
        if (a === undefined && b === undefined) {
          return 0
        } else if (b === undefined) {
          return 1
        } else if (a === undefined) {
          return -1
        } else if (a === b) {
          continue
        } else {
          return compareIdentifiers(a, b)
        }
      } while (++i)
    }
    compareBuild(other) {
      if (!(other instanceof SemVer)) {
        other = new SemVer(other, this.options)
      }
      let i = 0
      do {
        const a = this.build[i]
        const b = other.build[i]
        debug('build compare', i, a, b)
        if (a === undefined && b === undefined) {
          return 0
        } else if (b === undefined) {
          return 1
        } else if (a === undefined) {
          return -1
        } else if (a === b) {
          continue
        } else {
          return compareIdentifiers(a, b)
        }
      } while (++i)
    }

    // preminor will bump the version up to the next minor release, and immediately
    // down to pre-release. premajor and prepatch work the same way.
    inc(release, identifier, identifierBase) {
      if (release.startsWith('pre')) {
        if (!identifier && identifierBase === false) {
          throw new Error('invalid increment argument: identifier is empty')
        }
        // Avoid an invalid semver results
        if (identifier) {
          const match = `-${identifier}`.match(
            this.options.loose ? re[t.PRERELEASELOOSE] : re[t.PRERELEASE]
          )
          if (!match || match[1] !== identifier) {
            throw new Error(`invalid identifier: ${identifier}`)
          }
        }
      }
      switch (release) {
        case 'premajor':
          this.prerelease.length = 0
          this.patch = 0
          this.minor = 0
          this.major++
          this.inc('pre', identifier, identifierBase)
          break
        case 'preminor':
          this.prerelease.length = 0
          this.patch = 0
          this.minor++
          this.inc('pre', identifier, identifierBase)
          break
        case 'prepatch':
          // If this is already a prerelease, it will bump to the next version
          // drop any prereleases that might already exist, since they are not
          // relevant at this point.
          this.prerelease.length = 0
          this.inc('patch', identifier, identifierBase)
          this.inc('pre', identifier, identifierBase)
          break
        // If the input is a non-prerelease version, this acts the same as
        // prepatch.
        case 'prerelease':
          if (this.prerelease.length === 0) {
            this.inc('patch', identifier, identifierBase)
          }
          this.inc('pre', identifier, identifierBase)
          break
        case 'release':
          if (this.prerelease.length === 0) {
            throw new Error(`version ${this.raw} is not a prerelease`)
          }
          this.prerelease.length = 0
          break
        case 'major':
          // If this is a pre-major version, bump up to the same major version.
          // Otherwise increment major.
          // 1.0.0-5 bumps to 1.0.0
          // 1.1.0 bumps to 2.0.0
          if (
            this.minor !== 0 ||
            this.patch !== 0 ||
            this.prerelease.length === 0
          ) {
            this.major++
          }
          this.minor = 0
          this.patch = 0
          this.prerelease = []
          break
        case 'minor':
          // If this is a pre-minor version, bump up to the same minor version.
          // Otherwise increment minor.
          // 1.2.0-5 bumps to 1.2.0
          // 1.2.1 bumps to 1.3.0
          if (this.patch !== 0 || this.prerelease.length === 0) {
            this.minor++
          }
          this.patch = 0
          this.prerelease = []
          break
        case 'patch':
          // If this is not a pre-release version, it will increment the patch.
          // If it is a pre-release it will bump up to the same patch version.
          // 1.2.0-5 patches to 1.2.0
          // 1.2.0 patches to 1.2.1
          if (this.prerelease.length === 0) {
            this.patch++
          }
          this.prerelease = []
          break
        // This probably shouldn't be used publicly.
        // 1.0.0 'pre' would become 1.0.0-0 which is the wrong direction.
        case 'pre': {
          const base = Number(identifierBase) ? 1 : 0
          if (this.prerelease.length === 0) {
            this.prerelease = [base]
          } else {
            let i = this.prerelease.length
            while (--i >= 0) {
              if (typeof this.prerelease[i] === 'number') {
                this.prerelease[i]++
                i = -2
              }
            }
            if (i === -1) {
              // didn't increment anything
              if (
                identifier === this.prerelease.join('.') &&
                identifierBase === false
              ) {
                throw new Error(
                  'invalid increment argument: identifier already exists'
                )
              }
              this.prerelease.push(base)
            }
          }
          if (identifier) {
            // 1.2.0-beta.1 bumps to 1.2.0-beta.2,
            // 1.2.0-beta.fooblz or 1.2.0-beta bumps to 1.2.0-beta.0
            let prerelease = [identifier, base]
            if (identifierBase === false) {
              prerelease = [identifier]
            }
            if (compareIdentifiers(this.prerelease[0], identifier) === 0) {
              if (isNaN(this.prerelease[1])) {
                this.prerelease = prerelease
              }
            } else {
              this.prerelease = prerelease
            }
          }
          break
        }
        default:
          throw new Error(`invalid increment argument: ${release}`)
      }
      this.raw = this.format()
      if (this.build.length) {
        this.raw += `+${this.build.join('.')}`
      }
      return this
    }
  }
  semver$1 = SemVer
  return semver$1
}

let parse_1
let hasRequiredParse$2
function requireParse$2() {
  if (hasRequiredParse$2) {
    return parse_1
  }
  hasRequiredParse$2 = 1
  const SemVer = requireSemver$1()
  const parse = (version, options, throwErrors = false) => {
    if (version instanceof SemVer) {
      return version
    }
    try {
      return new SemVer(version, options)
    } catch (er) {
      if (!throwErrors) {
        return null
      }
      throw er
    }
  }
  parse_1 = parse
  return parse_1
}

let valid_1
let hasRequiredValid$1
function requireValid$1() {
  if (hasRequiredValid$1) {
    return valid_1
  }
  hasRequiredValid$1 = 1
  const parse = requireParse$2()
  const valid = (version, options) => {
    const v = parse(version, options)
    return v ? v.version : null
  }
  valid_1 = valid
  return valid_1
}

let clean_1
let hasRequiredClean
function requireClean() {
  if (hasRequiredClean) {
    return clean_1
  }
  hasRequiredClean = 1
  const parse = requireParse$2()
  const clean = (version, options) => {
    const s = parse(version.trim().replace(/^[=v]+/, ''), options)
    return s ? s.version : null
  }
  clean_1 = clean
  return clean_1
}

let lib$9
let hasRequiredLib$9
function requireLib$9() {
  if (hasRequiredLib$9) {
    return lib$9
  }
  hasRequiredLib$9 = 1
  const META = Symbol('proc-log.meta')
  lib$9 = {
    META: META,
    output: {
      LEVELS: ['standard', 'error', 'buffer', 'flush'],
      KEYS: {
        standard: 'standard',
        error: 'error',
        buffer: 'buffer',
        flush: 'flush'
      },
      standard: function (...args) {
        return process.emit('output', 'standard', ...args)
      },
      error: function (...args) {
        return process.emit('output', 'error', ...args)
      },
      buffer: function (...args) {
        return process.emit('output', 'buffer', ...args)
      },
      flush: function (...args) {
        return process.emit('output', 'flush', ...args)
      }
    },
    log: {
      LEVELS: [
        'notice',
        'error',
        'warn',
        'info',
        'verbose',
        'http',
        'silly',
        'timing',
        'pause',
        'resume'
      ],
      KEYS: {
        notice: 'notice',
        error: 'error',
        warn: 'warn',
        info: 'info',
        verbose: 'verbose',
        http: 'http',
        silly: 'silly',
        timing: 'timing',
        pause: 'pause',
        resume: 'resume'
      },
      error: function (...args) {
        return process.emit('log', 'error', ...args)
      },
      notice: function (...args) {
        return process.emit('log', 'notice', ...args)
      },
      warn: function (...args) {
        return process.emit('log', 'warn', ...args)
      },
      info: function (...args) {
        return process.emit('log', 'info', ...args)
      },
      verbose: function (...args) {
        return process.emit('log', 'verbose', ...args)
      },
      http: function (...args) {
        return process.emit('log', 'http', ...args)
      },
      silly: function (...args) {
        return process.emit('log', 'silly', ...args)
      },
      timing: function (...args) {
        return process.emit('log', 'timing', ...args)
      },
      pause: function () {
        return process.emit('log', 'pause')
      },
      resume: function () {
        return process.emit('log', 'resume')
      }
    },
    time: {
      LEVELS: ['start', 'end'],
      KEYS: {
        start: 'start',
        end: 'end'
      },
      start: function (name, fn) {
        process.emit('time', 'start', name)
        function end() {
          return process.emit('time', 'end', name)
        }
        if (typeof fn === 'function') {
          const res = fn()
          if (res && res.finally) {
            return res.finally(end)
          }
          end()
          return res
        }
        return end
      },
      end: function (name) {
        return process.emit('time', 'end', name)
      }
    },
    input: {
      LEVELS: ['start', 'end', 'read'],
      KEYS: {
        start: 'start',
        end: 'end',
        read: 'read'
      },
      start: function (fn) {
        process.emit('input', 'start')
        function end() {
          return process.emit('input', 'end')
        }
        if (typeof fn === 'function') {
          const res = fn()
          if (res && res.finally) {
            return res.finally(end)
          }
          end()
          return res
        }
        return end
      },
      end: function () {
        return process.emit('input', 'end')
      },
      read: function (...args) {
        let resolve, reject
        const promise = new Promise((_resolve, _reject) => {
          resolve = _resolve
          reject = _reject
        })
        process.emit('input', 'read', resolve, reject, ...args)
        return promise
      }
    }
  }
  return lib$9
}

const commonjs$4 = {}

let hasRequiredCommonjs$4
function requireCommonjs$4() {
  if (hasRequiredCommonjs$4) {
    return commonjs$4
  }
  hasRequiredCommonjs$4 = 1
  /**
   * @module LRUCache
   */
  Object.defineProperty(commonjs$4, '__esModule', {
    value: true
  })
  commonjs$4.LRUCache = void 0
  const perf =
    typeof performance === 'object' &&
    performance &&
    typeof performance.now === 'function'
      ? performance
      : Date
  const warned = new Set()
  /* c8 ignore start */
  const PROCESS = typeof process === 'object' && !!process ? process : {}
  /* c8 ignore start */
  const emitWarning = (msg, type, code, fn) => {
    typeof PROCESS.emitWarning === 'function'
      ? PROCESS.emitWarning(msg, type, code, fn)
      : console.error(`[${code}] ${type}: ${msg}`)
  }
  let AC = globalThis.AbortController
  let AS = globalThis.AbortSignal
  /* c8 ignore start */
  if (typeof AC === 'undefined') {
    //@ts-ignore
    AS = class AbortSignal {
      onabort
      _onabort = []
      reason
      aborted = false
      addEventListener(_, fn) {
        this._onabort.push(fn)
      }
    }
    //@ts-ignore
    AC = class AbortController {
      constructor() {
        warnACPolyfill()
      }
      signal = new AS()
      abort(reason) {
        if (this.signal.aborted) {
          return
        }
        //@ts-ignore
        this.signal.reason = reason
        //@ts-ignore
        this.signal.aborted = true
        //@ts-ignore
        for (const fn of this.signal._onabort) {
          fn(reason)
        }
        this.signal.onabort?.(reason)
      }
    }
    let printACPolyfillWarning =
      PROCESS.env?.LRU_CACHE_IGNORE_AC_WARNING !== '1'
    const warnACPolyfill = () => {
      if (!printACPolyfillWarning) {
        return
      }
      printACPolyfillWarning = false
      emitWarning(
        'AbortController is not defined. If using lru-cache in ' +
          'node 14, load an AbortController polyfill from the ' +
          '`node-abort-controller` package. A minimal polyfill is ' +
          'provided for use by LRUCache.fetch(), but it should not be ' +
          'relied upon in other contexts (eg, passing it to other APIs that ' +
          'use AbortController/AbortSignal might have undesirable effects). ' +
          'You may disable this with LRU_CACHE_IGNORE_AC_WARNING=1 in the env.',
        'NO_ABORT_CONTROLLER',
        'ENOTSUP',
        warnACPolyfill
      )
    }
  }
  /* c8 ignore stop */
  const shouldWarn = code => !warned.has(code)
  const isPosInt = n => n && n === Math.floor(n) && n > 0 && isFinite(n)
  /* c8 ignore start */
  // This is a little bit ridiculous, tbh.
  // The maximum array length is 2^32-1 or thereabouts on most JS impls.
  // And well before that point, you're caching the entire world, I mean,
  // that's ~32GB of just integers for the next/prev links, plus whatever
  // else to hold that many keys and values.  Just filling the memory with
  // zeroes at init time is brutal when you get that big.
  // But why not be complete?
  // Maybe in the future, these limits will have expanded.
  const getUintArray = max =>
    !isPosInt(max)
      ? null
      : max <= Math.pow(2, 8)
        ? Uint8Array
        : max <= Math.pow(2, 16)
          ? Uint16Array
          : max <= Math.pow(2, 32)
            ? Uint32Array
            : max <= Number.MAX_SAFE_INTEGER
              ? ZeroArray
              : null
  /* c8 ignore stop */
  class ZeroArray extends Array {
    constructor(size) {
      super(size)
      this.fill(0)
    }
  }
  class Stack {
    heap
    length
    // private constructor
    static #constructing = false
    static create(max) {
      const HeapCls = getUintArray(max)
      if (!HeapCls) {
        return []
      }
      Stack.#constructing = true
      const s = new Stack(max, HeapCls)
      Stack.#constructing = false
      return s
    }
    constructor(max, HeapCls) {
      /* c8 ignore start */
      if (!Stack.#constructing) {
        throw new TypeError('instantiate Stack using Stack.create(n)')
      }
      /* c8 ignore stop */
      this.heap = new HeapCls(max)
      this.length = 0
    }
    push(n) {
      this.heap[this.length++] = n
    }
    pop() {
      return this.heap[--this.length]
    }
  }
  /**
   * Default export, the thing you're using this module to get.
   *
   * The `K` and `V` types define the key and value types, respectively. The
   * optional `FC` type defines the type of the `context` object passed to
   * `cache.fetch()` and `cache.memo()`.
   *
   * Keys and values **must not** be `null` or `undefined`.
   *
   * All properties from the options object (with the exception of `max`,
   * `maxSize`, `fetchMethod`, `memoMethod`, `dispose` and `disposeAfter`) are
   * added as normal public members. (The listed options are read-only getters.)
   *
   * Changing any of these will alter the defaults for subsequent method calls.
   */
  class LRUCache {
    // options that cannot be changed without disaster
    #max
    #maxSize
    #dispose
    #disposeAfter
    #fetchMethod
    #memoMethod
    /**
     * {@link LRUCache.OptionsBase.ttl}
     */
    ttl
    /**
     * {@link LRUCache.OptionsBase.ttlResolution}
     */
    ttlResolution
    /**
     * {@link LRUCache.OptionsBase.ttlAutopurge}
     */
    ttlAutopurge
    /**
     * {@link LRUCache.OptionsBase.updateAgeOnGet}
     */
    updateAgeOnGet
    /**
     * {@link LRUCache.OptionsBase.updateAgeOnHas}
     */
    updateAgeOnHas
    /**
     * {@link LRUCache.OptionsBase.allowStale}
     */
    allowStale
    /**
     * {@link LRUCache.OptionsBase.noDisposeOnSet}
     */
    noDisposeOnSet
    /**
     * {@link LRUCache.OptionsBase.noUpdateTTL}
     */
    noUpdateTTL
    /**
     * {@link LRUCache.OptionsBase.maxEntrySize}
     */
    maxEntrySize
    /**
     * {@link LRUCache.OptionsBase.sizeCalculation}
     */
    sizeCalculation
    /**
     * {@link LRUCache.OptionsBase.noDeleteOnFetchRejection}
     */
    noDeleteOnFetchRejection
    /**
     * {@link LRUCache.OptionsBase.noDeleteOnStaleGet}
     */
    noDeleteOnStaleGet
    /**
     * {@link LRUCache.OptionsBase.allowStaleOnFetchAbort}
     */
    allowStaleOnFetchAbort
    /**
     * {@link LRUCache.OptionsBase.allowStaleOnFetchRejection}
     */
    allowStaleOnFetchRejection
    /**
     * {@link LRUCache.OptionsBase.ignoreFetchAbort}
     */
    ignoreFetchAbort
    // computed properties
    #size
    #calculatedSize
    #keyMap
    #keyList
    #valList
    #next
    #prev
    #head
    #tail
    #free
    #disposed
    #sizes
    #starts
    #ttls
    #hasDispose
    #hasFetchMethod
    #hasDisposeAfter
    /**
     * Do not call this method unless you need to inspect the
     * inner workings of the cache.  If anything returned by this
     * object is modified in any way, strange breakage may occur.
     *
     * These fields are private for a reason!
     *
     * @internal
     */
    static unsafeExposeInternals(c) {
      return {
        // properties
        starts: c.#starts,
        ttls: c.#ttls,
        sizes: c.#sizes,
        keyMap: c.#keyMap,
        keyList: c.#keyList,
        valList: c.#valList,
        next: c.#next,
        prev: c.#prev,
        get head() {
          return c.#head
        },
        get tail() {
          return c.#tail
        },
        free: c.#free,
        // methods
        isBackgroundFetch: p => c.#isBackgroundFetch(p),
        backgroundFetch: (k, index, options, context) =>
          c.#backgroundFetch(k, index, options, context),
        moveToTail: index => c.#moveToTail(index),
        indexes: options => c.#indexes(options),
        rindexes: options => c.#rindexes(options),
        isStale: index => c.#isStale(index)
      }
    }
    // Protected read-only members
    /**
     * {@link LRUCache.OptionsBase.max} (read-only)
     */
    get max() {
      return this.#max
    }
    /**
     * {@link LRUCache.OptionsBase.maxSize} (read-only)
     */
    get maxSize() {
      return this.#maxSize
    }
    /**
     * The total computed size of items in the cache (read-only)
     */
    get calculatedSize() {
      return this.#calculatedSize
    }
    /**
     * The number of items stored in the cache (read-only)
     */
    get size() {
      return this.#size
    }
    /**
     * {@link LRUCache.OptionsBase.fetchMethod} (read-only)
     */
    get fetchMethod() {
      return this.#fetchMethod
    }
    get memoMethod() {
      return this.#memoMethod
    }
    /**
     * {@link LRUCache.OptionsBase.dispose} (read-only)
     */
    get dispose() {
      return this.#dispose
    }
    /**
     * {@link LRUCache.OptionsBase.disposeAfter} (read-only)
     */
    get disposeAfter() {
      return this.#disposeAfter
    }
    constructor(options) {
      const {
        max = 0,
        ttl,
        ttlResolution = 1,
        ttlAutopurge,
        updateAgeOnGet,
        updateAgeOnHas,
        allowStale,
        dispose,
        disposeAfter,
        noDisposeOnSet,
        noUpdateTTL,
        maxSize = 0,
        maxEntrySize = 0,
        sizeCalculation,
        fetchMethod,
        memoMethod,
        noDeleteOnFetchRejection,
        noDeleteOnStaleGet,
        allowStaleOnFetchRejection,
        allowStaleOnFetchAbort,
        ignoreFetchAbort
      } = options
      if (max !== 0 && !isPosInt(max)) {
        throw new TypeError('max option must be a nonnegative integer')
      }
      const UintArray = max ? getUintArray(max) : Array
      if (!UintArray) {
        throw new Error('invalid max value: ' + max)
      }
      this.#max = max
      this.#maxSize = maxSize
      this.maxEntrySize = maxEntrySize || this.#maxSize
      this.sizeCalculation = sizeCalculation
      if (this.sizeCalculation) {
        if (!this.#maxSize && !this.maxEntrySize) {
          throw new TypeError(
            'cannot set sizeCalculation without setting maxSize or maxEntrySize'
          )
        }
        if (typeof this.sizeCalculation !== 'function') {
          throw new TypeError('sizeCalculation set to non-function')
        }
      }
      if (memoMethod !== undefined && typeof memoMethod !== 'function') {
        throw new TypeError('memoMethod must be a function if defined')
      }
      this.#memoMethod = memoMethod
      if (fetchMethod !== undefined && typeof fetchMethod !== 'function') {
        throw new TypeError('fetchMethod must be a function if specified')
      }
      this.#fetchMethod = fetchMethod
      this.#hasFetchMethod = !!fetchMethod
      this.#keyMap = new Map()
      this.#keyList = new Array(max).fill(undefined)
      this.#valList = new Array(max).fill(undefined)
      this.#next = new UintArray(max)
      this.#prev = new UintArray(max)
      this.#head = 0
      this.#tail = 0
      this.#free = Stack.create(max)
      this.#size = 0
      this.#calculatedSize = 0
      if (typeof dispose === 'function') {
        this.#dispose = dispose
      }
      if (typeof disposeAfter === 'function') {
        this.#disposeAfter = disposeAfter
        this.#disposed = []
      } else {
        this.#disposeAfter = undefined
        this.#disposed = undefined
      }
      this.#hasDispose = !!this.#dispose
      this.#hasDisposeAfter = !!this.#disposeAfter
      this.noDisposeOnSet = !!noDisposeOnSet
      this.noUpdateTTL = !!noUpdateTTL
      this.noDeleteOnFetchRejection = !!noDeleteOnFetchRejection
      this.allowStaleOnFetchRejection = !!allowStaleOnFetchRejection
      this.allowStaleOnFetchAbort = !!allowStaleOnFetchAbort
      this.ignoreFetchAbort = !!ignoreFetchAbort
      // NB: maxEntrySize is set to maxSize if it's set
      if (this.maxEntrySize !== 0) {
        if (this.#maxSize !== 0) {
          if (!isPosInt(this.#maxSize)) {
            throw new TypeError(
              'maxSize must be a positive integer if specified'
            )
          }
        }
        if (!isPosInt(this.maxEntrySize)) {
          throw new TypeError(
            'maxEntrySize must be a positive integer if specified'
          )
        }
        this.#initializeSizeTracking()
      }
      this.allowStale = !!allowStale
      this.noDeleteOnStaleGet = !!noDeleteOnStaleGet
      this.updateAgeOnGet = !!updateAgeOnGet
      this.updateAgeOnHas = !!updateAgeOnHas
      this.ttlResolution =
        isPosInt(ttlResolution) || ttlResolution === 0 ? ttlResolution : 1
      this.ttlAutopurge = !!ttlAutopurge
      this.ttl = ttl || 0
      if (this.ttl) {
        if (!isPosInt(this.ttl)) {
          throw new TypeError('ttl must be a positive integer if specified')
        }
        this.#initializeTTLTracking()
      }
      // do not allow completely unbounded caches
      if (this.#max === 0 && this.ttl === 0 && this.#maxSize === 0) {
        throw new TypeError('At least one of max, maxSize, or ttl is required')
      }
      if (!this.ttlAutopurge && !this.#max && !this.#maxSize) {
        const code = 'LRU_CACHE_UNBOUNDED'
        if (shouldWarn(code)) {
          warned.add(code)
          const msg =
            'TTL caching without ttlAutopurge, max, or maxSize can ' +
            'result in unbounded memory consumption.'
          emitWarning(msg, 'UnboundedCacheWarning', code, LRUCache)
        }
      }
    }
    /**
     * Return the number of ms left in the item's TTL. If item is not in cache,
     * returns `0`. Returns `Infinity` if item is in cache without a defined TTL.
     */
    getRemainingTTL(key) {
      return this.#keyMap.has(key) ? Infinity : 0
    }
    #initializeTTLTracking() {
      const ttls = new ZeroArray(this.#max)
      const starts = new ZeroArray(this.#max)
      this.#ttls = ttls
      this.#starts = starts
      this.#setItemTTL = (index, ttl, start = perf.now()) => {
        starts[index] = ttl !== 0 ? start : 0
        ttls[index] = ttl
        if (ttl !== 0 && this.ttlAutopurge) {
          const t = setTimeout(() => {
            if (this.#isStale(index)) {
              this.#delete(this.#keyList[index], 'expire')
            }
          }, ttl + 1)
          // unref() not supported on all platforms
          /* c8 ignore start */
          if (t.unref) {
            t.unref()
          }
          /* c8 ignore stop */
        }
      }
      this.#updateItemAge = index => {
        starts[index] = ttls[index] !== 0 ? perf.now() : 0
      }
      this.#statusTTL = (status, index) => {
        if (ttls[index]) {
          const ttl = ttls[index]
          const start = starts[index]
          /* c8 ignore next */
          if (!ttl || !start) {
            return
          }
          status.ttl = ttl
          status.start = start
          status.now = cachedNow || getNow()
          const age = status.now - start
          status.remainingTTL = ttl - age
        }
      }
      // debounce calls to perf.now() to 1s so we're not hitting
      // that costly call repeatedly.
      let cachedNow = 0
      const getNow = () => {
        const n = perf.now()
        if (this.ttlResolution > 0) {
          cachedNow = n
          const t = setTimeout(() => (cachedNow = 0), this.ttlResolution)
          // not available on all platforms
          /* c8 ignore start */
          if (t.unref) {
            t.unref()
          }
          /* c8 ignore stop */
        }
        return n
      }
      this.getRemainingTTL = key => {
        const index = this.#keyMap.get(key)
        if (index === undefined) {
          return 0
        }
        const ttl = ttls[index]
        const start = starts[index]
        if (!ttl || !start) {
          return Infinity
        }
        const age = (cachedNow || getNow()) - start
        return ttl - age
      }
      this.#isStale = index => {
        const s = starts[index]
        const t = ttls[index]
        return !!t && !!s && (cachedNow || getNow()) - s > t
      }
    }
    // conditionally set private methods related to TTL
    #updateItemAge = () => {}
    #statusTTL = () => {}
    #setItemTTL = () => {}
    /* c8 ignore stop */
    #isStale = () => false
    #initializeSizeTracking() {
      const sizes = new ZeroArray(this.#max)
      this.#calculatedSize = 0
      this.#sizes = sizes
      this.#removeItemSize = index => {
        this.#calculatedSize -= sizes[index]
        sizes[index] = 0
      }
      this.#requireSize = (k, v, size, sizeCalculation) => {
        // provisionally accept background fetches.
        // actual value size will be checked when they return.
        if (this.#isBackgroundFetch(v)) {
          return 0
        }
        if (!isPosInt(size)) {
          if (sizeCalculation) {
            if (typeof sizeCalculation !== 'function') {
              throw new TypeError('sizeCalculation must be a function')
            }
            size = sizeCalculation(v, k)
            if (!isPosInt(size)) {
              throw new TypeError(
                'sizeCalculation return invalid (expect positive integer)'
              )
            }
          } else {
            throw new TypeError(
              'invalid size value (must be positive integer). ' +
                'When maxSize or maxEntrySize is used, sizeCalculation ' +
                'or size must be set.'
            )
          }
        }
        return size
      }
      this.#addItemSize = (index, size, status) => {
        sizes[index] = size
        if (this.#maxSize) {
          const maxSize = this.#maxSize - sizes[index]
          while (this.#calculatedSize > maxSize) {
            this.#evict(true)
          }
        }
        this.#calculatedSize += sizes[index]
        if (status) {
          status.entrySize = size
          status.totalCalculatedSize = this.#calculatedSize
        }
      }
    }
    #removeItemSize = _i => {}
    #addItemSize = (_i, _s, _st) => {}
    #requireSize = (_k, _v, size, sizeCalculation) => {
      if (size || sizeCalculation) {
        throw new TypeError(
          'cannot set size without setting maxSize or maxEntrySize on cache'
        )
      }
      return 0
    };
    *#indexes({ allowStale = this.allowStale } = {}) {
      if (this.#size) {
        for (let i = this.#tail; true; ) {
          if (!this.#isValidIndex(i)) {
            break
          }
          if (allowStale || !this.#isStale(i)) {
            yield i
          }
          if (i === this.#head) {
            break
          } else {
            i = this.#prev[i]
          }
        }
      }
    }
    *#rindexes({ allowStale = this.allowStale } = {}) {
      if (this.#size) {
        for (let i = this.#head; true; ) {
          if (!this.#isValidIndex(i)) {
            break
          }
          if (allowStale || !this.#isStale(i)) {
            yield i
          }
          if (i === this.#tail) {
            break
          } else {
            i = this.#next[i]
          }
        }
      }
    }
    #isValidIndex(index) {
      return (
        index !== undefined && this.#keyMap.get(this.#keyList[index]) === index
      )
    }
    /**
     * Return a generator yielding `[key, value]` pairs,
     * in order from most recently used to least recently used.
     */
    *entries() {
      for (const i of this.#indexes()) {
        if (
          this.#valList[i] !== undefined &&
          this.#keyList[i] !== undefined &&
          !this.#isBackgroundFetch(this.#valList[i])
        ) {
          yield [this.#keyList[i], this.#valList[i]]
        }
      }
    }
    /**
     * Inverse order version of {@link LRUCache.entries}
     *
     * Return a generator yielding `[key, value]` pairs,
     * in order from least recently used to most recently used.
     */
    *rentries() {
      for (const i of this.#rindexes()) {
        if (
          this.#valList[i] !== undefined &&
          this.#keyList[i] !== undefined &&
          !this.#isBackgroundFetch(this.#valList[i])
        ) {
          yield [this.#keyList[i], this.#valList[i]]
        }
      }
    }
    /**
     * Return a generator yielding the keys in the cache,
     * in order from most recently used to least recently used.
     */
    *keys() {
      for (const i of this.#indexes()) {
        const k = this.#keyList[i]
        if (k !== undefined && !this.#isBackgroundFetch(this.#valList[i])) {
          yield k
        }
      }
    }
    /**
     * Inverse order version of {@link LRUCache.keys}
     *
     * Return a generator yielding the keys in the cache,
     * in order from least recently used to most recently used.
     */
    *rkeys() {
      for (const i of this.#rindexes()) {
        const k = this.#keyList[i]
        if (k !== undefined && !this.#isBackgroundFetch(this.#valList[i])) {
          yield k
        }
      }
    }
    /**
     * Return a generator yielding the values in the cache,
     * in order from most recently used to least recently used.
     */
    *values() {
      for (const i of this.#indexes()) {
        const v = this.#valList[i]
        if (v !== undefined && !this.#isBackgroundFetch(this.#valList[i])) {
          yield this.#valList[i]
        }
      }
    }
    /**
     * Inverse order version of {@link LRUCache.values}
     *
     * Return a generator yielding the values in the cache,
     * in order from least recently used to most recently used.
     */
    *rvalues() {
      for (const i of this.#rindexes()) {
        const v = this.#valList[i]
        if (v !== undefined && !this.#isBackgroundFetch(this.#valList[i])) {
          yield this.#valList[i]
        }
      }
    }
    /**
     * Iterating over the cache itself yields the same results as
     * {@link LRUCache.entries}
     */
    [Symbol.iterator]() {
      return this.entries()
    }
    /**
     * A String value that is used in the creation of the default string
     * description of an object. Called by the built-in method
     * `Object.prototype.toString`.
     */
    [Symbol.toStringTag] = 'LRUCache'
    /**
     * Find a value for which the supplied fn method returns a truthy value,
     * similar to `Array.find()`. fn is called as `fn(value, key, cache)`.
     */
    find(fn, getOptions = {}) {
      for (const i of this.#indexes()) {
        const v = this.#valList[i]
        const value = this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v
        if (value === undefined) {
          continue
        }
        if (fn(value, this.#keyList[i], this)) {
          return this.get(this.#keyList[i], getOptions)
        }
      }
    }
    /**
     * Call the supplied function on each item in the cache, in order from most
     * recently used to least recently used.
     *
     * `fn` is called as `fn(value, key, cache)`.
     *
     * If `thisp` is provided, function will be called in the `this`-context of
     * the provided object, or the cache if no `thisp` object is provided.
     *
     * Does not update age or recenty of use, or iterate over stale values.
     */
    forEach(fn, thisp = this) {
      for (const i of this.#indexes()) {
        const v = this.#valList[i]
        const value = this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v
        if (value === undefined) {
          continue
        }
        fn.call(thisp, value, this.#keyList[i], this)
      }
    }
    /**
     * The same as {@link LRUCache.forEach} but items are iterated over in
     * reverse order.  (ie, less recently used items are iterated over first.)
     */
    rforEach(fn, thisp = this) {
      for (const i of this.#rindexes()) {
        const v = this.#valList[i]
        const value = this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v
        if (value === undefined) {
          continue
        }
        fn.call(thisp, value, this.#keyList[i], this)
      }
    }
    /**
     * Delete any stale entries. Returns true if anything was removed,
     * false otherwise.
     */
    purgeStale() {
      let deleted = false
      for (const i of this.#rindexes({
        allowStale: true
      })) {
        if (this.#isStale(i)) {
          this.#delete(this.#keyList[i], 'expire')
          deleted = true
        }
      }
      return deleted
    }
    /**
     * Get the extended info about a given entry, to get its value, size, and
     * TTL info simultaneously. Returns `undefined` if the key is not present.
     *
     * Unlike {@link LRUCache#dump}, which is designed to be portable and survive
     * serialization, the `start` value is always the current timestamp, and the
     * `ttl` is a calculated remaining time to live (negative if expired).
     *
     * Always returns stale values, if their info is found in the cache, so be
     * sure to check for expirations (ie, a negative {@link LRUCache.Entry#ttl})
     * if relevant.
     */
    info(key) {
      const i = this.#keyMap.get(key)
      if (i === undefined) {
        return undefined
      }
      const v = this.#valList[i]
      const value = this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v
      if (value === undefined) {
        return undefined
      }
      const entry = {
        value
      }
      if (this.#ttls && this.#starts) {
        const ttl = this.#ttls[i]
        const start = this.#starts[i]
        if (ttl && start) {
          const remain = ttl - (perf.now() - start)
          entry.ttl = remain
          entry.start = Date.now()
        }
      }
      if (this.#sizes) {
        entry.size = this.#sizes[i]
      }
      return entry
    }
    /**
     * Return an array of [key, {@link LRUCache.Entry}] tuples which can be
     * passed to {@link LRLUCache#load}.
     *
     * The `start` fields are calculated relative to a portable `Date.now()`
     * timestamp, even if `performance.now()` is available.
     *
     * Stale entries are always included in the `dump`, even if
     * {@link LRUCache.OptionsBase.allowStale} is false.
     *
     * Note: this returns an actual array, not a generator, so it can be more
     * easily passed around.
     */
    dump() {
      const arr = []
      for (const i of this.#indexes({
        allowStale: true
      })) {
        const key = this.#keyList[i]
        const v = this.#valList[i]
        const value = this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v
        if (value === undefined || key === undefined) {
          continue
        }
        const entry = {
          value
        }
        if (this.#ttls && this.#starts) {
          entry.ttl = this.#ttls[i]
          // always dump the start relative to a portable timestamp
          // it's ok for this to be a bit slow, it's a rare operation.
          const age = perf.now() - this.#starts[i]
          entry.start = Math.floor(Date.now() - age)
        }
        if (this.#sizes) {
          entry.size = this.#sizes[i]
        }
        arr.unshift([key, entry])
      }
      return arr
    }
    /**
     * Reset the cache and load in the items in entries in the order listed.
     *
     * The shape of the resulting cache may be different if the same options are
     * not used in both caches.
     *
     * The `start` fields are assumed to be calculated relative to a portable
     * `Date.now()` timestamp, even if `performance.now()` is available.
     */
    load(arr) {
      this.clear()
      for (const [key, entry] of arr) {
        if (entry.start) {
          // entry.start is a portable timestamp, but we may be using
          // node's performance.now(), so calculate the offset, so that
          // we get the intended remaining TTL, no matter how long it's
          // been on ice.
          //
          // it's ok for this to be a bit slow, it's a rare operation.
          const age = Date.now() - entry.start
          entry.start = perf.now() - age
        }
        this.set(key, entry.value, entry)
      }
    }
    /**
     * Add a value to the cache.
     *
     * Note: if `undefined` is specified as a value, this is an alias for
     * {@link LRUCache#delete}
     *
     * Fields on the {@link LRUCache.SetOptions} options param will override
     * their corresponding values in the constructor options for the scope
     * of this single `set()` operation.
     *
     * If `start` is provided, then that will set the effective start
     * time for the TTL calculation. Note that this must be a previous
     * value of `performance.now()` if supported, or a previous value of
     * `Date.now()` if not.
     *
     * Options object may also include `size`, which will prevent
     * calling the `sizeCalculation` function and just use the specified
     * number if it is a positive integer, and `noDisposeOnSet` which
     * will prevent calling a `dispose` function in the case of
     * overwrites.
     *
     * If the `size` (or return value of `sizeCalculation`) for a given
     * entry is greater than `maxEntrySize`, then the item will not be
     * added to the cache.
     *
     * Will update the recency of the entry.
     *
     * If the value is `undefined`, then this is an alias for
     * `cache.delete(key)`. `undefined` is never stored in the cache.
     */
    set(k, v, setOptions = {}) {
      if (v === undefined) {
        this.delete(k)
        return this
      }
      const {
        ttl = this.ttl,
        start,
        noDisposeOnSet = this.noDisposeOnSet,
        sizeCalculation = this.sizeCalculation,
        status
      } = setOptions
      let { noUpdateTTL = this.noUpdateTTL } = setOptions
      const size = this.#requireSize(
        k,
        v,
        setOptions.size || 0,
        sizeCalculation
      )
      // if the item doesn't fit, don't do anything
      // NB: maxEntrySize set to maxSize by default
      if (this.maxEntrySize && size > this.maxEntrySize) {
        if (status) {
          status.set = 'miss'
          status.maxEntrySizeExceeded = true
        }
        // have to delete, in case something is there already.
        this.#delete(k, 'set')
        return this
      }
      let index = this.#size === 0 ? undefined : this.#keyMap.get(k)
      if (index === undefined) {
        // addition
        index =
          this.#size === 0
            ? this.#tail
            : this.#free.length !== 0
              ? this.#free.pop()
              : this.#size === this.#max
                ? this.#evict(false)
                : this.#size
        this.#keyList[index] = k
        this.#valList[index] = v
        this.#keyMap.set(k, index)
        this.#next[this.#tail] = index
        this.#prev[index] = this.#tail
        this.#tail = index
        this.#size++
        this.#addItemSize(index, size, status)
        if (status) {
          status.set = 'add'
        }
        noUpdateTTL = false
      } else {
        // update
        this.#moveToTail(index)
        const oldVal = this.#valList[index]
        if (v !== oldVal) {
          if (this.#hasFetchMethod && this.#isBackgroundFetch(oldVal)) {
            oldVal.__abortController.abort(new Error('replaced'))
            const { __staleWhileFetching: s } = oldVal
            if (s !== undefined && !noDisposeOnSet) {
              if (this.#hasDispose) {
                this.#dispose?.(s, k, 'set')
              }
              if (this.#hasDisposeAfter) {
                this.#disposed?.push([s, k, 'set'])
              }
            }
          } else if (!noDisposeOnSet) {
            if (this.#hasDispose) {
              this.#dispose?.(oldVal, k, 'set')
            }
            if (this.#hasDisposeAfter) {
              this.#disposed?.push([oldVal, k, 'set'])
            }
          }
          this.#removeItemSize(index)
          this.#addItemSize(index, size, status)
          this.#valList[index] = v
          if (status) {
            status.set = 'replace'
            const oldValue =
              oldVal && this.#isBackgroundFetch(oldVal)
                ? oldVal.__staleWhileFetching
                : oldVal
            if (oldValue !== undefined) {
              status.oldValue = oldValue
            }
          }
        } else if (status) {
          status.set = 'update'
        }
      }
      if (ttl !== 0 && !this.#ttls) {
        this.#initializeTTLTracking()
      }
      if (this.#ttls) {
        if (!noUpdateTTL) {
          this.#setItemTTL(index, ttl, start)
        }
        if (status) {
          this.#statusTTL(status, index)
        }
      }
      if (!noDisposeOnSet && this.#hasDisposeAfter && this.#disposed) {
        const dt = this.#disposed
        let task
        while ((task = dt?.shift())) {
          this.#disposeAfter?.(...task)
        }
      }
      return this
    }
    /**
     * Evict the least recently used item, returning its value or
     * `undefined` if cache is empty.
     */
    pop() {
      try {
        while (this.#size) {
          const val = this.#valList[this.#head]
          this.#evict(true)
          if (this.#isBackgroundFetch(val)) {
            if (val.__staleWhileFetching) {
              return val.__staleWhileFetching
            }
          } else if (val !== undefined) {
            return val
          }
        }
      } finally {
        if (this.#hasDisposeAfter && this.#disposed) {
          const dt = this.#disposed
          let task
          while ((task = dt?.shift())) {
            this.#disposeAfter?.(...task)
          }
        }
      }
    }
    #evict(free) {
      const head = this.#head
      const k = this.#keyList[head]
      const v = this.#valList[head]
      if (this.#hasFetchMethod && this.#isBackgroundFetch(v)) {
        v.__abortController.abort(new Error('evicted'))
      } else if (this.#hasDispose || this.#hasDisposeAfter) {
        if (this.#hasDispose) {
          this.#dispose?.(v, k, 'evict')
        }
        if (this.#hasDisposeAfter) {
          this.#disposed?.push([v, k, 'evict'])
        }
      }
      this.#removeItemSize(head)
      // if we aren't about to use the index, then null these out
      if (free) {
        this.#keyList[head] = undefined
        this.#valList[head] = undefined
        this.#free.push(head)
      }
      if (this.#size === 1) {
        this.#head = this.#tail = 0
        this.#free.length = 0
      } else {
        this.#head = this.#next[head]
      }
      this.#keyMap.delete(k)
      this.#size--
      return head
    }
    /**
     * Check if a key is in the cache, without updating the recency of use.
     * Will return false if the item is stale, even though it is technically
     * in the cache.
     *
     * Check if a key is in the cache, without updating the recency of
     * use. Age is updated if {@link LRUCache.OptionsBase.updateAgeOnHas} is set
     * to `true` in either the options or the constructor.
     *
     * Will return `false` if the item is stale, even though it is technically in
     * the cache. The difference can be determined (if it matters) by using a
     * `status` argument, and inspecting the `has` field.
     *
     * Will not update item age unless
     * {@link LRUCache.OptionsBase.updateAgeOnHas} is set.
     */
    has(k, hasOptions = {}) {
      const { updateAgeOnHas = this.updateAgeOnHas, status } = hasOptions
      const index = this.#keyMap.get(k)
      if (index !== undefined) {
        const v = this.#valList[index]
        if (
          this.#isBackgroundFetch(v) &&
          v.__staleWhileFetching === undefined
        ) {
          return false
        }
        if (!this.#isStale(index)) {
          if (updateAgeOnHas) {
            this.#updateItemAge(index)
          }
          if (status) {
            status.has = 'hit'
            this.#statusTTL(status, index)
          }
          return true
        } else if (status) {
          status.has = 'stale'
          this.#statusTTL(status, index)
        }
      } else if (status) {
        status.has = 'miss'
      }
      return false
    }
    /**
     * Like {@link LRUCache#get} but doesn't update recency or delete stale
     * items.
     *
     * Returns `undefined` if the item is stale, unless
     * {@link LRUCache.OptionsBase.allowStale} is set.
     */
    peek(k, peekOptions = {}) {
      const { allowStale = this.allowStale } = peekOptions
      const index = this.#keyMap.get(k)
      if (index === undefined || (!allowStale && this.#isStale(index))) {
        return
      }
      const v = this.#valList[index]
      // either stale and allowed, or forcing a refresh of non-stale value
      return this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v
    }
    #backgroundFetch(k, index, options, context) {
      const v = index === undefined ? undefined : this.#valList[index]
      if (this.#isBackgroundFetch(v)) {
        return v
      }
      const ac = new AC()
      const { signal } = options
      // when/if our AC signals, then stop listening to theirs.
      signal?.addEventListener('abort', () => ac.abort(signal.reason), {
        signal: ac.signal
      })
      const fetchOpts = {
        signal: ac.signal,
        options,
        context
      }
      const cb = (v, updateCache = false) => {
        const { aborted } = ac.signal
        const ignoreAbort = options.ignoreFetchAbort && v !== undefined
        if (options.status) {
          if (aborted && !updateCache) {
            options.status.fetchAborted = true
            options.status.fetchError = ac.signal.reason
            if (ignoreAbort) {
              options.status.fetchAbortIgnored = true
            }
          } else {
            options.status.fetchResolved = true
          }
        }
        if (aborted && !ignoreAbort && !updateCache) {
          return fetchFail(ac.signal.reason)
        }
        // either we didn't abort, and are still here, or we did, and ignored
        const bf = p
        if (this.#valList[index] === p) {
          if (v === undefined) {
            if (bf.__staleWhileFetching) {
              this.#valList[index] = bf.__staleWhileFetching
            } else {
              this.#delete(k, 'fetch')
            }
          } else {
            if (options.status) {
              options.status.fetchUpdated = true
            }
            this.set(k, v, fetchOpts.options)
          }
        }
        return v
      }
      const eb = er => {
        if (options.status) {
          options.status.fetchRejected = true
          options.status.fetchError = er
        }
        return fetchFail(er)
      }
      const fetchFail = er => {
        const { aborted } = ac.signal
        const allowStaleAborted = aborted && options.allowStaleOnFetchAbort
        const allowStale =
          allowStaleAborted || options.allowStaleOnFetchRejection
        const noDelete = allowStale || options.noDeleteOnFetchRejection
        const bf = p
        if (this.#valList[index] === p) {
          // if we allow stale on fetch rejections, then we need to ensure that
          // the stale value is not removed from the cache when the fetch fails.
          const del = !noDelete || bf.__staleWhileFetching === undefined
          if (del) {
            this.#delete(k, 'fetch')
          } else if (!allowStaleAborted) {
            // still replace the *promise* with the stale value,
            // since we are done with the promise at this point.
            // leave it untouched if we're still waiting for an
            // aborted background fetch that hasn't yet returned.
            this.#valList[index] = bf.__staleWhileFetching
          }
        }
        if (allowStale) {
          if (options.status && bf.__staleWhileFetching !== undefined) {
            options.status.returnedStale = true
          }
          return bf.__staleWhileFetching
        } else if (bf.__returned === bf) {
          throw er
        }
      }
      const pcall = (res, rej) => {
        const fmp = this.#fetchMethod?.(k, v, fetchOpts)
        if (fmp && fmp instanceof Promise) {
          fmp.then(v => res(v === undefined ? undefined : v), rej)
        }
        // ignored, we go until we finish, regardless.
        // defer check until we are actually aborting,
        // so fetchMethod can override.
        ac.signal.addEventListener('abort', () => {
          if (!options.ignoreFetchAbort || options.allowStaleOnFetchAbort) {
            res(undefined)
            // when it eventually resolves, update the cache.
            if (options.allowStaleOnFetchAbort) {
              res = v => cb(v, true)
            }
          }
        })
      }
      if (options.status) {
        options.status.fetchDispatched = true
      }
      const p = new Promise(pcall).then(cb, eb)
      const bf = Object.assign(p, {
        __abortController: ac,
        __staleWhileFetching: v,
        __returned: undefined
      })
      if (index === undefined) {
        // internal, don't expose status.
        this.set(k, bf, {
          ...fetchOpts.options,
          status: undefined
        })
        index = this.#keyMap.get(k)
      } else {
        this.#valList[index] = bf
      }
      return bf
    }
    #isBackgroundFetch(p) {
      if (!this.#hasFetchMethod) {
        return false
      }
      const b = p
      return (
        !!b &&
        b instanceof Promise &&
        b.hasOwnProperty('__staleWhileFetching') &&
        b.__abortController instanceof AC
      )
    }
    async fetch(k, fetchOptions = {}) {
      const {
        // get options
        allowStale = this.allowStale,
        updateAgeOnGet = this.updateAgeOnGet,
        noDeleteOnStaleGet = this.noDeleteOnStaleGet,
        // set options
        ttl = this.ttl,
        noDisposeOnSet = this.noDisposeOnSet,
        size = 0,
        sizeCalculation = this.sizeCalculation,
        noUpdateTTL = this.noUpdateTTL,
        // fetch exclusive options
        noDeleteOnFetchRejection = this.noDeleteOnFetchRejection,
        allowStaleOnFetchRejection = this.allowStaleOnFetchRejection,
        ignoreFetchAbort = this.ignoreFetchAbort,
        allowStaleOnFetchAbort = this.allowStaleOnFetchAbort,
        context,
        forceRefresh = false,
        status,
        signal
      } = fetchOptions
      if (!this.#hasFetchMethod) {
        if (status) {
          status.fetch = 'get'
        }
        return this.get(k, {
          allowStale,
          updateAgeOnGet,
          noDeleteOnStaleGet,
          status
        })
      }
      const options = {
        allowStale,
        updateAgeOnGet,
        noDeleteOnStaleGet,
        ttl,
        noDisposeOnSet,
        size,
        sizeCalculation,
        noUpdateTTL,
        noDeleteOnFetchRejection,
        allowStaleOnFetchRejection,
        allowStaleOnFetchAbort,
        ignoreFetchAbort,
        status,
        signal
      }
      let index = this.#keyMap.get(k)
      if (index === undefined) {
        if (status) {
          status.fetch = 'miss'
        }
        const p = this.#backgroundFetch(k, index, options, context)
        return (p.__returned = p)
      } else {
        // in cache, maybe already fetching
        const v = this.#valList[index]
        if (this.#isBackgroundFetch(v)) {
          const stale = allowStale && v.__staleWhileFetching !== undefined
          if (status) {
            status.fetch = 'inflight'
            if (stale) {
              status.returnedStale = true
            }
          }
          return stale ? v.__staleWhileFetching : (v.__returned = v)
        }
        // if we force a refresh, that means do NOT serve the cached value,
        // unless we are already in the process of refreshing the cache.
        const isStale = this.#isStale(index)
        if (!forceRefresh && !isStale) {
          if (status) {
            status.fetch = 'hit'
          }
          this.#moveToTail(index)
          if (updateAgeOnGet) {
            this.#updateItemAge(index)
          }
          if (status) {
            this.#statusTTL(status, index)
          }
          return v
        }
        // ok, it is stale or a forced refresh, and not already fetching.
        // refresh the cache.
        const p = this.#backgroundFetch(k, index, options, context)
        const hasStale = p.__staleWhileFetching !== undefined
        const staleVal = hasStale && allowStale
        if (status) {
          status.fetch = isStale ? 'stale' : 'refresh'
          if (staleVal && isStale) {
            status.returnedStale = true
          }
        }
        return staleVal ? p.__staleWhileFetching : (p.__returned = p)
      }
    }
    async forceFetch(k, fetchOptions = {}) {
      const v = await this.fetch(k, fetchOptions)
      if (v === undefined) {
        throw new Error('fetch() returned undefined')
      }
      return v
    }
    memo(k, memoOptions = {}) {
      const memoMethod = this.#memoMethod
      if (!memoMethod) {
        throw new Error('no memoMethod provided to constructor')
      }
      const { context, forceRefresh, ...options } = memoOptions
      const v = this.get(k, options)
      if (!forceRefresh && v !== undefined) {
        return v
      }
      const vv = memoMethod(k, v, {
        options,
        context
      })
      this.set(k, vv, options)
      return vv
    }
    /**
     * Return a value from the cache. Will update the recency of the cache
     * entry found.
     *
     * If the key is not found, get() will return `undefined`.
     */
    get(k, getOptions = {}) {
      const {
        allowStale = this.allowStale,
        updateAgeOnGet = this.updateAgeOnGet,
        noDeleteOnStaleGet = this.noDeleteOnStaleGet,
        status
      } = getOptions
      const index = this.#keyMap.get(k)
      if (index !== undefined) {
        const value = this.#valList[index]
        const fetching = this.#isBackgroundFetch(value)
        if (status) {
          this.#statusTTL(status, index)
        }
        if (this.#isStale(index)) {
          if (status) {
            status.get = 'stale'
          }
          // delete only if not an in-flight background fetch
          if (!fetching) {
            if (!noDeleteOnStaleGet) {
              this.#delete(k, 'expire')
            }
            if (status && allowStale) {
              status.returnedStale = true
            }
            return allowStale ? value : undefined
          } else {
            if (
              status &&
              allowStale &&
              value.__staleWhileFetching !== undefined
            ) {
              status.returnedStale = true
            }
            return allowStale ? value.__staleWhileFetching : undefined
          }
        } else {
          if (status) {
            status.get = 'hit'
          }
          // if we're currently fetching it, we don't actually have it yet
          // it's not stale, which means this isn't a staleWhileRefetching.
          // If it's not stale, and fetching, AND has a __staleWhileFetching
          // value, then that means the user fetched with {forceRefresh:true},
          // so it's safe to return that value.
          if (fetching) {
            return value.__staleWhileFetching
          }
          this.#moveToTail(index)
          if (updateAgeOnGet) {
            this.#updateItemAge(index)
          }
          return value
        }
      } else if (status) {
        status.get = 'miss'
      }
    }
    #connect(p, n) {
      this.#prev[n] = p
      this.#next[p] = n
    }
    #moveToTail(index) {
      // if tail already, nothing to do
      // if head, move head to next[index]
      // else
      //   move next[prev[index]] to next[index] (head has no prev)
      //   move prev[next[index]] to prev[index]
      // prev[index] = tail
      // next[tail] = index
      // tail = index
      if (index !== this.#tail) {
        if (index === this.#head) {
          this.#head = this.#next[index]
        } else {
          this.#connect(this.#prev[index], this.#next[index])
        }
        this.#connect(this.#tail, index)
        this.#tail = index
      }
    }
    /**
     * Deletes a key out of the cache.
     *
     * Returns true if the key was deleted, false otherwise.
     */
    delete(k) {
      return this.#delete(k, 'delete')
    }
    #delete(k, reason) {
      let deleted = false
      if (this.#size !== 0) {
        const index = this.#keyMap.get(k)
        if (index !== undefined) {
          deleted = true
          if (this.#size === 1) {
            this.#clear(reason)
          } else {
            this.#removeItemSize(index)
            const v = this.#valList[index]
            if (this.#isBackgroundFetch(v)) {
              v.__abortController.abort(new Error('deleted'))
            } else if (this.#hasDispose || this.#hasDisposeAfter) {
              if (this.#hasDispose) {
                this.#dispose?.(v, k, reason)
              }
              if (this.#hasDisposeAfter) {
                this.#disposed?.push([v, k, reason])
              }
            }
            this.#keyMap.delete(k)
            this.#keyList[index] = undefined
            this.#valList[index] = undefined
            if (index === this.#tail) {
              this.#tail = this.#prev[index]
            } else if (index === this.#head) {
              this.#head = this.#next[index]
            } else {
              const pi = this.#prev[index]
              this.#next[pi] = this.#next[index]
              const ni = this.#next[index]
              this.#prev[ni] = this.#prev[index]
            }
            this.#size--
            this.#free.push(index)
          }
        }
      }
      if (this.#hasDisposeAfter && this.#disposed?.length) {
        const dt = this.#disposed
        let task
        while ((task = dt?.shift())) {
          this.#disposeAfter?.(...task)
        }
      }
      return deleted
    }
    /**
     * Clear the cache entirely, throwing away all values.
     */
    clear() {
      return this.#clear('delete')
    }
    #clear(reason) {
      for (const index of this.#rindexes({
        allowStale: true
      })) {
        const v = this.#valList[index]
        if (this.#isBackgroundFetch(v)) {
          v.__abortController.abort(new Error('deleted'))
        } else {
          const k = this.#keyList[index]
          if (this.#hasDispose) {
            this.#dispose?.(v, k, reason)
          }
          if (this.#hasDisposeAfter) {
            this.#disposed?.push([v, k, reason])
          }
        }
      }
      this.#keyMap.clear()
      this.#valList.fill(undefined)
      this.#keyList.fill(undefined)
      if (this.#ttls && this.#starts) {
        this.#ttls.fill(0)
        this.#starts.fill(0)
      }
      if (this.#sizes) {
        this.#sizes.fill(0)
      }
      this.#head = 0
      this.#tail = 0
      this.#free.length = 0
      this.#calculatedSize = 0
      this.#size = 0
      if (this.#hasDisposeAfter && this.#disposed) {
        const dt = this.#disposed
        let task
        while ((task = dt?.shift())) {
          this.#disposeAfter?.(...task)
        }
      }
    }
  }
  commonjs$4.LRUCache = LRUCache
  return commonjs$4
}

/* eslint-disable max-len */
let hosts_1
let hasRequiredHosts
function requireHosts() {
  if (hasRequiredHosts) {
    return hosts_1
  }
  hasRequiredHosts = 1
  const maybeJoin = (...args) => (args.every(arg => arg) ? args.join('') : '')
  const maybeEncode = arg => (arg ? encodeURIComponent(arg) : '')
  const formatHashFragment = f =>
    f
      .toLowerCase()
      .replace(/^\W+/g, '') // strip leading non-characters
      .replace(/(?<!\W)\W+$/, '') // strip trailing non-characters
      .replace(/\//g, '') // strip all slashes
      .replace(/\W+/g, '-') // replace remaining non-characters with '-'

  const defaults = {
    sshtemplate: ({ domain, user, project, committish }) =>
      `git@${domain}:${user}/${project}.git${maybeJoin('#', committish)}`,
    sshurltemplate: ({ domain, user, project, committish }) =>
      `git+ssh://git@${domain}/${user}/${project}.git${maybeJoin('#', committish)}`,
    edittemplate: ({ domain, user, project, committish, editpath, path }) =>
      `https://${domain}/${user}/${project}${maybeJoin('/', editpath, '/', maybeEncode(committish || 'HEAD'), '/', path)}`,
    browsetemplate: ({ domain, user, project, committish, treepath }) =>
      `https://${domain}/${user}/${project}${maybeJoin('/', treepath, '/', maybeEncode(committish))}`,
    browsetreetemplate: ({
      domain,
      user,
      project,
      committish,
      treepath,
      path,
      fragment,
      hashformat
    }) =>
      `https://${domain}/${user}/${project}/${treepath}/${maybeEncode(committish || 'HEAD')}/${path}${maybeJoin('#', hashformat(fragment || ''))}`,
    browseblobtemplate: ({
      domain,
      user,
      project,
      committish,
      blobpath,
      path,
      fragment,
      hashformat
    }) =>
      `https://${domain}/${user}/${project}/${blobpath}/${maybeEncode(committish || 'HEAD')}/${path}${maybeJoin('#', hashformat(fragment || ''))}`,
    docstemplate: ({ domain, user, project, treepath, committish }) =>
      `https://${domain}/${user}/${project}${maybeJoin('/', treepath, '/', maybeEncode(committish))}#readme`,
    httpstemplate: ({ auth, domain, user, project, committish }) =>
      `git+https://${maybeJoin(auth, '@')}${domain}/${user}/${project}.git${maybeJoin('#', committish)}`,
    filetemplate: ({ domain, user, project, committish, path }) =>
      `https://${domain}/${user}/${project}/raw/${maybeEncode(committish || 'HEAD')}/${path}`,
    shortcuttemplate: ({ type, user, project, committish }) =>
      `${type}:${user}/${project}${maybeJoin('#', committish)}`,
    pathtemplate: ({ user, project, committish }) =>
      `${user}/${project}${maybeJoin('#', committish)}`,
    bugstemplate: ({ domain, user, project }) =>
      `https://${domain}/${user}/${project}/issues`,
    hashformat: formatHashFragment
  }
  const hosts = {}
  hosts.github = {
    // First two are insecure and generally shouldn't be used any more, but
    // they are still supported.
    protocols: ['git:', 'http:', 'git+ssh:', 'git+https:', 'ssh:', 'https:'],
    domain: 'github.com',
    treepath: 'tree',
    blobpath: 'blob',
    editpath: 'edit',
    filetemplate: ({ auth, user, project, committish, path }) =>
      `https://${maybeJoin(auth, '@')}raw.githubusercontent.com/${user}/${project}/${maybeEncode(committish || 'HEAD')}/${path}`,
    gittemplate: ({ auth, domain, user, project, committish }) =>
      `git://${maybeJoin(auth, '@')}${domain}/${user}/${project}.git${maybeJoin('#', committish)}`,
    tarballtemplate: ({ domain, user, project, committish }) =>
      `https://codeload.${domain}/${user}/${project}/tar.gz/${maybeEncode(committish || 'HEAD')}`,
    extract: url => {
      let [, user, project, type, committish] = url.pathname.split('/', 5)
      if (type && type !== 'tree') {
        return
      }
      if (!type) {
        committish = url.hash.slice(1)
      }
      if (project && project.endsWith('.git')) {
        project = project.slice(0, -4)
      }
      if (!user || !project) {
        return
      }
      return {
        user,
        project,
        committish
      }
    }
  }
  hosts.bitbucket = {
    protocols: ['git+ssh:', 'git+https:', 'ssh:', 'https:'],
    domain: 'bitbucket.org',
    treepath: 'src',
    blobpath: 'src',
    editpath: '?mode=edit',
    edittemplate: ({
      domain,
      user,
      project,
      committish,
      treepath,
      path,
      editpath
    }) =>
      `https://${domain}/${user}/${project}${maybeJoin('/', treepath, '/', maybeEncode(committish || 'HEAD'), '/', path, editpath)}`,
    tarballtemplate: ({ domain, user, project, committish }) =>
      `https://${domain}/${user}/${project}/get/${maybeEncode(committish || 'HEAD')}.tar.gz`,
    extract: url => {
      let [, user, project, aux] = url.pathname.split('/', 4)
      if (['get'].includes(aux)) {
        return
      }
      if (project && project.endsWith('.git')) {
        project = project.slice(0, -4)
      }
      if (!user || !project) {
        return
      }
      return {
        user,
        project,
        committish: url.hash.slice(1)
      }
    }
  }
  hosts.gitlab = {
    protocols: ['git+ssh:', 'git+https:', 'ssh:', 'https:'],
    domain: 'gitlab.com',
    treepath: 'tree',
    blobpath: 'tree',
    editpath: '-/edit',
    httpstemplate: ({ auth, domain, user, project, committish }) =>
      `git+https://${maybeJoin(auth, '@')}${domain}/${user}/${project}.git${maybeJoin('#', committish)}`,
    tarballtemplate: ({ domain, user, project, committish }) =>
      `https://${domain}/${user}/${project}/repository/archive.tar.gz?ref=${maybeEncode(committish || 'HEAD')}`,
    extract: url => {
      const path = url.pathname.slice(1)
      if (path.includes('/-/') || path.includes('/archive.tar.gz')) {
        return
      }
      const segments = path.split('/')
      let project = segments.pop()
      if (project.endsWith('.git')) {
        project = project.slice(0, -4)
      }
      const user = segments.join('/')
      if (!user || !project) {
        return
      }
      return {
        user,
        project,
        committish: url.hash.slice(1)
      }
    }
  }
  hosts.gist = {
    protocols: ['git:', 'git+ssh:', 'git+https:', 'ssh:', 'https:'],
    domain: 'gist.github.com',
    editpath: 'edit',
    sshtemplate: ({ domain, project, committish }) =>
      `git@${domain}:${project}.git${maybeJoin('#', committish)}`,
    sshurltemplate: ({ domain, project, committish }) =>
      `git+ssh://git@${domain}/${project}.git${maybeJoin('#', committish)}`,
    edittemplate: ({ domain, user, project, committish, editpath }) =>
      `https://${domain}/${user}/${project}${maybeJoin('/', maybeEncode(committish))}/${editpath}`,
    browsetemplate: ({ domain, project, committish }) =>
      `https://${domain}/${project}${maybeJoin('/', maybeEncode(committish))}`,
    browsetreetemplate: ({ domain, project, committish, path, hashformat }) =>
      `https://${domain}/${project}${maybeJoin('/', maybeEncode(committish))}${maybeJoin('#', hashformat(path))}`,
    browseblobtemplate: ({ domain, project, committish, path, hashformat }) =>
      `https://${domain}/${project}${maybeJoin('/', maybeEncode(committish))}${maybeJoin('#', hashformat(path))}`,
    docstemplate: ({ domain, project, committish }) =>
      `https://${domain}/${project}${maybeJoin('/', maybeEncode(committish))}`,
    httpstemplate: ({ domain, project, committish }) =>
      `git+https://${domain}/${project}.git${maybeJoin('#', committish)}`,
    filetemplate: ({ user, project, committish, path }) =>
      `https://gist.githubusercontent.com/${user}/${project}/raw${maybeJoin('/', maybeEncode(committish))}/${path}`,
    shortcuttemplate: ({ type, project, committish }) =>
      `${type}:${project}${maybeJoin('#', committish)}`,
    pathtemplate: ({ project, committish }) =>
      `${project}${maybeJoin('#', committish)}`,
    bugstemplate: ({ domain, project }) => `https://${domain}/${project}`,
    gittemplate: ({ domain, project, committish }) =>
      `git://${domain}/${project}.git${maybeJoin('#', committish)}`,
    tarballtemplate: ({ project, committish }) =>
      `https://codeload.github.com/gist/${project}/tar.gz/${maybeEncode(committish || 'HEAD')}`,
    extract: url => {
      let [, user, project, aux] = url.pathname.split('/', 4)
      if (aux === 'raw') {
        return
      }
      if (!project) {
        if (!user) {
          return
        }
        project = user
        user = null
      }
      if (project.endsWith('.git')) {
        project = project.slice(0, -4)
      }
      return {
        user,
        project,
        committish: url.hash.slice(1)
      }
    },
    hashformat: function (fragment) {
      return fragment && 'file-' + formatHashFragment(fragment)
    }
  }
  hosts.sourcehut = {
    protocols: ['git+ssh:', 'https:'],
    domain: 'git.sr.ht',
    treepath: 'tree',
    blobpath: 'tree',
    filetemplate: ({ domain, user, project, committish, path }) =>
      `https://${domain}/${user}/${project}/blob/${maybeEncode(committish) || 'HEAD'}/${path}`,
    httpstemplate: ({ domain, user, project, committish }) =>
      `https://${domain}/${user}/${project}.git${maybeJoin('#', committish)}`,
    tarballtemplate: ({ domain, user, project, committish }) =>
      `https://${domain}/${user}/${project}/archive/${maybeEncode(committish) || 'HEAD'}.tar.gz`,
    bugstemplate: () => null,
    extract: url => {
      let [, user, project, aux] = url.pathname.split('/', 4)

      // tarball url
      if (['archive'].includes(aux)) {
        return
      }
      if (project && project.endsWith('.git')) {
        project = project.slice(0, -4)
      }
      if (!user || !project) {
        return
      }
      return {
        user,
        project,
        committish: url.hash.slice(1)
      }
    }
  }
  for (const [name, host] of Object.entries(hosts)) {
    hosts[name] = Object.assign({}, defaults, host)
  }
  hosts_1 = hosts
  return hosts_1
}

let parseUrl
let hasRequiredParseUrl
function requireParseUrl() {
  if (hasRequiredParseUrl) {
    return parseUrl
  }
  hasRequiredParseUrl = 1
  const url = require$$0
  const lastIndexOfBefore = (str, char, beforeChar) => {
    const startPosition = str.indexOf(beforeChar)
    return str.lastIndexOf(char, startPosition > -1 ? startPosition : Infinity)
  }
  const safeUrl = u => {
    try {
      return new url.URL(u)
    } catch {
      // this fn should never throw
    }
  }

  // accepts input like git:github.com:user/repo and inserts the // after the first :
  const correctProtocol = (arg, protocols) => {
    const firstColon = arg.indexOf(':')
    const proto = arg.slice(0, firstColon + 1)
    if (Object.prototype.hasOwnProperty.call(protocols, proto)) {
      return arg
    }
    const firstAt = arg.indexOf('@')
    if (firstAt > -1) {
      if (firstAt > firstColon) {
        return `git+ssh://${arg}`
      } else {
        return arg
      }
    }
    const doubleSlash = arg.indexOf('//')
    if (doubleSlash === firstColon + 1) {
      return arg
    }
    return `${arg.slice(0, firstColon + 1)}//${arg.slice(firstColon + 1)}`
  }

  // attempt to correct an scp style url so that it will parse with `new URL()`
  const correctUrl = giturl => {
    // ignore @ that come after the first hash since the denotes the start
    // of a committish which can contain @ characters
    const firstAt = lastIndexOfBefore(giturl, '@', '#')
    // ignore colons that come after the hash since that could include colons such as:
    // git@github.com:user/package-2#semver:^1.0.0
    const lastColonBeforeHash = lastIndexOfBefore(giturl, ':', '#')
    if (lastColonBeforeHash > firstAt) {
      // the last : comes after the first @ (or there is no @)
      // like it would in:
      // proto://hostname.com:user/repo
      // username@hostname.com:user/repo
      // :password@hostname.com:user/repo
      // username:password@hostname.com:user/repo
      // proto://username@hostname.com:user/repo
      // proto://:password@hostname.com:user/repo
      // proto://username:password@hostname.com:user/repo
      // then we replace the last : with a / to create a valid path
      giturl =
        giturl.slice(0, lastColonBeforeHash) +
        '/' +
        giturl.slice(lastColonBeforeHash + 1)
    }
    if (
      lastIndexOfBefore(giturl, ':', '#') === -1 &&
      giturl.indexOf('//') === -1
    ) {
      // we have no : at all
      // as it would be in:
      // username@hostname.com/user/repo
      // then we prepend a protocol
      giturl = `git+ssh://${giturl}`
    }
    return giturl
  }
  parseUrl = (giturl, protocols) => {
    const withProtocol = protocols ? correctProtocol(giturl, protocols) : giturl
    return safeUrl(withProtocol) || safeUrl(correctUrl(withProtocol))
  }
  return parseUrl
}

let fromUrl
let hasRequiredFromUrl
function requireFromUrl() {
  if (hasRequiredFromUrl) {
    return fromUrl
  }
  hasRequiredFromUrl = 1
  const parseUrl = requireParseUrl()

  // look for github shorthand inputs, such as npm/cli
  const isGitHubShorthand = arg => {
    // it cannot contain whitespace before the first #
    // it cannot start with a / because that's probably an absolute file path
    // but it must include a slash since repos are username/repository
    // it cannot start with a . because that's probably a relative file path
    // it cannot start with an @ because that's a scoped package if it passes the other tests
    // it cannot contain a : before a # because that tells us that there's a protocol
    // a second / may not exist before a #
    const firstHash = arg.indexOf('#')
    const firstSlash = arg.indexOf('/')
    const secondSlash = arg.indexOf('/', firstSlash + 1)
    const firstColon = arg.indexOf(':')
    const firstSpace = /\s/.exec(arg)
    const firstAt = arg.indexOf('@')
    const spaceOnlyAfterHash =
      !firstSpace || (firstHash > -1 && firstSpace.index > firstHash)
    const atOnlyAfterHash =
      firstAt === -1 || (firstHash > -1 && firstAt > firstHash)
    const colonOnlyAfterHash =
      firstColon === -1 || (firstHash > -1 && firstColon > firstHash)
    const secondSlashOnlyAfterHash =
      secondSlash === -1 || (firstHash > -1 && secondSlash > firstHash)
    const hasSlash = firstSlash > 0
    // if a # is found, what we really want to know is that the character
    // immediately before # is not a /
    const doesNotEndWithSlash =
      firstHash > -1 ? arg[firstHash - 1] !== '/' : !arg.endsWith('/')
    const doesNotStartWithDot = !arg.startsWith('.')
    return (
      spaceOnlyAfterHash &&
      hasSlash &&
      doesNotEndWithSlash &&
      doesNotStartWithDot &&
      atOnlyAfterHash &&
      colonOnlyAfterHash &&
      secondSlashOnlyAfterHash
    )
  }
  fromUrl = (giturl, opts, { gitHosts, protocols }) => {
    if (!giturl) {
      return
    }
    const correctedUrl = isGitHubShorthand(giturl) ? `github:${giturl}` : giturl
    const parsed = parseUrl(correctedUrl, protocols)
    if (!parsed) {
      return
    }
    const gitHostShortcut = gitHosts.byShortcut[parsed.protocol]
    const gitHostDomain =
      gitHosts.byDomain[
        parsed.hostname.startsWith('www.')
          ? parsed.hostname.slice(4)
          : parsed.hostname
      ]
    const gitHostName = gitHostShortcut || gitHostDomain
    if (!gitHostName) {
      return
    }
    const gitHostInfo = gitHosts[gitHostShortcut || gitHostDomain]
    let auth = null
    if (
      protocols[parsed.protocol]?.auth &&
      (parsed.username || parsed.password)
    ) {
      auth = `${parsed.username}${parsed.password ? ':' + parsed.password : ''}`
    }
    let committish = null
    let user = null
    let project = null
    let defaultRepresentation = null
    try {
      if (gitHostShortcut) {
        let pathname = parsed.pathname.startsWith('/')
          ? parsed.pathname.slice(1)
          : parsed.pathname
        const firstAt = pathname.indexOf('@')
        // we ignore auth for shortcuts, so just trim it out
        if (firstAt > -1) {
          pathname = pathname.slice(firstAt + 1)
        }
        const lastSlash = pathname.lastIndexOf('/')
        if (lastSlash > -1) {
          user = decodeURIComponent(pathname.slice(0, lastSlash))
          // we want nulls only, never empty strings
          if (!user) {
            user = null
          }
          project = decodeURIComponent(pathname.slice(lastSlash + 1))
        } else {
          project = decodeURIComponent(pathname)
        }
        if (project.endsWith('.git')) {
          project = project.slice(0, -4)
        }
        if (parsed.hash) {
          committish = decodeURIComponent(parsed.hash.slice(1))
        }
        defaultRepresentation = 'shortcut'
      } else {
        if (!gitHostInfo.protocols.includes(parsed.protocol)) {
          return
        }
        const segments = gitHostInfo.extract(parsed)
        if (!segments) {
          return
        }
        user = segments.user && decodeURIComponent(segments.user)
        project = decodeURIComponent(segments.project)
        committish = decodeURIComponent(segments.committish)
        defaultRepresentation =
          protocols[parsed.protocol]?.name || parsed.protocol.slice(0, -1)
      }
    } catch (err) {
      /* istanbul ignore else */
      if (err instanceof URIError) {
        return
      } else {
        throw err
      }
    }
    return [
      gitHostName,
      user,
      auth,
      project,
      committish,
      defaultRepresentation,
      opts
    ]
  }
  return fromUrl
}

let lib$8
let hasRequiredLib$8
function requireLib$8() {
  if (hasRequiredLib$8) {
    return lib$8
  }
  hasRequiredLib$8 = 1
  const { LRUCache } = /*@__PURE__*/ requireCommonjs$4()
  const hosts = requireHosts()
  const fromUrl = requireFromUrl()
  const parseUrl = requireParseUrl()
  const cache = new LRUCache({
    max: 1000
  })
  function unknownHostedUrl(url) {
    try {
      const { protocol, hostname, pathname } = new URL(url)
      if (!hostname) {
        return null
      }
      const proto = /(?:git\+)http:$/.test(protocol) ? 'http:' : 'https:'
      const path = pathname.replace(/\.git$/, '')
      return `${proto}//${hostname}${path}`
    } catch {
      return null
    }
  }
  class GitHost {
    constructor(
      type,
      user,
      auth,
      project,
      committish,
      defaultRepresentation,
      opts = {}
    ) {
      Object.assign(this, GitHost.#gitHosts[type], {
        type,
        user,
        auth,
        project,
        committish,
        default: defaultRepresentation,
        opts
      })
    }
    static #gitHosts = {
      byShortcut: {},
      byDomain: {}
    }
    static #protocols = {
      'git+ssh:': {
        name: 'sshurl'
      },
      'ssh:': {
        name: 'sshurl'
      },
      'git+https:': {
        name: 'https',
        auth: true
      },
      'git:': {
        auth: true
      },
      'http:': {
        auth: true
      },
      'https:': {
        auth: true
      },
      'git+http:': {
        auth: true
      }
    }
    static addHost(name, host) {
      GitHost.#gitHosts[name] = host
      GitHost.#gitHosts.byDomain[host.domain] = name
      GitHost.#gitHosts.byShortcut[`${name}:`] = name
      GitHost.#protocols[`${name}:`] = {
        name
      }
    }
    static fromUrl(giturl, opts) {
      if (typeof giturl !== 'string') {
        return
      }
      const key = giturl + JSON.stringify(opts || {})
      if (!cache.has(key)) {
        const hostArgs = fromUrl(giturl, opts, {
          gitHosts: GitHost.#gitHosts,
          protocols: GitHost.#protocols
        })
        cache.set(key, hostArgs ? new GitHost(...hostArgs) : undefined)
      }
      return cache.get(key)
    }
    static fromManifest(manifest, opts = {}) {
      if (!manifest || typeof manifest !== 'object') {
        return
      }
      const r = manifest.repository
      // TODO: look into also checking the `bugs`/`homepage` URLs

      const rurl =
        r &&
        (typeof r === 'string'
          ? r
          : typeof r === 'object' && typeof r.url === 'string'
            ? r.url
            : null)
      if (!rurl) {
        throw new Error('no repository')
      }
      const info =
        (rurl && GitHost.fromUrl(rurl.replace(/^git\+/, ''), opts)) || null
      if (info) {
        return info
      }
      const unk = unknownHostedUrl(rurl)
      return GitHost.fromUrl(unk, opts) || unk
    }
    static parseUrl(url) {
      return parseUrl(url)
    }
    #fill(template, opts) {
      if (typeof template !== 'function') {
        return null
      }
      const options = {
        ...this,
        ...this.opts,
        ...opts
      }

      // the path should always be set so we don't end up with 'undefined' in urls
      if (!options.path) {
        options.path = ''
      }

      // template functions will insert the leading slash themselves
      if (options.path.startsWith('/')) {
        options.path = options.path.slice(1)
      }
      if (options.noCommittish) {
        options.committish = null
      }
      const result = template(options)
      return options.noGitPlus && result.startsWith('git+')
        ? result.slice(4)
        : result
    }
    hash() {
      return this.committish ? `#${this.committish}` : ''
    }
    ssh(opts) {
      return this.#fill(this.sshtemplate, opts)
    }
    sshurl(opts) {
      return this.#fill(this.sshurltemplate, opts)
    }
    browse(path, ...args) {
      // not a string, treat path as opts
      if (typeof path !== 'string') {
        return this.#fill(this.browsetemplate, path)
      }
      if (typeof args[0] !== 'string') {
        return this.#fill(this.browsetreetemplate, {
          ...args[0],
          path
        })
      }
      return this.#fill(this.browsetreetemplate, {
        ...args[1],
        fragment: args[0],
        path
      })
    }

    // If the path is known to be a file, then browseFile should be used. For some hosts
    // the url is the same as browse, but for others like GitHub a file can use both `/tree/`
    // and `/blob/` in the path. When using a default committish of `HEAD` then the `/tree/`
    // path will redirect to a specific commit. Using the `/blob/` path avoids this and
    // does not redirect to a different commit.
    browseFile(path, ...args) {
      if (typeof args[0] !== 'string') {
        return this.#fill(this.browseblobtemplate, {
          ...args[0],
          path
        })
      }
      return this.#fill(this.browseblobtemplate, {
        ...args[1],
        fragment: args[0],
        path
      })
    }
    docs(opts) {
      return this.#fill(this.docstemplate, opts)
    }
    bugs(opts) {
      return this.#fill(this.bugstemplate, opts)
    }
    https(opts) {
      return this.#fill(this.httpstemplate, opts)
    }
    git(opts) {
      return this.#fill(this.gittemplate, opts)
    }
    shortcut(opts) {
      return this.#fill(this.shortcuttemplate, opts)
    }
    path(opts) {
      return this.#fill(this.pathtemplate, opts)
    }
    tarball(opts) {
      return this.#fill(this.tarballtemplate, {
        ...opts,
        noCommittish: false
      })
    }
    file(path, opts) {
      return this.#fill(this.filetemplate, {
        ...opts,
        path
      })
    }
    edit(path, opts) {
      return this.#fill(this.edittemplate, {
        ...opts,
        path
      })
    }
    getDefaultRepresentation() {
      return this.default
    }
    toString(opts) {
      if (this.default && typeof this[this.default] === 'function') {
        return this[this.default](opts)
      }
      return this.sshurl(opts)
    }
  }
  for (const [name, host] of Object.entries(hosts)) {
    GitHost.addHost(name, host)
  }
  lib$8 = GitHost
  return lib$8
}

const commonjs$3 = {}

const commonjs$2 = {}

let balancedMatch
let hasRequiredBalancedMatch
function requireBalancedMatch() {
  if (hasRequiredBalancedMatch) {
    return balancedMatch
  }
  hasRequiredBalancedMatch = 1
  balancedMatch = balanced
  function balanced(a, b, str) {
    if (a instanceof RegExp) {
      a = maybeMatch(a, str)
    }
    if (b instanceof RegExp) {
      b = maybeMatch(b, str)
    }
    const r = range(a, b, str)
    return (
      r && {
        start: r[0],
        end: r[1],
        pre: str.slice(0, r[0]),
        body: str.slice(r[0] + a.length, r[1]),
        post: str.slice(r[1] + b.length)
      }
    )
  }
  function maybeMatch(reg, str) {
    const m = str.match(reg)
    return m ? m[0] : null
  }
  balanced.range = range
  function range(a, b, str) {
    let begs, beg, left, right, result
    let ai = str.indexOf(a)
    let bi = str.indexOf(b, ai + 1)
    let i = ai
    if (ai >= 0 && bi > 0) {
      if (a === b) {
        return [ai, bi]
      }
      begs = []
      left = str.length
      while (i >= 0 && !result) {
        if (i == ai) {
          begs.push(i)
          ai = str.indexOf(a, i + 1)
        } else if (begs.length == 1) {
          result = [begs.pop(), bi]
        } else {
          beg = begs.pop()
          if (beg < left) {
            left = beg
            right = bi
          }
          bi = str.indexOf(b, i + 1)
        }
        i = ai < bi && ai >= 0 ? ai : bi
      }
      if (begs.length) {
        result = [left, right]
      }
    }
    return result
  }
  return balancedMatch
}

let braceExpansion
let hasRequiredBraceExpansion
function requireBraceExpansion() {
  if (hasRequiredBraceExpansion) {
    return braceExpansion
  }
  hasRequiredBraceExpansion = 1
  const balanced = requireBalancedMatch()
  braceExpansion = expandTop
  const escSlash = '\0SLASH' + Math.random() + '\0'
  const escOpen = '\0OPEN' + Math.random() + '\0'
  const escClose = '\0CLOSE' + Math.random() + '\0'
  const escComma = '\0COMMA' + Math.random() + '\0'
  const escPeriod = '\0PERIOD' + Math.random() + '\0'
  function numeric(str) {
    return parseInt(str, 10) == str ? parseInt(str, 10) : str.charCodeAt(0)
  }
  function escapeBraces(str) {
    return str
      .split('\\\\')
      .join(escSlash)
      .split('\\{')
      .join(escOpen)
      .split('\\}')
      .join(escClose)
      .split('\\,')
      .join(escComma)
      .split('\\.')
      .join(escPeriod)
  }
  function unescapeBraces(str) {
    return str
      .split(escSlash)
      .join('\\')
      .split(escOpen)
      .join('{')
      .split(escClose)
      .join('}')
      .split(escComma)
      .join(',')
      .split(escPeriod)
      .join('.')
  }

  // Basically just str.split(","), but handling cases
  // where we have nested braced sections, which should be
  // treated as individual members, like {a,{b,c},d}
  function parseCommaParts(str) {
    if (!str) {
      return ['']
    }
    const parts = []
    const m = balanced('{', '}', str)
    if (!m) {
      return str.split(',')
    }
    const pre = m.pre
    const body = m.body
    const post = m.post
    const p = pre.split(',')
    p[p.length - 1] += '{' + body + '}'
    const postParts = parseCommaParts(post)
    if (post.length) {
      p[p.length - 1] += postParts.shift()
      p.push.apply(p, postParts)
    }
    parts.push.apply(parts, p)
    return parts
  }
  function expandTop(str) {
    if (!str) {
      return []
    }

    // I don't know why Bash 4.3 does this, but it does.
    // Anything starting with {} will have the first two bytes preserved
    // but *only* at the top level, so {},a}b will not expand to anything,
    // but a{},b}c will be expanded to [a}c,abc].
    // One could argue that this is a bug in Bash, but since the goal of
    // this module is to match Bash's rules, we escape a leading {}
    if (str.substr(0, 2) === '{}') {
      str = '\\{\\}' + str.substr(2)
    }
    return expand(escapeBraces(str), true).map(unescapeBraces)
  }
  function embrace(str) {
    return '{' + str + '}'
  }
  function isPadded(el) {
    return /^-?0\d/.test(el)
  }
  function lte(i, y) {
    return i <= y
  }
  function gte(i, y) {
    return i >= y
  }
  function expand(str, isTop) {
    const expansions = []
    const m = balanced('{', '}', str)
    if (!m) {
      return [str]
    }

    // no need to expand pre, since it is guaranteed to be free of brace-sets
    const pre = m.pre
    const post = m.post.length ? expand(m.post, false) : ['']
    if (m.pre.endsWith('\u0024' /*'$'*/)) {
      for (var k = 0; k < post.length; k++) {
        var expansion = pre + '{' + m.body + '}' + post[k]
        expansions.push(expansion)
      }
    } else {
      const isNumericSequence = /^-?\d+\.\.-?\d+(?:\.\.-?\d+)?$/.test(m.body)
      const isAlphaSequence = /^[a-zA-Z]\.\.[a-zA-Z](?:\.\.-?\d+)?$/.test(
        m.body
      )
      const isSequence = isNumericSequence || isAlphaSequence
      const isOptions = m.body.indexOf(',') >= 0
      if (!isSequence && !isOptions) {
        // {a},b}
        if (m.post.match(/,(?!,).*\}/)) {
          str = m.pre + '{' + m.body + escClose + m.post
          return expand(str)
        }
        return [str]
      }
      let n
      if (isSequence) {
        n = m.body.split(/\.\./)
      } else {
        n = parseCommaParts(m.body)
        if (n.length === 1) {
          // x{{a,b}}y ==> x{a}y x{b}y
          n = expand(n[0], false).map(embrace)
          if (n.length === 1) {
            return post.map(function (p) {
              return m.pre + n[0] + p
            })
          }
        }
      }

      // at this point, n is the parts, and we know it's not a comma set
      // with a single entry.
      let N
      if (isSequence) {
        const x = numeric(n[0])
        const y = numeric(n[1])
        const width = Math.max(n[0].length, n[1].length)
        let incr = n.length == 3 ? Math.abs(numeric(n[2])) : 1
        let test = lte
        const reverse = y < x
        if (reverse) {
          incr *= -1
          test = gte
        }
        const pad = n.some(isPadded)
        N = []
        for (let i = x; test(i, y); i += incr) {
          let c
          if (isAlphaSequence) {
            c = String.fromCharCode(i)
            if (c === '\\') {
              c = ''
            }
          } else {
            c = String(i)
            if (pad) {
              const need = width - c.length
              if (need > 0) {
                const z = new Array(need + 1).join('0')
                if (i < 0) {
                  c = '-' + z + c.slice(1)
                } else {
                  c = z + c
                }
              }
            }
          }
          N.push(c)
        }
      } else {
        N = []
        for (var j = 0; j < n.length; j++) {
          N.push.apply(N, expand(n[j], false))
        }
      }
      for (var j = 0; j < N.length; j++) {
        for (var k = 0; k < post.length; k++) {
          var expansion = pre + N[j] + post[k]
          if (!isTop || isSequence || expansion) {
            expansions.push(expansion)
          }
        }
      }
    }
    return expansions
  }
  return braceExpansion
}

const assertValidPattern = {}

let hasRequiredAssertValidPattern
function requireAssertValidPattern() {
  if (hasRequiredAssertValidPattern) {
    return assertValidPattern
  }
  hasRequiredAssertValidPattern = 1
  Object.defineProperty(assertValidPattern, '__esModule', {
    value: true
  })
  assertValidPattern.assertValidPattern = void 0
  const MAX_PATTERN_LENGTH = 1024 * 64
  const assertValidPattern$1 = pattern => {
    if (typeof pattern !== 'string') {
      throw new TypeError('invalid pattern')
    }
    if (pattern.length > MAX_PATTERN_LENGTH) {
      throw new TypeError('pattern is too long')
    }
  }
  assertValidPattern.assertValidPattern = assertValidPattern$1
  return assertValidPattern
}

const ast = {}

const braceExpressions = {}

let hasRequiredBraceExpressions
function requireBraceExpressions() {
  if (hasRequiredBraceExpressions) {
    return braceExpressions
  }
  hasRequiredBraceExpressions = 1
  // translate the various posix character classes into unicode properties
  // this works across all unicode locales
  Object.defineProperty(braceExpressions, '__esModule', {
    value: true
  })
  braceExpressions.parseClass = void 0
  // { <posix class>: [<translation>, /u flag required, negated]
  const posixClasses = {
    '[:alnum:]': ['\\p{L}\\p{Nl}\\p{Nd}', true],
    '[:alpha:]': ['\\p{L}\\p{Nl}', true],
    '[:ascii:]': ['\\x' + '00-\\x' + '7f', false],
    '[:blank:]': ['\\p{Zs}\\t', true],
    '[:cntrl:]': ['\\p{Cc}', true],
    '[:digit:]': ['\\p{Nd}', true],
    '[:graph:]': ['\\p{Z}\\p{C}', true, true],
    '[:lower:]': ['\\p{Ll}', true],
    '[:print:]': ['\\p{C}', true],
    '[:punct:]': ['\\p{P}', true],
    '[:space:]': ['\\p{Z}\\t\\r\\n\\v\\f', true],
    '[:upper:]': ['\\p{Lu}', true],
    '[:word:]': ['\\p{L}\\p{Nl}\\p{Nd}\\p{Pc}', true],
    '[:xdigit:]': ['A-Fa-f0-9', false]
  }
  // only need to escape a few things inside of brace expressions
  // escapes: [ \ ] -
  const braceEscape = s => s.replace(/[[\]\\-]/g, '\\$&')
  // escape all regexp magic characters
  const regexpEscape = s => s.replace(/[-[\]{}()*+?.,\\^$|#\s]/g, '\\$&')
  // everything has already been escaped, we just have to join
  const rangesToString = ranges => ranges.join('')
  // takes a glob string at a posix brace expression, and returns
  // an equivalent regular expression source, and boolean indicating
  // whether the /u flag needs to be applied, and the number of chars
  // consumed to parse the character class.
  // This also removes out of order ranges, and returns ($.) if the
  // entire class just no good.
  const parseClass = (glob, position) => {
    const pos = position
    /* c8 ignore start */
    if (glob.charAt(pos) !== '[') {
      throw new Error('not in a brace expression')
    }
    /* c8 ignore stop */
    const ranges = []
    const negs = []
    let i = pos + 1
    let sawStart = false
    let uflag = false
    let escaping = false
    let negate = false
    let endPos = pos
    let rangeStart = ''
    WHILE: while (i < glob.length) {
      const c = glob.charAt(i)
      if ((c === '!' || c === '^') && i === pos + 1) {
        negate = true
        i++
        continue
      }
      if (c === ']' && sawStart && !escaping) {
        endPos = i + 1
        break
      }
      sawStart = true
      if (c === '\\') {
        if (!escaping) {
          escaping = true
          i++
          continue
        }
        // escaped \ char, fall through and treat like normal char
      }
      if (c === '[' && !escaping) {
        // either a posix class, a collation equivalent, or just a [
        for (const [cls, [unip, u, neg]] of Object.entries(posixClasses)) {
          if (glob.startsWith(cls, i)) {
            // invalid, [a-[] is fine, but not [a-[:alpha]]
            if (rangeStart) {
              return ['$.', false, glob.length - pos, true]
            }
            i += cls.length
            if (neg) {
              negs.push(unip)
            } else {
              ranges.push(unip)
            }
            uflag = uflag || u
            continue WHILE
          }
        }
      }
      // now it's just a normal character, effectively
      escaping = false
      if (rangeStart) {
        // throw this range away if it's not valid, but others
        // can still match.
        if (c > rangeStart) {
          ranges.push(braceEscape(rangeStart) + '-' + braceEscape(c))
        } else if (c === rangeStart) {
          ranges.push(braceEscape(c))
        }
        rangeStart = ''
        i++
        continue
      }
      // now might be the start of a range.
      // can be either c-d or c-] or c<more...>] or c] at this point
      if (glob.startsWith('-]', i + 1)) {
        ranges.push(braceEscape(c + '-'))
        i += 2
        continue
      }
      if (glob.startsWith('-', i + 1)) {
        rangeStart = c
        i += 2
        continue
      }
      // not the start of a range, just a single character
      ranges.push(braceEscape(c))
      i++
    }
    if (endPos < i) {
      // didn't see the end of the class, not a valid class,
      // but might still be valid as a literal match.
      return ['', false, 0, false]
    }
    // if we got no ranges and no negates, then we have a range that
    // cannot possibly match anything, and that poisons the whole glob
    if (!ranges.length && !negs.length) {
      return ['$.', false, glob.length - pos, true]
    }
    // if we got one positive range, and it's a single character, then that's
    // not actually a magic pattern, it's just that one literal character.
    // we should not treat that as "magic", we should just return the literal
    // character. [_] is a perfectly valid way to escape glob magic chars.
    if (
      negs.length === 0 &&
      ranges.length === 1 &&
      /^\\?.$/.test(ranges[0]) &&
      !negate
    ) {
      const r = ranges[0].length === 2 ? ranges[0].slice(-1) : ranges[0]
      return [regexpEscape(r), false, endPos - pos, false]
    }
    const sranges = '[' + (negate ? '^' : '') + rangesToString(ranges) + ']'
    const snegs = '[' + (negate ? '' : '^') + rangesToString(negs) + ']'
    const comb =
      ranges.length && negs.length
        ? '(' + sranges + '|' + snegs + ')'
        : ranges.length
          ? sranges
          : snegs
    return [comb, uflag, endPos - pos, true]
  }
  braceExpressions.parseClass = parseClass
  return braceExpressions
}

const _unescape = {}

let hasRequired_unescape
function require_unescape() {
  if (hasRequired_unescape) {
    return _unescape
  }
  hasRequired_unescape = 1
  Object.defineProperty(_unescape, '__esModule', {
    value: true
  })
  _unescape.unescape = void 0
  /**
   * Un-escape a string that has been escaped with {@link escape}.
   *
   * If the {@link windowsPathsNoEscape} option is used, then square-brace
   * escapes are removed, but not backslash escapes.  For example, it will turn
   * the string `'[*]'` into `*`, but it will not turn `'\\*'` into `'*'`,
   * becuase `\` is a path separator in `windowsPathsNoEscape` mode.
   *
   * When `windowsPathsNoEscape` is not set, then both brace escapes and
   * backslash escapes are removed.
   *
   * Slashes (and backslashes in `windowsPathsNoEscape` mode) cannot be escaped
   * or unescaped.
   */
  const unescape = (s, { windowsPathsNoEscape = false } = {}) => {
    return windowsPathsNoEscape
      ? s.replace(/\[([^/\\])\]/g, '$1')
      : s.replace(/((?!\\).|^)\[([^/\\])\]/g, '$1$2').replace(/\\([^/])/g, '$1')
  }
  _unescape.unescape = unescape
  return _unescape
}

let hasRequiredAst
function requireAst() {
  if (hasRequiredAst) {
    return ast
  }
  hasRequiredAst = 1
  // parse a single path portion
  Object.defineProperty(ast, '__esModule', {
    value: true
  })
  ast.AST = void 0
  const brace_expressions_js_1 = requireBraceExpressions()
  const unescape_js_1 = require_unescape()
  const types = new Set(['!', '?', '+', '*', '@'])
  const isExtglobType = c => types.has(c)
  // Patterns that get prepended to bind to the start of either the
  // entire string, or just a single path portion, to prevent dots
  // and/or traversal patterns, when needed.
  // Exts don't need the ^ or / bit, because the root binds that already.
  const startNoTraversal = '(?!(?:^|/)\\.\\.?(?:$|/))'
  const startNoDot = '(?!\\.)'
  // characters that indicate a start of pattern needs the "no dots" bit,
  // because a dot *might* be matched. ( is not in the list, because in
  // the case of a child extglob, it will handle the prevention itself.
  const addPatternStart = new Set(['[', '.'])
  // cases where traversal is A-OK, no dot prevention needed
  const justDots = new Set(['..', '.'])
  const reSpecials = new Set('().*{}+?[]^$\\!')
  const regExpEscape = s => s.replace(/[-[\]{}()*+?.,\\^$|#\s]/g, '\\$&')
  // any single thing other than /
  const qmark = '[^/]'
  // * => any number of characters
  const star = qmark + '*?'
  // use + when we need to ensure that *something* matches, because the * is
  // the only thing in the path portion.
  const starNoEmpty = qmark + '+?'
  // remove the \ chars that we added if we end up doing a nonmagic compare
  // const deslash = (s: string) => s.replace(/\\(.)/g, '$1')
  class AST {
    type
    #root
    #hasMagic
    #uflag = false
    #parts = []
    #parent
    #parentIndex
    #negs
    #filledNegs = false
    #options
    #toString
    // set to true if it's an extglob with no children
    // (which really means one child of '')
    #emptyExt = false
    constructor(type, parent, options = {}) {
      this.type = type
      // extglobs are inherently magical
      if (type) {
        this.#hasMagic = true
      }
      this.#parent = parent
      this.#root = this.#parent ? this.#parent.#root : this
      this.#options = this.#root === this ? options : this.#root.#options
      this.#negs = this.#root === this ? [] : this.#root.#negs
      if (type === '!' && !this.#root.#filledNegs) {
        this.#negs.push(this)
      }
      this.#parentIndex = this.#parent ? this.#parent.#parts.length : 0
    }
    get hasMagic() {
      /* c8 ignore start */
      if (this.#hasMagic !== undefined) {
        return this.#hasMagic
      }
      /* c8 ignore stop */
      for (const p of this.#parts) {
        if (typeof p === 'string') {
          continue
        }
        if (p.type || p.hasMagic) {
          return (this.#hasMagic = true)
        }
      }
      // note: will be undefined until we generate the regexp src and find out
      return this.#hasMagic
    }
    // reconstructs the pattern
    toString() {
      if (this.#toString !== undefined) {
        return this.#toString
      }
      if (!this.type) {
        return (this.#toString = this.#parts.map(p => String(p)).join(''))
      } else {
        return (this.#toString =
          this.type + '(' + this.#parts.map(p => String(p)).join('|') + ')')
      }
    }
    #fillNegs() {
      /* c8 ignore start */
      if (this !== this.#root) {
        throw new Error('should only call on root')
      }
      if (this.#filledNegs) {
        return this
      }
      /* c8 ignore stop */
      // call toString() once to fill this out
      this.toString()
      this.#filledNegs = true
      let n
      while ((n = this.#negs.pop())) {
        if (n.type !== '!') {
          continue
        }
        // walk up the tree, appending everthing that comes AFTER parentIndex
        let p = n
        let pp = p.#parent
        while (pp) {
          for (
            let i = p.#parentIndex + 1;
            !pp.type && i < pp.#parts.length;
            i++
          ) {
            for (const part of n.#parts) {
              /* c8 ignore start */
              if (typeof part === 'string') {
                throw new Error('string part in extglob AST??')
              }
              /* c8 ignore stop */
              part.copyIn(pp.#parts[i])
            }
          }
          p = pp
          pp = p.#parent
        }
      }
      return this
    }
    push(...parts) {
      for (const p of parts) {
        if (p === '') {
          continue
        }
        /* c8 ignore start */
        if (
          typeof p !== 'string' &&
          !(p instanceof AST && p.#parent === this)
        ) {
          throw new Error('invalid part: ' + p)
        }
        /* c8 ignore stop */
        this.#parts.push(p)
      }
    }
    toJSON() {
      const ret =
        this.type === null
          ? this.#parts
              .slice()
              .map(p => (typeof p === 'string' ? p : p.toJSON()))
          : [this.type, ...this.#parts.map(p => p.toJSON())]
      if (this.isStart() && !this.type) {
        ret.unshift([])
      }
      if (
        this.isEnd() &&
        (this === this.#root ||
          (this.#root.#filledNegs && this.#parent?.type === '!'))
      ) {
        ret.push({})
      }
      return ret
    }
    isStart() {
      if (this.#root === this) {
        return true
      }
      // if (this.type) return !!this.#parent?.isStart()
      if (!this.#parent?.isStart()) {
        return false
      }
      if (this.#parentIndex === 0) {
        return true
      }
      // if everything AHEAD of this is a negation, then it's still the "start"
      const p = this.#parent
      for (let i = 0; i < this.#parentIndex; i++) {
        const pp = p.#parts[i]
        if (!(pp instanceof AST && pp.type === '!')) {
          return false
        }
      }
      return true
    }
    isEnd() {
      if (this.#root === this) {
        return true
      }
      if (this.#parent?.type === '!') {
        return true
      }
      if (!this.#parent?.isEnd()) {
        return false
      }
      if (!this.type) {
        return this.#parent?.isEnd()
      }
      // if not root, it'll always have a parent
      /* c8 ignore start */
      const pl = this.#parent ? this.#parent.#parts.length : 0
      /* c8 ignore stop */
      return this.#parentIndex === pl - 1
    }
    copyIn(part) {
      if (typeof part === 'string') {
        this.push(part)
      } else {
        this.push(part.clone(this))
      }
    }
    clone(parent) {
      const c = new AST(this.type, parent)
      for (const p of this.#parts) {
        c.copyIn(p)
      }
      return c
    }
    static #parseAST(str, ast, pos, opt) {
      let escaping = false
      let inBrace = false
      let braceStart = -1
      let braceNeg = false
      if (ast.type === null) {
        // outside of a extglob, append until we find a start
        let i = pos
        let acc = ''
        while (i < str.length) {
          const c = str.charAt(i++)
          // still accumulate escapes at this point, but we do ignore
          // starts that are escaped
          if (escaping || c === '\\') {
            escaping = !escaping
            acc += c
            continue
          }
          if (inBrace) {
            if (i === braceStart + 1) {
              if (c === '^' || c === '!') {
                braceNeg = true
              }
            } else if (c === ']' && !(i === braceStart + 2 && braceNeg)) {
              inBrace = false
            }
            acc += c
            continue
          } else if (c === '[') {
            inBrace = true
            braceStart = i
            braceNeg = false
            acc += c
            continue
          }
          if (!opt.noext && isExtglobType(c) && str.charAt(i) === '(') {
            ast.push(acc)
            acc = ''
            const ext = new AST(c, ast)
            i = AST.#parseAST(str, ext, i, opt)
            ast.push(ext)
            continue
          }
          acc += c
        }
        ast.push(acc)
        return i
      }
      // some kind of extglob, pos is at the (
      // find the next | or )
      let i = pos + 1
      let part = new AST(null, ast)
      const parts = []
      let acc = ''
      while (i < str.length) {
        const c = str.charAt(i++)
        // still accumulate escapes at this point, but we do ignore
        // starts that are escaped
        if (escaping || c === '\\') {
          escaping = !escaping
          acc += c
          continue
        }
        if (inBrace) {
          if (i === braceStart + 1) {
            if (c === '^' || c === '!') {
              braceNeg = true
            }
          } else if (c === ']' && !(i === braceStart + 2 && braceNeg)) {
            inBrace = false
          }
          acc += c
          continue
        } else if (c === '[') {
          inBrace = true
          braceStart = i
          braceNeg = false
          acc += c
          continue
        }
        if (isExtglobType(c) && str.charAt(i) === '(') {
          part.push(acc)
          acc = ''
          const ext = new AST(c, part)
          part.push(ext)
          i = AST.#parseAST(str, ext, i, opt)
          continue
        }
        if (c === '|') {
          part.push(acc)
          acc = ''
          parts.push(part)
          part = new AST(null, ast)
          continue
        }
        if (c === ')') {
          if (acc === '' && ast.#parts.length === 0) {
            ast.#emptyExt = true
          }
          part.push(acc)
          acc = ''
          ast.push(...parts, part)
          return i
        }
        acc += c
      }
      // unfinished extglob
      // if we got here, it was a malformed extglob! not an extglob, but
      // maybe something else in there.
      ast.type = null
      ast.#hasMagic = undefined
      ast.#parts = [str.substring(pos - 1)]
      return i
    }
    static fromGlob(pattern, options = {}) {
      const ast = new AST(null, undefined, options)
      AST.#parseAST(pattern, ast, 0, options)
      return ast
    }
    // returns the regular expression if there's magic, or the unescaped
    // string if not.
    toMMPattern() {
      // should only be called on root
      /* c8 ignore start */
      if (this !== this.#root) {
        return this.#root.toMMPattern()
      }
      /* c8 ignore stop */
      const glob = this.toString()
      const [re, body, hasMagic, uflag] = this.toRegExpSource()
      // if we're in nocase mode, and not nocaseMagicOnly, then we do
      // still need a regular expression if we have to case-insensitively
      // match capital/lowercase characters.
      const anyMagic =
        hasMagic ||
        this.#hasMagic ||
        (this.#options.nocase &&
          !this.#options.nocaseMagicOnly &&
          glob.toUpperCase() !== glob.toLowerCase())
      if (!anyMagic) {
        return body
      }
      const flags = (this.#options.nocase ? 'i' : '') + (uflag ? 'u' : '')
      return Object.assign(new RegExp(`^${re}$`, flags), {
        _src: re,
        _glob: glob
      })
    }
    get options() {
      return this.#options
    }
    // returns the string match, the regexp source, whether there's magic
    // in the regexp (so a regular expression is required) and whether or
    // not the uflag is needed for the regular expression (for posix classes)
    // TODO: instead of injecting the start/end at this point, just return
    // the BODY of the regexp, along with the start/end portions suitable
    // for binding the start/end in either a joined full-path makeRe context
    // (where we bind to (^|/), or a standalone matchPart context (where
    // we bind to ^, and not /).  Otherwise slashes get duped!
    //
    // In part-matching mode, the start is:
    // - if not isStart: nothing
    // - if traversal possible, but not allowed: ^(?!\.\.?$)
    // - if dots allowed or not possible: ^
    // - if dots possible and not allowed: ^(?!\.)
    // end is:
    // - if not isEnd(): nothing
    // - else: $
    //
    // In full-path matching mode, we put the slash at the START of the
    // pattern, so start is:
    // - if first pattern: same as part-matching mode
    // - if not isStart(): nothing
    // - if traversal possible, but not allowed: /(?!\.\.?(?:$|/))
    // - if dots allowed or not possible: /
    // - if dots possible and not allowed: /(?!\.)
    // end is:
    // - if last pattern, same as part-matching mode
    // - else nothing
    //
    // Always put the (?:$|/) on negated tails, though, because that has to be
    // there to bind the end of the negated pattern portion, and it's easier to
    // just stick it in now rather than try to inject it later in the middle of
    // the pattern.
    //
    // We can just always return the same end, and leave it up to the caller
    // to know whether it's going to be used joined or in parts.
    // And, if the start is adjusted slightly, can do the same there:
    // - if not isStart: nothing
    // - if traversal possible, but not allowed: (?:/|^)(?!\.\.?$)
    // - if dots allowed or not possible: (?:/|^)
    // - if dots possible and not allowed: (?:/|^)(?!\.)
    //
    // But it's better to have a simpler binding without a conditional, for
    // performance, so probably better to return both start options.
    //
    // Then the caller just ignores the end if it's not the first pattern,
    // and the start always gets applied.
    //
    // But that's always going to be $ if it's the ending pattern, or nothing,
    // so the caller can just attach $ at the end of the pattern when building.
    //
    // So the todo is:
    // - better detect what kind of start is needed
    // - return both flavors of starting pattern
    // - attach $ at the end of the pattern when creating the actual RegExp
    //
    // Ah, but wait, no, that all only applies to the root when the first pattern
    // is not an extglob. If the first pattern IS an extglob, then we need all
    // that dot prevention biz to live in the extglob portions, because eg
    // +(*|.x*) can match .xy but not .yx.
    //
    // So, return the two flavors if it's #root and the first child is not an
    // AST, otherwise leave it to the child AST to handle it, and there,
    // use the (?:^|/) style of start binding.
    //
    // Even simplified further:
    // - Since the start for a join is eg /(?!\.) and the start for a part
    // is ^(?!\.), we can just prepend (?!\.) to the pattern (either root
    // or start or whatever) and prepend ^ or / at the Regexp construction.
    toRegExpSource(allowDot) {
      const dot = allowDot ?? !!this.#options.dot
      if (this.#root === this) {
        this.#fillNegs()
      }
      if (!this.type) {
        const noEmpty = this.isStart() && this.isEnd()
        const src = this.#parts
          .map(p => {
            const [re, _, hasMagic, uflag] =
              typeof p === 'string'
                ? AST.#parseGlob(p, this.#hasMagic, noEmpty)
                : p.toRegExpSource(allowDot)
            this.#hasMagic = this.#hasMagic || hasMagic
            this.#uflag = this.#uflag || uflag
            return re
          })
          .join('')
        let start = ''
        if (this.isStart()) {
          if (typeof this.#parts[0] === 'string') {
            // this is the string that will match the start of the pattern,
            // so we need to protect against dots and such.
            // '.' and '..' cannot match unless the pattern is that exactly,
            // even if it starts with . or dot:true is set.
            const dotTravAllowed =
              this.#parts.length === 1 && justDots.has(this.#parts[0])
            if (!dotTravAllowed) {
              const aps = addPatternStart
              // check if we have a possibility of matching . or ..,
              // and prevent that.
              const needNoTrav =
                // dots are allowed, and the pattern starts with [ or .
                (dot && aps.has(src.charAt(0))) ||
                // the pattern starts with \., and then [ or .
                (src.startsWith('\\.') && aps.has(src.charAt(2))) ||
                // the pattern starts with \.\., and then [ or .
                (src.startsWith('\\.\\.') && aps.has(src.charAt(4)))
              // no need to prevent dots if it can't match a dot, or if a
              // sub-pattern will be preventing it anyway.
              const needNoDot = !dot && !allowDot && aps.has(src.charAt(0))
              start = needNoTrav
                ? startNoTraversal
                : needNoDot
                  ? startNoDot
                  : ''
            }
          }
        }
        // append the "end of path portion" pattern to negation tails
        let end = ''
        if (
          this.isEnd() &&
          this.#root.#filledNegs &&
          this.#parent?.type === '!'
        ) {
          end = '(?:$|\\/)'
        }
        const final = start + src + end
        return [
          final,
          (0, unescape_js_1.unescape)(src),
          (this.#hasMagic = !!this.#hasMagic),
          this.#uflag
        ]
      }
      // We need to calculate the body *twice* if it's a repeat pattern
      // at the start, once in nodot mode, then again in dot mode, so a
      // pattern like *(?) can match 'x.y'
      const repeated = this.type === '*' || this.type === '+'
      // some kind of extglob
      const start = this.type === '!' ? '(?:(?!(?:' : '(?:'
      let body = this.#partsToRegExp(dot)
      if (this.isStart() && this.isEnd() && !body && this.type !== '!') {
        // invalid extglob, has to at least be *something* present, if it's
        // the entire path portion.
        const s = this.toString()
        this.#parts = [s]
        this.type = null
        this.#hasMagic = undefined
        return [s, (0, unescape_js_1.unescape)(this.toString()), false, false]
      }
      // XXX abstract out this map method
      let bodyDotAllowed =
        !repeated || allowDot || dot || !startNoDot
          ? ''
          : this.#partsToRegExp(true)
      if (bodyDotAllowed === body) {
        bodyDotAllowed = ''
      }
      if (bodyDotAllowed) {
        body = `(?:${body})(?:${bodyDotAllowed})*?`
      }
      // an empty !() is exactly equivalent to a starNoEmpty
      let final = ''
      if (this.type === '!' && this.#emptyExt) {
        final = (this.isStart() && !dot ? startNoDot : '') + starNoEmpty
      } else {
        const close =
          this.type === '!'
            ? // !() must match something,but !(x) can match ''
              '))' +
              (this.isStart() && !dot && !allowDot ? startNoDot : '') +
              star +
              ')'
            : this.type === '@'
              ? ')'
              : this.type === '?'
                ? ')?'
                : this.type === '+' && bodyDotAllowed
                  ? ')'
                  : this.type === '*' && bodyDotAllowed
                    ? `)?`
                    : `)${this.type}`
        final = start + body + close
      }
      return [
        final,
        (0, unescape_js_1.unescape)(body),
        (this.#hasMagic = !!this.#hasMagic),
        this.#uflag
      ]
    }
    #partsToRegExp(dot) {
      return this.#parts
        .map(p => {
          // extglob ASTs should only contain parent ASTs
          /* c8 ignore start */
          if (typeof p === 'string') {
            throw new Error('string type in extglob ast??')
          }
          /* c8 ignore stop */
          // can ignore hasMagic, because extglobs are already always magic
          const [re, _, _hasMagic, uflag] = p.toRegExpSource(dot)
          this.#uflag = this.#uflag || uflag
          return re
        })
        .filter(p => !(this.isStart() && this.isEnd()) || !!p)
        .join('|')
    }
    static #parseGlob(glob, hasMagic, noEmpty = false) {
      let escaping = false
      let re = ''
      let uflag = false
      for (let i = 0; i < glob.length; i++) {
        const c = glob.charAt(i)
        if (escaping) {
          escaping = false
          re += (reSpecials.has(c) ? '\\' : '') + c
          continue
        }
        if (c === '\\') {
          if (i === glob.length - 1) {
            re += '\\\\'
          } else {
            escaping = true
          }
          continue
        }
        if (c === '[') {
          const [src, needUflag, consumed, magic] = (0,
          brace_expressions_js_1.parseClass)(glob, i)
          if (consumed) {
            re += src
            uflag = uflag || needUflag
            i += consumed - 1
            hasMagic = hasMagic || magic
            continue
          }
        }
        if (c === '*') {
          if (noEmpty && glob === '*') {
            re += starNoEmpty
          } else {
            re += star
          }
          hasMagic = true
          continue
        }
        if (c === '?') {
          re += qmark
          hasMagic = true
          continue
        }
        re += regExpEscape(c)
      }
      return [re, (0, unescape_js_1.unescape)(glob), !!hasMagic, uflag]
    }
  }
  ast.AST = AST
  return ast
}

const _escape$1 = {}

let hasRequired_escape$1
function require_escape$1() {
  if (hasRequired_escape$1) {
    return _escape$1
  }
  hasRequired_escape$1 = 1
  Object.defineProperty(_escape$1, '__esModule', {
    value: true
  })
  _escape$1.escape = void 0
  /**
   * Escape all magic characters in a glob pattern.
   *
   * If the {@link windowsPathsNoEscape | GlobOptions.windowsPathsNoEscape}
   * option is used, then characters are escaped by wrapping in `[]`, because
   * a magic character wrapped in a character class can only be satisfied by
   * that exact character.  In this mode, `\` is _not_ escaped, because it is
   * not interpreted as a magic character, but instead as a path separator.
   */
  const escape = (s, { windowsPathsNoEscape = false } = {}) => {
    // don't need to escape +@! because we escape the parens
    // that make those magic, and escaping ! as [!] isn't valid,
    // because [!]] is a valid glob class meaning not ']'.
    return windowsPathsNoEscape
      ? s.replace(/[?*()[\]]/g, '[$&]')
      : s.replace(/[?*()[\]\\]/g, '\\$&')
  }
  _escape$1.escape = escape
  return _escape$1
}

let hasRequiredCommonjs$3
function requireCommonjs$3() {
  if (hasRequiredCommonjs$3) {
    return commonjs$2
  }
  hasRequiredCommonjs$3 = 1
  ;(function (exports) {
    const __importDefault =
      (this && this.__importDefault) ||
      function (mod) {
        return mod && mod.__esModule
          ? mod
          : {
              default: mod
            }
      }
    Object.defineProperty(exports, '__esModule', {
      value: true
    })
    exports.unescape =
      exports.escape =
      exports.AST =
      exports.Minimatch =
      exports.match =
      exports.makeRe =
      exports.braceExpand =
      exports.defaults =
      exports.filter =
      exports.GLOBSTAR =
      exports.sep =
      exports.minimatch =
        void 0
    const brace_expansion_1 = __importDefault(requireBraceExpansion())
    const assert_valid_pattern_js_1 = requireAssertValidPattern()
    const ast_js_1 = requireAst()
    const escape_js_1 = require_escape$1()
    const unescape_js_1 = require_unescape()
    const minimatch = (p, pattern, options = {}) => {
      ;(0, assert_valid_pattern_js_1.assertValidPattern)(pattern)
      // shortcut: comments match nothing.
      if (!options.nocomment && pattern.charAt(0) === '#') {
        return false
      }
      return new Minimatch(pattern, options).match(p)
    }
    exports.minimatch = minimatch
    // Optimized checking for the most common glob patterns.
    const starDotExtRE = /^\*+([^+@!?*[(]*)$/
    const starDotExtTest = ext => f => !f.startsWith('.') && f.endsWith(ext)
    const starDotExtTestDot = ext => f => f.endsWith(ext)
    const starDotExtTestNocase = ext => {
      ext = ext.toLowerCase()
      return f => !f.startsWith('.') && f.toLowerCase().endsWith(ext)
    }
    const starDotExtTestNocaseDot = ext => {
      ext = ext.toLowerCase()
      return f => f.toLowerCase().endsWith(ext)
    }
    const starDotStarRE = /^\*+\.\*+$/
    const starDotStarTest = f => !f.startsWith('.') && f.includes('.')
    const starDotStarTestDot = f => f !== '.' && f !== '..' && f.includes('.')
    const dotStarRE = /^\.\*+$/
    const dotStarTest = f => f !== '.' && f !== '..' && f.startsWith('.')
    const starRE = /^\*+$/
    const starTest = f => f.length !== 0 && !f.startsWith('.')
    const starTestDot = f => f.length !== 0 && f !== '.' && f !== '..'
    const qmarksRE = /^\?+([^+@!?*[(]*)?$/
    const qmarksTestNocase = ([$0, ext = '']) => {
      const noext = qmarksTestNoExt([$0])
      if (!ext) {
        return noext
      }
      ext = ext.toLowerCase()
      return f => noext(f) && f.toLowerCase().endsWith(ext)
    }
    const qmarksTestNocaseDot = ([$0, ext = '']) => {
      const noext = qmarksTestNoExtDot([$0])
      if (!ext) {
        return noext
      }
      ext = ext.toLowerCase()
      return f => noext(f) && f.toLowerCase().endsWith(ext)
    }
    const qmarksTestDot = ([$0, ext = '']) => {
      const noext = qmarksTestNoExtDot([$0])
      return !ext ? noext : f => noext(f) && f.endsWith(ext)
    }
    const qmarksTest = ([$0, ext = '']) => {
      const noext = qmarksTestNoExt([$0])
      return !ext ? noext : f => noext(f) && f.endsWith(ext)
    }
    const qmarksTestNoExt = ([$0]) => {
      const len = $0.length
      return f => f.length === len && !f.startsWith('.')
    }
    const qmarksTestNoExtDot = ([$0]) => {
      const len = $0.length
      return f => f.length === len && f !== '.' && f !== '..'
    }
    /* c8 ignore start */
    const defaultPlatform =
      typeof process === 'object' && process
        ? (typeof process.env === 'object' &&
            process.env &&
            process.env.__MINIMATCH_TESTING_PLATFORM__) ||
          process.platform
        : 'posix'
    const path = {
      win32: {
        sep: '\\'
      },
      posix: {
        sep: '/'
      }
    }
    /* c8 ignore stop */
    exports.sep = defaultPlatform === 'win32' ? path.win32.sep : path.posix.sep
    exports.minimatch.sep = exports.sep
    exports.GLOBSTAR = Symbol('globstar **')
    exports.minimatch.GLOBSTAR = exports.GLOBSTAR
    // any single thing other than /
    // don't need to escape / when using new RegExp()
    const qmark = '[^/]'
    // * => any number of characters
    const star = qmark + '*?'
    // ** when dots are allowed.  Anything goes, except .. and .
    // not (^ or / followed by one or two dots followed by $ or /),
    // followed by anything, any number of times.
    const twoStarDot = '(?:(?!(?:\\/|^)(?:\\.{1,2})($|\\/)).)*?'
    // not a ^ or / followed by a dot,
    // followed by anything, any number of times.
    const twoStarNoDot = '(?:(?!(?:\\/|^)\\.).)*?'
    const filter =
      (pattern, options = {}) =>
      p =>
        (0, exports.minimatch)(p, pattern, options)
    exports.filter = filter
    exports.minimatch.filter = exports.filter
    const ext = (a, b = {}) => Object.assign({}, a, b)
    const defaults = def => {
      if (!def || typeof def !== 'object' || !Object.keys(def).length) {
        return exports.minimatch
      }
      const orig = exports.minimatch
      const m = (p, pattern, options = {}) =>
        orig(p, pattern, ext(def, options))
      return Object.assign(m, {
        Minimatch: class Minimatch extends orig.Minimatch {
          constructor(pattern, options = {}) {
            super(pattern, ext(def, options))
          }
          static defaults(options) {
            return orig.defaults(ext(def, options)).Minimatch
          }
        },
        AST: class AST extends orig.AST {
          /* c8 ignore start */
          constructor(type, parent, options = {}) {
            super(type, parent, ext(def, options))
          }
          /* c8 ignore stop */
          static fromGlob(pattern, options = {}) {
            return orig.AST.fromGlob(pattern, ext(def, options))
          }
        },
        unescape: (s, options = {}) => orig.unescape(s, ext(def, options)),
        escape: (s, options = {}) => orig.escape(s, ext(def, options)),
        filter: (pattern, options = {}) =>
          orig.filter(pattern, ext(def, options)),
        defaults: options => orig.defaults(ext(def, options)),
        makeRe: (pattern, options = {}) =>
          orig.makeRe(pattern, ext(def, options)),
        braceExpand: (pattern, options = {}) =>
          orig.braceExpand(pattern, ext(def, options)),
        match: (list, pattern, options = {}) =>
          orig.match(list, pattern, ext(def, options)),
        sep: orig.sep,
        GLOBSTAR: exports.GLOBSTAR
      })
    }
    exports.defaults = defaults
    exports.minimatch.defaults = exports.defaults
    // Brace expansion:
    // a{b,c}d -> abd acd
    // a{b,}c -> abc ac
    // a{0..3}d -> a0d a1d a2d a3d
    // a{b,c{d,e}f}g -> abg acdfg acefg
    // a{b,c}d{e,f}g -> abdeg acdeg abdeg abdfg
    //
    // Invalid sets are not expanded.
    // a{2..}b -> a{2..}b
    // a{b}c -> a{b}c
    const braceExpand = (pattern, options = {}) => {
      ;(0, assert_valid_pattern_js_1.assertValidPattern)(pattern)
      // Thanks to Yeting Li <https://github.com/yetingli> for
      // improving this regexp to avoid a ReDOS vulnerability.
      if (options.nobrace || !/\{(?:(?!\{).)*\}/.test(pattern)) {
        // shortcut. no need to expand.
        return [pattern]
      }
      return (0, brace_expansion_1.default)(pattern)
    }
    exports.braceExpand = braceExpand
    exports.minimatch.braceExpand = exports.braceExpand
    // parse a component of the expanded set.
    // At this point, no pattern may contain "/" in it
    // so we're going to return a 2d array, where each entry is the full
    // pattern, split on '/', and then turned into a regular expression.
    // A regexp is made at the end which joins each array with an
    // escaped /, and another full one which joins each regexp with |.
    //
    // Following the lead of Bash 4.1, note that "**" only has special meaning
    // when it is the *only* thing in a path portion.  Otherwise, any series
    // of * is equivalent to a single *.  Globstar behavior is enabled by
    // default, and can be disabled by setting options.noglobstar.
    const makeRe = (pattern, options = {}) =>
      new Minimatch(pattern, options).makeRe()
    exports.makeRe = makeRe
    exports.minimatch.makeRe = exports.makeRe
    const match = (list, pattern, options = {}) => {
      const mm = new Minimatch(pattern, options)
      list = list.filter(f => mm.match(f))
      if (mm.options.nonull && !list.length) {
        list.push(pattern)
      }
      return list
    }
    exports.match = match
    exports.minimatch.match = exports.match
    // replace stuff like \* with *
    const globMagic = /[?*]|[+@!]\(.*?\)|\[|\]/
    const regExpEscape = s => s.replace(/[-[\]{}()*+?.,\\^$|#\s]/g, '\\$&')
    class Minimatch {
      options
      set;
      pattern
      windowsPathsNoEscape
      nonegate
      negate
      comment
      empty
      preserveMultipleSlashes
      partial
      globSet
      globParts
      nocase
      isWindows
      platform
      windowsNoMagicRoot
      regexp
      constructor(pattern, options = {}) {
        ;(0, assert_valid_pattern_js_1.assertValidPattern)(pattern)
        options = options || {}
        this.options = options
        this.pattern = pattern
        this.platform = options.platform || defaultPlatform
        this.isWindows = this.platform === 'win32'
        this.windowsPathsNoEscape =
          !!options.windowsPathsNoEscape || options.allowWindowsEscape === false
        if (this.windowsPathsNoEscape) {
          this.pattern = this.pattern.replace(/\\/g, '/')
        }
        this.preserveMultipleSlashes = !!options.preserveMultipleSlashes
        this.regexp = null
        this.negate = false
        this.nonegate = !!options.nonegate
        this.comment = false
        this.empty = false
        this.partial = !!options.partial
        this.nocase = !!this.options.nocase
        this.windowsNoMagicRoot =
          options.windowsNoMagicRoot !== undefined
            ? options.windowsNoMagicRoot
            : !!(this.isWindows && this.nocase)
        this.globSet = []
        this.globParts = []
        this.set = []
        // make the set of regexps etc.
        this.make()
      }
      hasMagic() {
        if (this.options.magicalBraces && this.set.length > 1) {
          return true
        }
        for (const pattern of this.set) {
          for (const part of pattern) {
            if (typeof part !== 'string') {
              return true
            }
          }
        }
        return false
      }
      debug(..._) {}
      make() {
        const pattern = this.pattern
        const options = this.options
        // empty patterns and comments match nothing.
        if (!options.nocomment && pattern.charAt(0) === '#') {
          this.comment = true
          return
        }
        if (!pattern) {
          this.empty = true
          return
        }
        // step 1: figure out negation, etc.
        this.parseNegate()
        // step 2: expand braces
        this.globSet = [...new Set(this.braceExpand())]
        if (options.debug) {
          this.debug = (...args) => console.error(...args)
        }
        this.debug(this.pattern, this.globSet)
        // step 3: now we have a set, so turn each one into a series of
        // path-portion matching patterns.
        // These will be regexps, except in the case of "**", which is
        // set to the GLOBSTAR object for globstar behavior,
        // and will not contain any / characters
        //
        // First, we preprocess to make the glob pattern sets a bit simpler
        // and deduped.  There are some perf-killing patterns that can cause
        // problems with a glob walk, but we can simplify them down a bit.
        const rawGlobParts = this.globSet.map(s => this.slashSplit(s))
        this.globParts = this.preprocess(rawGlobParts)
        this.debug(this.pattern, this.globParts)
        // glob --> regexps
        let set = this.globParts.map((s, _, __) => {
          if (this.isWindows && this.windowsNoMagicRoot) {
            // check if it's a drive or unc path.
            const isUNC =
              s[0] === '' &&
              s[1] === '' &&
              (s[2] === '?' || !globMagic.test(s[2])) &&
              !globMagic.test(s[3])
            const isDrive = /^[a-z]:/i.test(s[0])
            if (isUNC) {
              return [...s.slice(0, 4), ...s.slice(4).map(ss => this.parse(ss))]
            } else if (isDrive) {
              return [s[0], ...s.slice(1).map(ss => this.parse(ss))]
            }
          }
          return s.map(ss => this.parse(ss))
        })
        this.debug(this.pattern, set)
        // filter out everything that didn't compile properly.
        this.set = set.filter(s => s.indexOf(false) === -1)
        // do not treat the ? in UNC paths as magic
        if (this.isWindows) {
          for (let i = 0; i < this.set.length; i++) {
            const p = this.set[i]
            if (
              p[0] === '' &&
              p[1] === '' &&
              this.globParts[i][2] === '?' &&
              typeof p[3] === 'string' &&
              /^[a-z]:$/i.test(p[3])
            ) {
              p[2] = '?'
            }
          }
        }
        this.debug(this.pattern, this.set)
      }
      // various transforms to equivalent pattern sets that are
      // faster to process in a filesystem walk.  The goal is to
      // eliminate what we can, and push all ** patterns as far
      // to the right as possible, even if it increases the number
      // of patterns that we have to process.
      preprocess(globParts) {
        // if we're not in globstar mode, then turn all ** into *
        if (this.options.noglobstar) {
          for (let i = 0; i < globParts.length; i++) {
            for (let j = 0; j < globParts[i].length; j++) {
              if (globParts[i][j] === '**') {
                globParts[i][j] = '*'
              }
            }
          }
        }
        const { optimizationLevel = 1 } = this.options
        if (optimizationLevel >= 2) {
          // aggressive optimization for the purpose of fs walking
          globParts = this.firstPhasePreProcess(globParts)
          globParts = this.secondPhasePreProcess(globParts)
        } else if (optimizationLevel >= 1) {
          // just basic optimizations to remove some .. parts
          globParts = this.levelOneOptimize(globParts)
        } else {
          // just collapse multiple ** portions into one
          globParts = this.adjascentGlobstarOptimize(globParts)
        }
        return globParts
      }
      // just get rid of adjascent ** portions
      adjascentGlobstarOptimize(globParts) {
        return globParts.map(parts => {
          let gs = -1
          while (-1 !== (gs = parts.indexOf('**', gs + 1))) {
            let i = gs
            while (parts[i + 1] === '**') {
              i++
            }
            if (i !== gs) {
              parts.splice(gs, i - gs)
            }
          }
          return parts
        })
      }
      // get rid of adjascent ** and resolve .. portions
      levelOneOptimize(globParts) {
        return globParts.map(parts => {
          parts = parts.reduce((set, part) => {
            const prev = set[set.length - 1]
            if (part === '**' && prev === '**') {
              return set
            }
            if (part === '..') {
              if (prev && prev !== '..' && prev !== '.' && prev !== '**') {
                set.pop()
                return set
              }
            }
            set.push(part)
            return set
          }, [])
          return parts.length === 0 ? [''] : parts
        })
      }
      levelTwoFileOptimize(parts) {
        if (!Array.isArray(parts)) {
          parts = this.slashSplit(parts)
        }
        let didSomething = false
        do {
          didSomething = false
          // <pre>/<e>/<rest> -> <pre>/<rest>
          if (!this.preserveMultipleSlashes) {
            for (let i = 1; i < parts.length - 1; i++) {
              const p = parts[i]
              // don't squeeze out UNC patterns
              if (i === 1 && p === '' && parts[0] === '') {
                continue
              }
              if (p === '.' || p === '') {
                didSomething = true
                parts.splice(i, 1)
                i--
              }
            }
            if (
              parts[0] === '.' &&
              parts.length === 2 &&
              (parts[1] === '.' || parts[1] === '')
            ) {
              didSomething = true
              parts.pop()
            }
          }
          // <pre>/<p>/../<rest> -> <pre>/<rest>
          let dd = 0
          while (-1 !== (dd = parts.indexOf('..', dd + 1))) {
            const p = parts[dd - 1]
            if (p && p !== '.' && p !== '..' && p !== '**') {
              didSomething = true
              parts.splice(dd - 1, 2)
              dd -= 2
            }
          }
        } while (didSomething)
        return parts.length === 0 ? [''] : parts
      }
      // First phase: single-pattern processing
      // <pre> is 1 or more portions
      // <rest> is 1 or more portions
      // <p> is any portion other than ., .., '', or **
      // <e> is . or ''
      //
      // **/.. is *brutal* for filesystem walking performance, because
      // it effectively resets the recursive walk each time it occurs,
      // and ** cannot be reduced out by a .. pattern part like a regexp
      // or most strings (other than .., ., and '') can be.
      //
      // <pre>/**/../<p>/<p>/<rest> -> {<pre>/../<p>/<p>/<rest>,<pre>/**/<p>/<p>/<rest>}
      // <pre>/<e>/<rest> -> <pre>/<rest>
      // <pre>/<p>/../<rest> -> <pre>/<rest>
      // **/**/<rest> -> **/<rest>
      //
      // **/*/<rest> -> */**/<rest> <== not valid because ** doesn't follow
      // this WOULD be allowed if ** did follow symlinks, or * didn't
      firstPhasePreProcess(globParts) {
        let didSomething = false
        do {
          didSomething = false
          // <pre>/**/../<p>/<p>/<rest> -> {<pre>/../<p>/<p>/<rest>,<pre>/**/<p>/<p>/<rest>}
          for (let parts of globParts) {
            let gs = -1
            while (-1 !== (gs = parts.indexOf('**', gs + 1))) {
              let gss = gs
              while (parts[gss + 1] === '**') {
                // <pre>/**/**/<rest> -> <pre>/**/<rest>
                gss++
              }
              // eg, if gs is 2 and gss is 4, that means we have 3 **
              // parts, and can remove 2 of them.
              if (gss > gs) {
                parts.splice(gs + 1, gss - gs)
              }
              let next = parts[gs + 1]
              const p = parts[gs + 2]
              const p2 = parts[gs + 3]
              if (next !== '..') {
                continue
              }
              if (
                !p ||
                p === '.' ||
                p === '..' ||
                !p2 ||
                p2 === '.' ||
                p2 === '..'
              ) {
                continue
              }
              didSomething = true
              // edit parts in place, and push the new one
              parts.splice(gs, 1)
              const other = parts.slice(0)
              other[gs] = '**'
              globParts.push(other)
              gs--
            }
            // <pre>/<e>/<rest> -> <pre>/<rest>
            if (!this.preserveMultipleSlashes) {
              for (let i = 1; i < parts.length - 1; i++) {
                const p = parts[i]
                // don't squeeze out UNC patterns
                if (i === 1 && p === '' && parts[0] === '') {
                  continue
                }
                if (p === '.' || p === '') {
                  didSomething = true
                  parts.splice(i, 1)
                  i--
                }
              }
              if (
                parts[0] === '.' &&
                parts.length === 2 &&
                (parts[1] === '.' || parts[1] === '')
              ) {
                didSomething = true
                parts.pop()
              }
            }
            // <pre>/<p>/../<rest> -> <pre>/<rest>
            let dd = 0
            while (-1 !== (dd = parts.indexOf('..', dd + 1))) {
              const p = parts[dd - 1]
              if (p && p !== '.' && p !== '..' && p !== '**') {
                didSomething = true
                const needDot = dd === 1 && parts[dd + 1] === '**'
                const splin = needDot ? ['.'] : []
                parts.splice(dd - 1, 2, ...splin)
                if (parts.length === 0) {
                  parts.push('')
                }
                dd -= 2
              }
            }
          }
        } while (didSomething)
        return globParts
      }
      // second phase: multi-pattern dedupes
      // {<pre>/*/<rest>,<pre>/<p>/<rest>} -> <pre>/*/<rest>
      // {<pre>/<rest>,<pre>/<rest>} -> <pre>/<rest>
      // {<pre>/**/<rest>,<pre>/<rest>} -> <pre>/**/<rest>
      //
      // {<pre>/**/<rest>,<pre>/**/<p>/<rest>} -> <pre>/**/<rest>
      // ^-- not valid because ** doens't follow symlinks
      secondPhasePreProcess(globParts) {
        for (let i = 0; i < globParts.length - 1; i++) {
          for (let j = i + 1; j < globParts.length; j++) {
            const matched = this.partsMatch(
              globParts[i],
              globParts[j],
              !this.preserveMultipleSlashes
            )
            if (matched) {
              globParts[i] = []
              globParts[j] = matched
              break
            }
          }
        }
        return globParts.filter(gs => gs.length)
      }
      partsMatch(a, b, emptyGSMatch = false) {
        let ai = 0
        let bi = 0
        let result = []
        let which = ''
        while (ai < a.length && bi < b.length) {
          if (a[ai] === b[bi]) {
            result.push(which === 'b' ? b[bi] : a[ai])
            ai++
            bi++
          } else if (emptyGSMatch && a[ai] === '**' && b[bi] === a[ai + 1]) {
            result.push(a[ai])
            ai++
          } else if (emptyGSMatch && b[bi] === '**' && a[ai] === b[bi + 1]) {
            result.push(b[bi])
            bi++
          } else if (
            a[ai] === '*' &&
            b[bi] &&
            (this.options.dot || !b[bi].startsWith('.')) &&
            b[bi] !== '**'
          ) {
            if (which === 'b') {
              return false
            }
            which = 'a'
            result.push(a[ai])
            ai++
            bi++
          } else if (
            b[bi] === '*' &&
            a[ai] &&
            (this.options.dot || !a[ai].startsWith('.')) &&
            a[ai] !== '**'
          ) {
            if (which === 'a') {
              return false
            }
            which = 'b'
            result.push(b[bi])
            ai++
            bi++
          } else {
            return false
          }
        }
        // if we fall out of the loop, it means they two are identical
        // as long as their lengths match
        return a.length === b.length && result
      }
      parseNegate() {
        if (this.nonegate) {
          return
        }
        const pattern = this.pattern
        let negate = false
        let negateOffset = 0
        for (let i = 0; i < pattern.length && pattern.charAt(i) === '!'; i++) {
          negate = !negate
          negateOffset++
        }
        if (negateOffset) {
          this.pattern = pattern.slice(negateOffset)
        }
        this.negate = negate
      }
      // set partial to true to test if, for example,
      // "/a/b" matches the start of "/*/b/*/d"
      // Partial means, if you run out of file before you run
      // out of pattern, then that's fine, as long as all
      // the parts match.
      matchOne(file, pattern, partial = false) {
        const options = this.options
        // UNC paths like //?/X:/... can match X:/... and vice versa
        // Drive letters in absolute drive or unc paths are always compared
        // case-insensitively.
        if (this.isWindows) {
          const fileDrive =
            typeof file[0] === 'string' && /^[a-z]:$/i.test(file[0])
          const fileUNC =
            !fileDrive &&
            file[0] === '' &&
            file[1] === '' &&
            file[2] === '?' &&
            /^[a-z]:$/i.test(file[3])
          const patternDrive =
            typeof pattern[0] === 'string' && /^[a-z]:$/i.test(pattern[0])
          const patternUNC =
            !patternDrive &&
            pattern[0] === '' &&
            pattern[1] === '' &&
            pattern[2] === '?' &&
            typeof pattern[3] === 'string' &&
            /^[a-z]:$/i.test(pattern[3])
          const fdi = fileUNC ? 3 : fileDrive ? 0 : undefined
          const pdi = patternUNC ? 3 : patternDrive ? 0 : undefined
          if (typeof fdi === 'number' && typeof pdi === 'number') {
            const [fd, pd] = [file[fdi], pattern[pdi]]
            if (fd.toLowerCase() === pd.toLowerCase()) {
              pattern[pdi] = fd
              if (pdi > fdi) {
                pattern = pattern.slice(pdi)
              } else if (fdi > pdi) {
                file = file.slice(fdi)
              }
            }
          }
        }
        // resolve and reduce . and .. portions in the file as well.
        // dont' need to do the second phase, because it's only one string[]
        const { optimizationLevel = 1 } = this.options
        if (optimizationLevel >= 2) {
          file = this.levelTwoFileOptimize(file)
        }
        this.debug('matchOne', this, {
          file,
          pattern
        })
        this.debug('matchOne', file.length, pattern.length)
        let fi = 0,
          pi = 0,
          fl = file.length,
          pl = pattern.length
        for (; fi < fl && pi < pl; fi++, pi++) {
          this.debug('matchOne loop')
          const p = pattern[pi]
          const f = file[fi]
          this.debug(pattern, p, f)
          // should be impossible.
          // some invalid regexp stuff in the set.
          /* c8 ignore start */
          if (p === false) {
            return false
          }
          /* c8 ignore stop */
          if (p === exports.GLOBSTAR) {
            this.debug('GLOBSTAR', [pattern, p, f])
            // "**"
            // a/**/b/**/c would match the following:
            // a/b/x/y/z/c
            // a/x/y/z/b/c
            // a/b/x/b/x/c
            // a/b/c
            // To do this, take the rest of the pattern after
            // the **, and see if it would match the file remainder.
            // If so, return success.
            // If not, the ** "swallows" a segment, and try again.
            // This is recursively awful.
            //
            // a/**/b/**/c matching a/b/x/y/z/c
            // - a matches a
            // - doublestar
            //   - matchOne(b/x/y/z/c, b/**/c)
            //     - b matches b
            //     - doublestar
            //       - matchOne(x/y/z/c, c) -> no
            //       - matchOne(y/z/c, c) -> no
            //       - matchOne(z/c, c) -> no
            //       - matchOne(c, c) yes, hit
            let fr = fi
            const pr = pi + 1
            if (pr === pl) {
              this.debug('** at the end')
              // a ** at the end will just swallow the rest.
              // We have found a match.
              // however, it will not swallow /.x, unless
              // options.dot is set.
              // . and .. are *never* matched by **, for explosively
              // exponential reasons.
              for (; fi < fl; fi++) {
                if (
                  file[fi] === '.' ||
                  file[fi] === '..' ||
                  (!options.dot && file[fi].charAt(0) === '.')
                ) {
                  return false
                }
              }
              return true
            }
            // ok, let's see if we can swallow whatever we can.
            while (fr < fl) {
              const swallowee = file[fr]
              this.debug('\nglobstar while', file, fr, pattern, pr, swallowee)
              // XXX remove this slice.  Just pass the start index.
              if (this.matchOne(file.slice(fr), pattern.slice(pr), partial)) {
                this.debug('globstar found match!', fr, fl, swallowee)
                // found a match.
                return true
              } else {
                // can't swallow "." or ".." ever.
                // can only swallow ".foo" when explicitly asked.
                if (
                  swallowee === '.' ||
                  swallowee === '..' ||
                  (!options.dot && swallowee.charAt(0) === '.')
                ) {
                  this.debug('dot detected!', file, fr, pattern, pr)
                  break
                }
                // ** swallows a segment, and continue.
                this.debug('globstar swallow a segment, and continue')
                fr++
              }
            }
            // no match was found.
            // However, in partial mode, we can't say this is necessarily over.
            /* c8 ignore start */
            if (partial) {
              // ran out of file
              this.debug('\n>>> no match, partial?', file, fr, pattern, pr)
              if (fr === fl) {
                return true
              }
            }
            /* c8 ignore stop */
            return false
          }
          // something other than **
          // non-magic patterns just have to match exactly
          // patterns with magic have been turned into regexps.
          let hit
          if (typeof p === 'string') {
            hit = f === p
            this.debug('string match', p, f, hit)
          } else {
            hit = p.test(f)
            this.debug('pattern match', p, f, hit)
          }
          if (!hit) {
            return false
          }
        }
        // Note: ending in / means that we'll get a final ""
        // at the end of the pattern.  This can only match a
        // corresponding "" at the end of the file.
        // If the file ends in /, then it can only match a
        // a pattern that ends in /, unless the pattern just
        // doesn't have any more for it. But, a/b/ should *not*
        // match "a/b/*", even though "" matches against the
        // [^/]*? pattern, except in partial mode, where it might
        // simply not be reached yet.
        // However, a/b/ should still satisfy a/*
        // now either we fell off the end of the pattern, or we're done.
        if (fi === fl && pi === pl) {
          // ran out of pattern and filename at the same time.
          // an exact hit!
          return true
        } else if (fi === fl) {
          // ran out of file, but still had pattern left.
          // this is ok if we're doing the match as part of
          // a glob fs traversal.
          return partial
        } else if (pi === pl) {
          // ran out of pattern, still have file left.
          // this is only acceptable if we're on the very last
          // empty segment of a file with a trailing slash.
          // a/* should match a/b/
          return fi === fl - 1 && file[fi] === ''
          /* c8 ignore start */
        } else {
          // should be unreachable.
          throw new Error('wtf?')
        }
        /* c8 ignore stop */
      }
      braceExpand() {
        return (0, exports.braceExpand)(this.pattern, this.options)
      }
      parse(pattern) {
        ;(0, assert_valid_pattern_js_1.assertValidPattern)(pattern)
        const options = this.options
        // shortcuts
        if (pattern === '**') {
          return exports.GLOBSTAR
        }
        if (pattern === '') {
          return ''
        }
        // far and away, the most common glob pattern parts are
        // *, *.*, and *.<ext>  Add a fast check method for those.
        let m
        let fastTest = null
        if ((m = pattern.match(starRE))) {
          fastTest = options.dot ? starTestDot : starTest
        } else if ((m = pattern.match(starDotExtRE))) {
          fastTest = (
            options.nocase
              ? options.dot
                ? starDotExtTestNocaseDot
                : starDotExtTestNocase
              : options.dot
                ? starDotExtTestDot
                : starDotExtTest
          )(m[1])
        } else if ((m = pattern.match(qmarksRE))) {
          fastTest = (
            options.nocase
              ? options.dot
                ? qmarksTestNocaseDot
                : qmarksTestNocase
              : options.dot
                ? qmarksTestDot
                : qmarksTest
          )(m)
        } else if ((m = pattern.match(starDotStarRE))) {
          fastTest = options.dot ? starDotStarTestDot : starDotStarTest
        } else if ((m = pattern.match(dotStarRE))) {
          fastTest = dotStarTest
        }
        const re = ast_js_1.AST.fromGlob(pattern, this.options).toMMPattern()
        if (fastTest && typeof re === 'object') {
          // Avoids overriding in frozen environments
          Reflect.defineProperty(re, 'test', {
            value: fastTest
          })
        }
        return re
      }
      makeRe() {
        if (this.regexp || this.regexp === false) {
          return this.regexp
        }
        // at this point, this.set is a 2d array of partial
        // pattern strings, or "**".
        //
        // It's better to use .match().  This function shouldn't
        // be used, really, but it's pretty convenient sometimes,
        // when you just want to work with a regex.
        const set = this.set
        if (!set.length) {
          this.regexp = false
          return this.regexp
        }
        const options = this.options
        const twoStar = options.noglobstar
          ? star
          : options.dot
            ? twoStarDot
            : twoStarNoDot
        const flags = new Set(options.nocase ? ['i'] : [])
        // regexpify non-globstar patterns
        // if ** is only item, then we just do one twoStar
        // if ** is first, and there are more, prepend (\/|twoStar\/)? to next
        // if ** is last, append (\/twoStar|) to previous
        // if ** is in the middle, append (\/|\/twoStar\/) to previous
        // then filter out GLOBSTAR symbols
        let re = set
          .map(pattern => {
            const pp = pattern.map(p => {
              if (p instanceof RegExp) {
                for (const f of p.flags.split('')) {
                  flags.add(f)
                }
              }
              return typeof p === 'string'
                ? regExpEscape(p)
                : p === exports.GLOBSTAR
                  ? exports.GLOBSTAR
                  : p._src
            })
            pp.forEach((p, i) => {
              const next = pp[i + 1]
              const prev = pp[i - 1]
              if (p !== exports.GLOBSTAR || prev === exports.GLOBSTAR) {
                return
              }
              if (prev === undefined) {
                if (next !== undefined && next !== exports.GLOBSTAR) {
                  pp[i + 1] = '(?:\\/|' + twoStar + '\\/)?' + next
                } else {
                  pp[i] = twoStar
                }
              } else if (next === undefined) {
                pp[i - 1] = prev + '(?:\\/|' + twoStar + ')?'
              } else if (next !== exports.GLOBSTAR) {
                pp[i - 1] = prev + '(?:\\/|\\/' + twoStar + '\\/)' + next
                pp[i + 1] = exports.GLOBSTAR
              }
            })
            return pp.filter(p => p !== exports.GLOBSTAR).join('/')
          })
          .join('|')
        // need to wrap in parens if we had more than one thing with |,
        // otherwise only the first will be anchored to ^ and the last to $
        const [open, close] = set.length > 1 ? ['(?:', ')'] : ['', '']
        // must match entire pattern
        // ending in a * or ** will make it less strict.
        re = '^' + open + re + close + '$'
        // can match anything, as long as it's not this.
        if (this.negate) {
          re = '^(?!' + re + ').+$'
        }
        try {
          this.regexp = new RegExp(re, [...flags].join(''))
          /* c8 ignore start */
        } catch (ex) {
          // should be impossible
          this.regexp = false
        }
        /* c8 ignore stop */
        return this.regexp
      }
      slashSplit(p) {
        // if p starts with // on windows, we preserve that
        // so that UNC paths aren't broken.  Otherwise, any number of
        // / characters are coalesced into one, unless
        // preserveMultipleSlashes is set to true.
        if (this.preserveMultipleSlashes) {
          return p.split('/')
        } else if (this.isWindows && /^\/\/[^/]+/.test(p)) {
          // add an extra '' for the one we lose
          return ['', ...p.split(/\/+/)]
        } else {
          return p.split(/\/+/)
        }
      }
      match(f, partial = this.partial) {
        this.debug('match', f, this.pattern)
        // short-circuit in the case of busted things.
        // comments, etc.
        if (this.comment) {
          return false
        }
        if (this.empty) {
          return f === ''
        }
        if (f === '/' && partial) {
          return true
        }
        const options = this.options
        // windows: need to use /, not \
        if (this.isWindows) {
          f = f.split('\\').join('/')
        }
        // treat the test path as a set of pathparts.
        const ff = this.slashSplit(f)
        this.debug(this.pattern, 'split', ff)
        // just ONE of the pattern sets in this.set needs to match
        // in order for it to be valid.  If negating, then just one
        // match means that we have failed.
        // Either way, return on the first hit.
        const set = this.set
        this.debug(this.pattern, 'set', set)
        // Find the basename of the path by looking for the last non-empty segment
        let filename = ff[ff.length - 1]
        if (!filename) {
          for (let i = ff.length - 2; !filename && i >= 0; i--) {
            filename = ff[i]
          }
        }
        for (let i = 0; i < set.length; i++) {
          const pattern = set[i]
          let file = ff
          if (options.matchBase && pattern.length === 1) {
            file = [filename]
          }
          const hit = this.matchOne(file, pattern, partial)
          if (hit) {
            if (options.flipNegate) {
              return true
            }
            return !this.negate
          }
        }
        // didn't get any hits.  this is success if it's a negative
        // pattern, failure otherwise.
        if (options.flipNegate) {
          return false
        }
        return this.negate
      }
      static defaults(def) {
        return exports.minimatch.defaults(def).Minimatch
      }
    }
    exports.Minimatch = Minimatch
    /* c8 ignore start */
    const ast_js_2 = requireAst()
    Object.defineProperty(exports, 'AST', {
      enumerable: true,
      get: function () {
        return ast_js_2.AST
      }
    })
    const escape_js_2 = require_escape$1()
    Object.defineProperty(exports, 'escape', {
      enumerable: true,
      get: function () {
        return escape_js_2.escape
      }
    })
    const unescape_js_2 = require_unescape()
    Object.defineProperty(exports, 'unescape', {
      enumerable: true,
      get: function () {
        return unescape_js_2.unescape
      }
    })
    /* c8 ignore stop */
    exports.minimatch.AST = ast_js_1.AST
    exports.minimatch.Minimatch = Minimatch
    exports.minimatch.escape = escape_js_1.escape
    exports.minimatch.unescape = unescape_js_1.unescape
  })(commonjs$2)
  return commonjs$2
}

const glob = {}

const commonjs$1 = {}

const commonjs = {}

let hasRequiredCommonjs$2
function requireCommonjs$2() {
  if (hasRequiredCommonjs$2) {
    return commonjs
  }
  hasRequiredCommonjs$2 = 1
  ;(function (exports) {
    const __importDefault =
      (this && this.__importDefault) ||
      function (mod) {
        return mod && mod.__esModule
          ? mod
          : {
              default: mod
            }
      }
    Object.defineProperty(exports, '__esModule', {
      value: true
    })
    exports.Minipass =
      exports.isWritable =
      exports.isReadable =
      exports.isStream =
        void 0
    const proc =
      typeof process === 'object' && process
        ? process
        : {
            stdout: null,
            stderr: null
          }
    const node_events_1 = require$$0$1
    const node_stream_1 = __importDefault(require$$1$2)
    const node_string_decoder_1 = require$$2$1
    /**
     * Return true if the argument is a Minipass stream, Node stream, or something
     * else that Minipass can interact with.
     */
    const isStream = s =>
      !!s &&
      typeof s === 'object' &&
      (s instanceof Minipass ||
        s instanceof node_stream_1.default ||
        (0, exports.isReadable)(s) ||
        (0, exports.isWritable)(s))
    exports.isStream = isStream
    /**
     * Return true if the argument is a valid {@link Minipass.Readable}
     */
    const isReadable = s =>
      !!s &&
      typeof s === 'object' &&
      s instanceof node_events_1.EventEmitter &&
      typeof s.pipe === 'function' &&
      // node core Writable streams have a pipe() method, but it throws
      s.pipe !== node_stream_1.default.Writable.prototype.pipe
    exports.isReadable = isReadable
    /**
     * Return true if the argument is a valid {@link Minipass.Writable}
     */
    const isWritable = s =>
      !!s &&
      typeof s === 'object' &&
      s instanceof node_events_1.EventEmitter &&
      typeof s.write === 'function' &&
      typeof s.end === 'function'
    exports.isWritable = isWritable
    const EOF = Symbol('EOF')
    const MAYBE_EMIT_END = Symbol('maybeEmitEnd')
    const EMITTED_END = Symbol('emittedEnd')
    const EMITTING_END = Symbol('emittingEnd')
    const EMITTED_ERROR = Symbol('emittedError')
    const CLOSED = Symbol('closed')
    const READ = Symbol('read')
    const FLUSH = Symbol('flush')
    const FLUSHCHUNK = Symbol('flushChunk')
    const ENCODING = Symbol('encoding')
    const DECODER = Symbol('decoder')
    const FLOWING = Symbol('flowing')
    const PAUSED = Symbol('paused')
    const RESUME = Symbol('resume')
    const BUFFER = Symbol('buffer')
    const PIPES = Symbol('pipes')
    const BUFFERLENGTH = Symbol('bufferLength')
    const BUFFERPUSH = Symbol('bufferPush')
    const BUFFERSHIFT = Symbol('bufferShift')
    const OBJECTMODE = Symbol('objectMode')
    // internal event when stream is destroyed
    const DESTROYED = Symbol('destroyed')
    // internal event when stream has an error
    const ERROR = Symbol('error')
    const EMITDATA = Symbol('emitData')
    const EMITEND = Symbol('emitEnd')
    const EMITEND2 = Symbol('emitEnd2')
    const ASYNC = Symbol('async')
    const ABORT = Symbol('abort')
    const ABORTED = Symbol('aborted')
    const SIGNAL = Symbol('signal')
    const DATALISTENERS = Symbol('dataListeners')
    const DISCARDED = Symbol('discarded')
    const defer = fn => Promise.resolve().then(fn)
    const nodefer = fn => fn()
    const isEndish = ev => ev === 'end' || ev === 'finish' || ev === 'prefinish'
    const isArrayBufferLike = b =>
      b instanceof ArrayBuffer ||
      (!!b &&
        typeof b === 'object' &&
        b.constructor &&
        b.constructor.name === 'ArrayBuffer' &&
        b.byteLength >= 0)
    const isArrayBufferView = b => !Buffer.isBuffer(b) && ArrayBuffer.isView(b)
    /**
     * Internal class representing a pipe to a destination stream.
     *
     * @internal
     */
    class Pipe {
      src
      dest
      opts
      ondrain
      constructor(src, dest, opts) {
        this.src = src
        this.dest = dest
        this.opts = opts
        this.ondrain = () => src[RESUME]()
        this.dest.on('drain', this.ondrain)
      }
      unpipe() {
        this.dest.removeListener('drain', this.ondrain)
      }
      // only here for the prototype
      /* c8 ignore start */
      proxyErrors(_er) {}
      /* c8 ignore stop */
      end() {
        this.unpipe()
        if (this.opts.end) {
          this.dest.end()
        }
      }
    }
    /**
     * Internal class representing a pipe to a destination stream where
     * errors are proxied.
     *
     * @internal
     */
    class PipeProxyErrors extends Pipe {
      unpipe() {
        this.src.removeListener('error', this.proxyErrors)
        super.unpipe()
      }
      constructor(src, dest, opts) {
        super(src, dest, opts)
        this.proxyErrors = er => dest.emit('error', er)
        src.on('error', this.proxyErrors)
      }
    }
    const isObjectModeOptions = o => !!o.objectMode
    const isEncodingOptions = o =>
      !o.objectMode && !!o.encoding && o.encoding !== 'buffer'
    /**
     * Main export, the Minipass class
     *
     * `RType` is the type of data emitted, defaults to Buffer
     *
     * `WType` is the type of data to be written, if RType is buffer or string,
     * then any {@link Minipass.ContiguousData} is allowed.
     *
     * `Events` is the set of event handler signatures that this object
     * will emit, see {@link Minipass.Events}
     */
    class Minipass extends node_events_1.EventEmitter {
      [FLOWING] = false;
      [PAUSED] = false;
      [PIPES] = [];
      [BUFFER] = [];
      [OBJECTMODE];
      [ENCODING];
      [ASYNC];
      [DECODER];
      [EOF] = false;
      [EMITTED_END] = false;
      [EMITTING_END] = false;
      [CLOSED] = false;
      [EMITTED_ERROR] = null;
      [BUFFERLENGTH] = 0;
      [DESTROYED] = false;
      [SIGNAL];
      [ABORTED] = false;
      [DATALISTENERS] = 0;
      [DISCARDED] = false
      /**
       * true if the stream can be written
       */
      writable = true
      /**
       * true if the stream can be read
       */
      readable = true
      /**
       * If `RType` is Buffer, then options do not need to be provided.
       * Otherwise, an options object must be provided to specify either
       * {@link Minipass.SharedOptions.objectMode} or
       * {@link Minipass.SharedOptions.encoding}, as appropriate.
       */
      constructor(...args) {
        const options = args[0] || {}
        super()
        if (options.objectMode && typeof options.encoding === 'string') {
          throw new TypeError(
            'Encoding and objectMode may not be used together'
          )
        }
        if (isObjectModeOptions(options)) {
          this[OBJECTMODE] = true
          this[ENCODING] = null
        } else if (isEncodingOptions(options)) {
          this[ENCODING] = options.encoding
          this[OBJECTMODE] = false
        } else {
          this[OBJECTMODE] = false
          this[ENCODING] = null
        }
        this[ASYNC] = !!options.async
        this[DECODER] = this[ENCODING]
          ? new node_string_decoder_1.StringDecoder(this[ENCODING])
          : null
        //@ts-ignore - private option for debugging and testing
        if (options && options.debugExposeBuffer === true) {
          Object.defineProperty(this, 'buffer', {
            get: () => this[BUFFER]
          })
        }
        //@ts-ignore - private option for debugging and testing
        if (options && options.debugExposePipes === true) {
          Object.defineProperty(this, 'pipes', {
            get: () => this[PIPES]
          })
        }
        const { signal } = options
        if (signal) {
          this[SIGNAL] = signal
          if (signal.aborted) {
            this[ABORT]()
          } else {
            signal.addEventListener('abort', () => this[ABORT]())
          }
        }
      }
      /**
       * The amount of data stored in the buffer waiting to be read.
       *
       * For Buffer strings, this will be the total byte length.
       * For string encoding streams, this will be the string character length,
       * according to JavaScript's `string.length` logic.
       * For objectMode streams, this is a count of the items waiting to be
       * emitted.
       */
      get bufferLength() {
        return this[BUFFERLENGTH]
      }
      /**
       * The `BufferEncoding` currently in use, or `null`
       */
      get encoding() {
        return this[ENCODING]
      }
      /**
       * @deprecated - This is a read only property
       */
      set encoding(_enc) {
        throw new Error('Encoding must be set at instantiation time')
      }
      /**
       * @deprecated - Encoding may only be set at instantiation time
       */
      setEncoding(_enc) {
        throw new Error('Encoding must be set at instantiation time')
      }
      /**
       * True if this is an objectMode stream
       */
      get objectMode() {
        return this[OBJECTMODE]
      }
      /**
       * @deprecated - This is a read-only property
       */
      set objectMode(_om) {
        throw new Error('objectMode must be set at instantiation time')
      }
      /**
       * true if this is an async stream
       */
      get ['async']() {
        return this[ASYNC]
      }
      /**
       * Set to true to make this stream async.
       *
       * Once set, it cannot be unset, as this would potentially cause incorrect
       * behavior.  Ie, a sync stream can be made async, but an async stream
       * cannot be safely made sync.
       */
      set ['async'](a) {
        this[ASYNC] = this[ASYNC] || !!a
      }
      // drop everything and get out of the flow completely
      [ABORT]() {
        this[ABORTED] = true
        this.emit('abort', this[SIGNAL]?.reason)
        this.destroy(this[SIGNAL]?.reason)
      }
      /**
       * True if the stream has been aborted.
       */
      get aborted() {
        return this[ABORTED]
      }
      /**
       * No-op setter. Stream aborted status is set via the AbortSignal provided
       * in the constructor options.
       */
      set aborted(_) {}
      write(chunk, encoding, cb) {
        if (this[ABORTED]) {
          return false
        }
        if (this[EOF]) {
          throw new Error('write after end')
        }
        if (this[DESTROYED]) {
          this.emit(
            'error',
            Object.assign(
              new Error('Cannot call write after a stream was destroyed'),
              {
                code: 'ERR_STREAM_DESTROYED'
              }
            )
          )
          return true
        }
        if (typeof encoding === 'function') {
          cb = encoding
          encoding = 'utf8'
        }
        if (!encoding) {
          encoding = 'utf8'
        }
        const fn = this[ASYNC] ? defer : nodefer
        // convert array buffers and typed array views into buffers
        // at some point in the future, we may want to do the opposite!
        // leave strings and buffers as-is
        // anything is only allowed if in object mode, so throw
        if (!this[OBJECTMODE] && !Buffer.isBuffer(chunk)) {
          if (isArrayBufferView(chunk)) {
            //@ts-ignore - sinful unsafe type changing
            chunk = Buffer.from(
              chunk.buffer,
              chunk.byteOffset,
              chunk.byteLength
            )
          } else if (isArrayBufferLike(chunk)) {
            //@ts-ignore - sinful unsafe type changing
            chunk = Buffer.from(chunk)
          } else if (typeof chunk !== 'string') {
            throw new Error(
              'Non-contiguous data written to non-objectMode stream'
            )
          }
        }
        // handle object mode up front, since it's simpler
        // this yields better performance, fewer checks later.
        if (this[OBJECTMODE]) {
          // maybe impossible?
          /* c8 ignore start */
          if (this[FLOWING] && this[BUFFERLENGTH] !== 0) {
            this[FLUSH](true)
          }
          /* c8 ignore stop */
          if (this[FLOWING]) {
            this.emit('data', chunk)
          } else {
            this[BUFFERPUSH](chunk)
          }
          if (this[BUFFERLENGTH] !== 0) {
            this.emit('readable')
          }
          if (cb) {
            fn(cb)
          }
          return this[FLOWING]
        }
        // at this point the chunk is a buffer or string
        // don't buffer it up or send it to the decoder
        if (!chunk.length) {
          if (this[BUFFERLENGTH] !== 0) {
            this.emit('readable')
          }
          if (cb) {
            fn(cb)
          }
          return this[FLOWING]
        }
        // fast-path writing strings of same encoding to a stream with
        // an empty buffer, skipping the buffer/decoder dance
        if (
          typeof chunk === 'string' &&
          // unless it is a string already ready for us to use
          !(encoding === this[ENCODING] && !this[DECODER]?.lastNeed)
        ) {
          //@ts-ignore - sinful unsafe type change
          chunk = Buffer.from(chunk, encoding)
        }
        if (Buffer.isBuffer(chunk) && this[ENCODING]) {
          //@ts-ignore - sinful unsafe type change
          chunk = this[DECODER].write(chunk)
        }
        // Note: flushing CAN potentially switch us into not-flowing mode
        if (this[FLOWING] && this[BUFFERLENGTH] !== 0) {
          this[FLUSH](true)
        }
        if (this[FLOWING]) {
          this.emit('data', chunk)
        } else {
          this[BUFFERPUSH](chunk)
        }
        if (this[BUFFERLENGTH] !== 0) {
          this.emit('readable')
        }
        if (cb) {
          fn(cb)
        }
        return this[FLOWING]
      }
      /**
       * Low-level explicit read method.
       *
       * In objectMode, the argument is ignored, and one item is returned if
       * available.
       *
       * `n` is the number of bytes (or in the case of encoding streams,
       * characters) to consume. If `n` is not provided, then the entire buffer
       * is returned, or `null` is returned if no data is available.
       *
       * If `n` is greater that the amount of data in the internal buffer,
       * then `null` is returned.
       */
      read(n) {
        if (this[DESTROYED]) {
          return null
        }
        this[DISCARDED] = false
        if (
          this[BUFFERLENGTH] === 0 ||
          n === 0 ||
          (n && n > this[BUFFERLENGTH])
        ) {
          this[MAYBE_EMIT_END]()
          return null
        }
        if (this[OBJECTMODE]) {
          n = null
        }
        if (this[BUFFER].length > 1 && !this[OBJECTMODE]) {
          // not object mode, so if we have an encoding, then RType is string
          // otherwise, must be Buffer
          this[BUFFER] = [
            this[ENCODING]
              ? this[BUFFER].join('')
              : Buffer.concat(this[BUFFER], this[BUFFERLENGTH])
          ]
        }
        const ret = this[READ](n || null, this[BUFFER][0])
        this[MAYBE_EMIT_END]()
        return ret
      }
      [READ](n, chunk) {
        if (this[OBJECTMODE]) {
          this[BUFFERSHIFT]()
        } else {
          const c = chunk
          if (n === c.length || n === null) {
            this[BUFFERSHIFT]()
          } else if (typeof c === 'string') {
            this[BUFFER][0] = c.slice(n)
            chunk = c.slice(0, n)
            this[BUFFERLENGTH] -= n
          } else {
            this[BUFFER][0] = c.subarray(n)
            chunk = c.subarray(0, n)
            this[BUFFERLENGTH] -= n
          }
        }
        this.emit('data', chunk)
        if (!this[BUFFER].length && !this[EOF]) {
          this.emit('drain')
        }
        return chunk
      }
      end(chunk, encoding, cb) {
        if (typeof chunk === 'function') {
          cb = chunk
          chunk = undefined
        }
        if (typeof encoding === 'function') {
          cb = encoding
          encoding = 'utf8'
        }
        if (chunk !== undefined) {
          this.write(chunk, encoding)
        }
        if (cb) {
          this.once('end', cb)
        }
        this[EOF] = true
        this.writable = false
        // if we haven't written anything, then go ahead and emit,
        // even if we're not reading.
        // we'll re-emit if a new 'end' listener is added anyway.
        // This makes MP more suitable to write-only use cases.
        if (this[FLOWING] || !this[PAUSED]) {
          this[MAYBE_EMIT_END]()
        }
        return this
      }
      // don't let the internal resume be overwritten
      [RESUME]() {
        if (this[DESTROYED]) {
          return
        }
        if (!this[DATALISTENERS] && !this[PIPES].length) {
          this[DISCARDED] = true
        }
        this[PAUSED] = false
        this[FLOWING] = true
        this.emit('resume')
        if (this[BUFFER].length) {
          this[FLUSH]()
        } else if (this[EOF]) {
          this[MAYBE_EMIT_END]()
        } else {
          this.emit('drain')
        }
      }
      /**
       * Resume the stream if it is currently in a paused state
       *
       * If called when there are no pipe destinations or `data` event listeners,
       * this will place the stream in a "discarded" state, where all data will
       * be thrown away. The discarded state is removed if a pipe destination or
       * data handler is added, if pause() is called, or if any synchronous or
       * asynchronous iteration is started.
       */
      resume() {
        return this[RESUME]()
      }
      /**
       * Pause the stream
       */
      pause() {
        this[FLOWING] = false
        this[PAUSED] = true
        this[DISCARDED] = false
      }
      /**
       * true if the stream has been forcibly destroyed
       */
      get destroyed() {
        return this[DESTROYED]
      }
      /**
       * true if the stream is currently in a flowing state, meaning that
       * any writes will be immediately emitted.
       */
      get flowing() {
        return this[FLOWING]
      }
      /**
       * true if the stream is currently in a paused state
       */
      get paused() {
        return this[PAUSED]
      }
      [BUFFERPUSH](chunk) {
        if (this[OBJECTMODE]) {
          this[BUFFERLENGTH] += 1
        } else {
          this[BUFFERLENGTH] += chunk.length
        }
        this[BUFFER].push(chunk)
      }
      [BUFFERSHIFT]() {
        if (this[OBJECTMODE]) {
          this[BUFFERLENGTH] -= 1
        } else {
          this[BUFFERLENGTH] -= this[BUFFER][0].length
        }
        return this[BUFFER].shift()
      }
      [FLUSH](noDrain = false) {
        do {} while (
          this[FLUSHCHUNK](this[BUFFERSHIFT]()) &&
          this[BUFFER].length
        )
        if (!noDrain && !this[BUFFER].length && !this[EOF]) {
          this.emit('drain')
        }
      }
      [FLUSHCHUNK](chunk) {
        this.emit('data', chunk)
        return this[FLOWING]
      }
      /**
       * Pipe all data emitted by this stream into the destination provided.
       *
       * Triggers the flow of data.
       */
      pipe(dest, opts) {
        if (this[DESTROYED]) {
          return dest
        }
        this[DISCARDED] = false
        const ended = this[EMITTED_END]
        opts = opts || {}
        if (dest === proc.stdout || dest === proc.stderr) {
          opts.end = false
        } else {
          opts.end = opts.end !== false
        }
        opts.proxyErrors = !!opts.proxyErrors
        // piping an ended stream ends immediately
        if (ended) {
          if (opts.end) {
            dest.end()
          }
        } else {
          // "as" here just ignores the WType, which pipes don't care about,
          // since they're only consuming from us, and writing to the dest
          this[PIPES].push(
            !opts.proxyErrors
              ? new Pipe(this, dest, opts)
              : new PipeProxyErrors(this, dest, opts)
          )
          if (this[ASYNC]) {
            defer(() => this[RESUME]())
          } else {
            this[RESUME]()
          }
        }
        return dest
      }
      /**
       * Fully unhook a piped destination stream.
       *
       * If the destination stream was the only consumer of this stream (ie,
       * there are no other piped destinations or `'data'` event listeners)
       * then the flow of data will stop until there is another consumer or
       * {@link Minipass#resume} is explicitly called.
       */
      unpipe(dest) {
        const p = this[PIPES].find(p => p.dest === dest)
        if (p) {
          if (this[PIPES].length === 1) {
            if (this[FLOWING] && this[DATALISTENERS] === 0) {
              this[FLOWING] = false
            }
            this[PIPES] = []
          } else {
            this[PIPES].splice(this[PIPES].indexOf(p), 1)
          }
          p.unpipe()
        }
      }
      /**
       * Alias for {@link Minipass#on}
       */
      addListener(ev, handler) {
        return this.on(ev, handler)
      }
      /**
       * Mostly identical to `EventEmitter.on`, with the following
       * behavior differences to prevent data loss and unnecessary hangs:
       *
       * - Adding a 'data' event handler will trigger the flow of data
       *
       * - Adding a 'readable' event handler when there is data waiting to be read
       *   will cause 'readable' to be emitted immediately.
       *
       * - Adding an 'endish' event handler ('end', 'finish', etc.) which has
       *   already passed will cause the event to be emitted immediately and all
       *   handlers removed.
       *
       * - Adding an 'error' event handler after an error has been emitted will
       *   cause the event to be re-emitted immediately with the error previously
       *   raised.
       */
      on(ev, handler) {
        const ret = super.on(ev, handler)
        if (ev === 'data') {
          this[DISCARDED] = false
          this[DATALISTENERS]++
          if (!this[PIPES].length && !this[FLOWING]) {
            this[RESUME]()
          }
        } else if (ev === 'readable' && this[BUFFERLENGTH] !== 0) {
          super.emit('readable')
        } else if (isEndish(ev) && this[EMITTED_END]) {
          super.emit(ev)
          this.removeAllListeners(ev)
        } else if (ev === 'error' && this[EMITTED_ERROR]) {
          const h = handler
          if (this[ASYNC]) {
            defer(() => h.call(this, this[EMITTED_ERROR]))
          } else {
            h.call(this, this[EMITTED_ERROR])
          }
        }
        return ret
      }
      /**
       * Alias for {@link Minipass#off}
       */
      removeListener(ev, handler) {
        return this.off(ev, handler)
      }
      /**
       * Mostly identical to `EventEmitter.off`
       *
       * If a 'data' event handler is removed, and it was the last consumer
       * (ie, there are no pipe destinations or other 'data' event listeners),
       * then the flow of data will stop until there is another consumer or
       * {@link Minipass#resume} is explicitly called.
       */
      off(ev, handler) {
        const ret = super.off(ev, handler)
        // if we previously had listeners, and now we don't, and we don't
        // have any pipes, then stop the flow, unless it's been explicitly
        // put in a discarded flowing state via stream.resume().
        if (ev === 'data') {
          this[DATALISTENERS] = this.listeners('data').length
          if (
            this[DATALISTENERS] === 0 &&
            !this[DISCARDED] &&
            !this[PIPES].length
          ) {
            this[FLOWING] = false
          }
        }
        return ret
      }
      /**
       * Mostly identical to `EventEmitter.removeAllListeners`
       *
       * If all 'data' event handlers are removed, and they were the last consumer
       * (ie, there are no pipe destinations), then the flow of data will stop
       * until there is another consumer or {@link Minipass#resume} is explicitly
       * called.
       */
      removeAllListeners(ev) {
        const ret = super.removeAllListeners(ev)
        if (ev === 'data' || ev === undefined) {
          this[DATALISTENERS] = 0
          if (!this[DISCARDED] && !this[PIPES].length) {
            this[FLOWING] = false
          }
        }
        return ret
      }
      /**
       * true if the 'end' event has been emitted
       */
      get emittedEnd() {
        return this[EMITTED_END]
      }
      [MAYBE_EMIT_END]() {
        if (
          !this[EMITTING_END] &&
          !this[EMITTED_END] &&
          !this[DESTROYED] &&
          this[BUFFER].length === 0 &&
          this[EOF]
        ) {
          this[EMITTING_END] = true
          this.emit('end')
          this.emit('prefinish')
          this.emit('finish')
          if (this[CLOSED]) {
            this.emit('close')
          }
          this[EMITTING_END] = false
        }
      }
      /**
       * Mostly identical to `EventEmitter.emit`, with the following
       * behavior differences to prevent data loss and unnecessary hangs:
       *
       * If the stream has been destroyed, and the event is something other
       * than 'close' or 'error', then `false` is returned and no handlers
       * are called.
       *
       * If the event is 'end', and has already been emitted, then the event
       * is ignored. If the stream is in a paused or non-flowing state, then
       * the event will be deferred until data flow resumes. If the stream is
       * async, then handlers will be called on the next tick rather than
       * immediately.
       *
       * If the event is 'close', and 'end' has not yet been emitted, then
       * the event will be deferred until after 'end' is emitted.
       *
       * If the event is 'error', and an AbortSignal was provided for the stream,
       * and there are no listeners, then the event is ignored, matching the
       * behavior of node core streams in the presense of an AbortSignal.
       *
       * If the event is 'finish' or 'prefinish', then all listeners will be
       * removed after emitting the event, to prevent double-firing.
       */
      emit(ev, ...args) {
        const data = args[0]
        // error and close are only events allowed after calling destroy()
        if (
          ev !== 'error' &&
          ev !== 'close' &&
          ev !== DESTROYED &&
          this[DESTROYED]
        ) {
          return false
        } else if (ev === 'data') {
          return !this[OBJECTMODE] && !data
            ? false
            : this[ASYNC]
              ? (defer(() => this[EMITDATA](data)), true)
              : this[EMITDATA](data)
        } else if (ev === 'end') {
          return this[EMITEND]()
        } else if (ev === 'close') {
          this[CLOSED] = true
          // don't emit close before 'end' and 'finish'
          if (!this[EMITTED_END] && !this[DESTROYED]) {
            return false
          }
          const ret = super.emit('close')
          this.removeAllListeners('close')
          return ret
        } else if (ev === 'error') {
          this[EMITTED_ERROR] = data
          super.emit(ERROR, data)
          const ret =
            !this[SIGNAL] || this.listeners('error').length
              ? super.emit('error', data)
              : false
          this[MAYBE_EMIT_END]()
          return ret
        } else if (ev === 'resume') {
          const ret = super.emit('resume')
          this[MAYBE_EMIT_END]()
          return ret
        } else if (ev === 'finish' || ev === 'prefinish') {
          const ret = super.emit(ev)
          this.removeAllListeners(ev)
          return ret
        }
        // Some other unknown event
        const ret = super.emit(ev, ...args)
        this[MAYBE_EMIT_END]()
        return ret
      }
      [EMITDATA](data) {
        for (const p of this[PIPES]) {
          if (p.dest.write(data) === false) {
            this.pause()
          }
        }
        const ret = this[DISCARDED] ? false : super.emit('data', data)
        this[MAYBE_EMIT_END]()
        return ret
      }
      [EMITEND]() {
        if (this[EMITTED_END]) {
          return false
        }
        this[EMITTED_END] = true
        this.readable = false
        return this[ASYNC]
          ? (defer(() => this[EMITEND2]()), true)
          : this[EMITEND2]()
      }
      [EMITEND2]() {
        if (this[DECODER]) {
          const data = this[DECODER].end()
          if (data) {
            for (const p of this[PIPES]) {
              p.dest.write(data)
            }
            if (!this[DISCARDED]) {
              super.emit('data', data)
            }
          }
        }
        for (const p of this[PIPES]) {
          p.end()
        }
        const ret = super.emit('end')
        this.removeAllListeners('end')
        return ret
      }
      /**
       * Return a Promise that resolves to an array of all emitted data once
       * the stream ends.
       */
      async collect() {
        const buf = Object.assign([], {
          dataLength: 0
        })
        if (!this[OBJECTMODE]) {
          buf.dataLength = 0
        }
        // set the promise first, in case an error is raised
        // by triggering the flow here.
        const p = this.promise()
        this.on('data', c => {
          buf.push(c)
          if (!this[OBJECTMODE]) {
            buf.dataLength += c.length
          }
        })
        await p
        return buf
      }
      /**
       * Return a Promise that resolves to the concatenation of all emitted data
       * once the stream ends.
       *
       * Not allowed on objectMode streams.
       */
      async concat() {
        if (this[OBJECTMODE]) {
          throw new Error('cannot concat in objectMode')
        }
        const buf = await this.collect()
        return this[ENCODING]
          ? buf.join('')
          : Buffer.concat(buf, buf.dataLength)
      }
      /**
       * Return a void Promise that resolves once the stream ends.
       */
      async promise() {
        return new Promise((resolve, reject) => {
          this.on(DESTROYED, () => reject(new Error('stream destroyed')))
          this.on('error', er => reject(er))
          this.on('end', () => resolve())
        })
      }
      /**
       * Asynchronous `for await of` iteration.
       *
       * This will continue emitting all chunks until the stream terminates.
       */
      [Symbol.asyncIterator]() {
        // set this up front, in case the consumer doesn't call next()
        // right away.
        this[DISCARDED] = false
        let stopped = false
        const stop = async () => {
          this.pause()
          stopped = true
          return {
            value: undefined,
            done: true
          }
        }
        const next = () => {
          if (stopped) {
            return stop()
          }
          const res = this.read()
          if (res !== null) {
            return Promise.resolve({
              done: false,
              value: res
            })
          }
          if (this[EOF]) {
            return stop()
          }
          let resolve
          let reject
          const onerr = er => {
            this.off('data', ondata)
            this.off('end', onend)
            this.off(DESTROYED, ondestroy)
            stop()
            reject(er)
          }
          const ondata = value => {
            this.off('error', onerr)
            this.off('end', onend)
            this.off(DESTROYED, ondestroy)
            this.pause()
            resolve({
              value,
              done: !!this[EOF]
            })
          }
          const onend = () => {
            this.off('error', onerr)
            this.off('data', ondata)
            this.off(DESTROYED, ondestroy)
            stop()
            resolve({
              done: true,
              value: undefined
            })
          }
          const ondestroy = () => onerr(new Error('stream destroyed'))
          return new Promise((res, rej) => {
            reject = rej
            resolve = res
            this.once(DESTROYED, ondestroy)
            this.once('error', onerr)
            this.once('end', onend)
            this.once('data', ondata)
          })
        }
        return {
          next,
          throw: stop,
          return: stop,
          [Symbol.asyncIterator]() {
            return this
          }
        }
      }
      /**
       * Synchronous `for of` iteration.
       *
       * The iteration will terminate when the internal buffer runs out, even
       * if the stream has not yet terminated.
       */
      [Symbol.iterator]() {
        // set this up front, in case the consumer doesn't call next()
        // right away.
        this[DISCARDED] = false
        let stopped = false
        const stop = () => {
          this.pause()
          this.off(ERROR, stop)
          this.off(DESTROYED, stop)
          this.off('end', stop)
          stopped = true
          return {
            done: true,
            value: undefined
          }
        }
        const next = () => {
          if (stopped) {
            return stop()
          }
          const value = this.read()
          return value === null
            ? stop()
            : {
                done: false,
                value
              }
        }
        this.once('end', stop)
        this.once(ERROR, stop)
        this.once(DESTROYED, stop)
        return {
          next,
          throw: stop,
          return: stop,
          [Symbol.iterator]() {
            return this
          }
        }
      }
      /**
       * Destroy a stream, preventing it from being used for any further purpose.
       *
       * If the stream has a `close()` method, then it will be called on
       * destruction.
       *
       * After destruction, any attempt to write data, read data, or emit most
       * events will be ignored.
       *
       * If an error argument is provided, then it will be emitted in an
       * 'error' event.
       */
      destroy(er) {
        if (this[DESTROYED]) {
          if (er) {
            this.emit('error', er)
          } else {
            this.emit(DESTROYED)
          }
          return this
        }
        this[DESTROYED] = true
        this[DISCARDED] = true
        // throw away all buffered data, it's never coming out
        this[BUFFER].length = 0
        this[BUFFERLENGTH] = 0
        const wc = this
        if (typeof wc.close === 'function' && !this[CLOSED]) {
          wc.close()
        }
        if (er) {
          this.emit('error', er)
        }
        // if no error to emit, still reject pending promises
        else {
          this.emit(DESTROYED)
        }
        return this
      }
      /**
       * Alias for {@link isStream}
       *
       * Former export location, maintained for backwards compatibility.
       *
       * @deprecated
       */
      static get isStream() {
        return exports.isStream
      }
    }
    exports.Minipass = Minipass
  })(commonjs)
  return commonjs
}

let hasRequiredCommonjs$1
function requireCommonjs$1() {
  if (hasRequiredCommonjs$1) {
    return commonjs$1
  }
  hasRequiredCommonjs$1 = 1
  const __createBinding =
    (this && this.__createBinding) ||
    (Object.create
      ? function (o, m, k, k2) {
          if (k2 === undefined) {
            k2 = k
          }
          let desc = Object.getOwnPropertyDescriptor(m, k)
          if (
            !desc ||
            ('get' in desc ? !m.__esModule : desc.writable || desc.configurable)
          ) {
            desc = {
              enumerable: true,
              get: function () {
                return m[k]
              }
            }
          }
          Object.defineProperty(o, k2, desc)
        }
      : function (o, m, k, k2) {
          if (k2 === undefined) {
            k2 = k
          }
          o[k2] = m[k]
        })
  const __setModuleDefault =
    (this && this.__setModuleDefault) ||
    (Object.create
      ? function (o, v) {
          Object.defineProperty(o, 'default', {
            enumerable: true,
            value: v
          })
        }
      : function (o, v) {
          o['default'] = v
        })
  const __importStar =
    (this && this.__importStar) ||
    function (mod) {
      if (mod && mod.__esModule) {
        return mod
      }
      const result = {}
      if (mod != null) {
        for (var k in mod)
          if (k !== 'default' && Object.prototype.hasOwnProperty.call(mod, k))
            __createBinding(result, mod, k)
      }
      __setModuleDefault(result, mod)
      return result
    }
  Object.defineProperty(commonjs$1, '__esModule', {
    value: true
  })
  commonjs$1.PathScurry =
    commonjs$1.Path =
    commonjs$1.PathScurryDarwin =
    commonjs$1.PathScurryPosix =
    commonjs$1.PathScurryWin32 =
    commonjs$1.PathScurryBase =
    commonjs$1.PathPosix =
    commonjs$1.PathWin32 =
    commonjs$1.PathBase =
    commonjs$1.ChildrenCache =
    commonjs$1.ResolveCache =
      void 0
  const lru_cache_1 = /*@__PURE__*/ requireCommonjs$4()
  const node_path_1 = require$$2$2
  const node_url_1 = require$$0$3
  const fs_1 = require$$0$2
  const actualFS = __importStar(require$$4)
  const realpathSync = fs_1.realpathSync.native
  // TODO: test perf of fs/promises realpath vs realpathCB,
  // since the promises one uses realpath.native
  const promises_1 = require$$5
  const minipass_1 = requireCommonjs$2()
  const defaultFS = {
    lstatSync: fs_1.lstatSync,
    readdir: fs_1.readdir,
    readdirSync: fs_1.readdirSync,
    readlinkSync: fs_1.readlinkSync,
    realpathSync,
    promises: {
      lstat: promises_1.lstat,
      readdir: promises_1.readdir,
      readlink: promises_1.readlink,
      realpath: promises_1.realpath
    }
  }
  // if they just gave us require('fs') then use our default
  const fsFromOption = fsOption =>
    !fsOption || fsOption === defaultFS || fsOption === actualFS
      ? defaultFS
      : {
          ...defaultFS,
          ...fsOption,
          promises: {
            ...defaultFS.promises,
            ...fsOption.promises
          }
        }
  // turn something like //?/c:/ into c:\
  const uncDriveRegexp = /^\\\\\?\\([a-z]:)\\?$/i
  const uncToDrive = rootPath =>
    rootPath.replace(/\//g, '\\').replace(uncDriveRegexp, '$1\\')
  // windows paths are separated by either / or \
  const eitherSep = /[\\/]/
  const UNKNOWN = 0 // may not even exist, for all we know
  const IFIFO = 0b0001
  const IFCHR = 0b0010
  const IFDIR = 0b0100
  const IFBLK = 0b0110
  const IFREG = 0b1000
  const IFLNK = 0b1010
  const IFSOCK = 0b1100
  const IFMT = 0b1111
  // mask to unset low 4 bits
  const IFMT_UNKNOWN = ~IFMT
  // set after successfully calling readdir() and getting entries.
  const READDIR_CALLED = 0b0000_0001_0000
  // set after a successful lstat()
  const LSTAT_CALLED = 0b0000_0010_0000
  // set if an entry (or one of its parents) is definitely not a dir
  const ENOTDIR = 0b0000_0100_0000
  // set if an entry (or one of its parents) does not exist
  // (can also be set on lstat errors like EACCES or ENAMETOOLONG)
  const ENOENT = 0b0000_1000_0000
  // cannot have child entries -- also verify &IFMT is either IFDIR or IFLNK
  // set if we fail to readlink
  const ENOREADLINK = 0b0001_0000_0000
  // set if we know realpath() will fail
  const ENOREALPATH = 0b0010_0000_0000
  const ENOCHILD = ENOTDIR | ENOENT | ENOREALPATH
  const TYPEMASK = 0b0011_1111_1111
  const entToType = s =>
    s.isFile()
      ? IFREG
      : s.isDirectory()
        ? IFDIR
        : s.isSymbolicLink()
          ? IFLNK
          : s.isCharacterDevice()
            ? IFCHR
            : s.isBlockDevice()
              ? IFBLK
              : s.isSocket()
                ? IFSOCK
                : s.isFIFO()
                  ? IFIFO
                  : UNKNOWN
  // normalize unicode path names
  const normalizeCache = new Map()
  const normalize = s => {
    const c = normalizeCache.get(s)
    if (c) {
      return c
    }
    const n = s.normalize('NFKD')
    normalizeCache.set(s, n)
    return n
  }
  const normalizeNocaseCache = new Map()
  const normalizeNocase = s => {
    const c = normalizeNocaseCache.get(s)
    if (c) {
      return c
    }
    const n = normalize(s.toLowerCase())
    normalizeNocaseCache.set(s, n)
    return n
  }
  /**
   * An LRUCache for storing resolved path strings or Path objects.
   * @internal
   */
  class ResolveCache extends lru_cache_1.LRUCache {
    constructor() {
      super({
        max: 256
      })
    }
  }
  commonjs$1.ResolveCache = ResolveCache
  // In order to prevent blowing out the js heap by allocating hundreds of
  // thousands of Path entries when walking extremely large trees, the "children"
  // in this tree are represented by storing an array of Path entries in an
  // LRUCache, indexed by the parent.  At any time, Path.children() may return an
  // empty array, indicating that it doesn't know about any of its children, and
  // thus has to rebuild that cache.  This is fine, it just means that we don't
  // benefit as much from having the cached entries, but huge directory walks
  // don't blow out the stack, and smaller ones are still as fast as possible.
  //
  //It does impose some complexity when building up the readdir data, because we
  //need to pass a reference to the children array that we started with.
  /**
   * an LRUCache for storing child entries.
   * @internal
   */
  class ChildrenCache extends lru_cache_1.LRUCache {
    constructor(maxSize = 16 * 1024) {
      super({
        maxSize,
        // parent + children
        sizeCalculation: a => a.length + 1
      })
    }
  }
  commonjs$1.ChildrenCache = ChildrenCache
  const setAsCwd = Symbol('PathScurry setAsCwd')
  /**
   * Path objects are sort of like a super-powered
   * {@link https://nodejs.org/docs/latest/api/fs.html#class-fsdirent fs.Dirent}
   *
   * Each one represents a single filesystem entry on disk, which may or may not
   * exist. It includes methods for reading various types of information via
   * lstat, readlink, and readdir, and caches all information to the greatest
   * degree possible.
   *
   * Note that fs operations that would normally throw will instead return an
   * "empty" value. This is in order to prevent excessive overhead from error
   * stack traces.
   */
  class PathBase {
    /**
     * the basename of this path
     *
     * **Important**: *always* test the path name against any test string
     * usingthe {@link isNamed} method, and not by directly comparing this
     * string. Otherwise, unicode path strings that the system sees as identical
     * will not be properly treated as the same path, leading to incorrect
     * behavior and possible security issues.
     */
    name
    /**
     * the Path entry corresponding to the path root.
     *
     * @internal
     */
    root
    /**
     * All roots found within the current PathScurry family
     *
     * @internal
     */
    roots
    /**
     * a reference to the parent path, or undefined in the case of root entries
     *
     * @internal
     */
    parent
    /**
     * boolean indicating whether paths are compared case-insensitively
     * @internal
     */
    nocase
    /**
     * boolean indicating that this path is the current working directory
     * of the PathScurry collection that contains it.
     */
    isCWD = false
    // potential default fs override
    #fs
    // Stats fields
    #dev
    get dev() {
      return this.#dev
    }
    #mode
    get mode() {
      return this.#mode
    }
    #nlink
    get nlink() {
      return this.#nlink
    }
    #uid
    get uid() {
      return this.#uid
    }
    #gid
    get gid() {
      return this.#gid
    }
    #rdev
    get rdev() {
      return this.#rdev
    }
    #blksize
    get blksize() {
      return this.#blksize
    }
    #ino
    get ino() {
      return this.#ino
    }
    #size
    get size() {
      return this.#size
    }
    #blocks
    get blocks() {
      return this.#blocks
    }
    #atimeMs
    get atimeMs() {
      return this.#atimeMs
    }
    #mtimeMs
    get mtimeMs() {
      return this.#mtimeMs
    }
    #ctimeMs
    get ctimeMs() {
      return this.#ctimeMs
    }
    #birthtimeMs
    get birthtimeMs() {
      return this.#birthtimeMs
    }
    #atime
    get atime() {
      return this.#atime
    }
    #mtime
    get mtime() {
      return this.#mtime
    }
    #ctime
    get ctime() {
      return this.#ctime
    }
    #birthtime
    get birthtime() {
      return this.#birthtime
    }
    #matchName
    #depth
    #fullpath
    #fullpathPosix
    #relative
    #relativePosix
    #type
    #children
    #linkTarget
    #realpath
    /**
     * This property is for compatibility with the Dirent class as of
     * Node v20, where Dirent['parentPath'] refers to the path of the
     * directory that was passed to readdir. For root entries, it's the path
     * to the entry itself.
     */
    get parentPath() {
      return (this.parent || this).fullpath()
    }
    /**
     * Deprecated alias for Dirent['parentPath'] Somewhat counterintuitively,
     * this property refers to the *parent* path, not the path object itself.
     */
    get path() {
      return this.parentPath
    }
    /**
     * Do not create new Path objects directly.  They should always be accessed
     * via the PathScurry class or other methods on the Path class.
     *
     * @internal
     */
    constructor(name, type = UNKNOWN, root, roots, nocase, children, opts) {
      this.name = name
      this.#matchName = nocase ? normalizeNocase(name) : normalize(name)
      this.#type = type & TYPEMASK
      this.nocase = nocase
      this.roots = roots
      this.root = root || this
      this.#children = children
      this.#fullpath = opts.fullpath
      this.#relative = opts.relative
      this.#relativePosix = opts.relativePosix
      this.parent = opts.parent
      if (this.parent) {
        this.#fs = this.parent.#fs
      } else {
        this.#fs = fsFromOption(opts.fs)
      }
    }
    /**
     * Returns the depth of the Path object from its root.
     *
     * For example, a path at `/foo/bar` would have a depth of 2.
     */
    depth() {
      if (this.#depth !== undefined) {
        return this.#depth
      }
      if (!this.parent) {
        return (this.#depth = 0)
      }
      return (this.#depth = this.parent.depth() + 1)
    }
    /**
     * @internal
     */
    childrenCache() {
      return this.#children
    }
    /**
     * Get the Path object referenced by the string path, resolved from this Path
     */
    resolve(path) {
      if (!path) {
        return this
      }
      const rootPath = this.getRootString(path)
      const dir = path.substring(rootPath.length)
      const dirParts = dir.split(this.splitSep)
      const result = rootPath
        ? this.getRoot(rootPath).#resolveParts(dirParts)
        : this.#resolveParts(dirParts)
      return result
    }
    #resolveParts(dirParts) {
      let p = this
      for (const part of dirParts) {
        p = p.child(part)
      }
      return p
    }
    /**
     * Returns the cached children Path objects, if still available.  If they
     * have fallen out of the cache, then returns an empty array, and resets the
     * READDIR_CALLED bit, so that future calls to readdir() will require an fs
     * lookup.
     *
     * @internal
     */
    children() {
      const cached = this.#children.get(this)
      if (cached) {
        return cached
      }
      const children = Object.assign([], {
        provisional: 0
      })
      this.#children.set(this, children)
      this.#type &= ~READDIR_CALLED
      return children
    }
    /**
     * Resolves a path portion and returns or creates the child Path.
     *
     * Returns `this` if pathPart is `''` or `'.'`, or `parent` if pathPart is
     * `'..'`.
     *
     * This should not be called directly.  If `pathPart` contains any path
     * separators, it will lead to unsafe undefined behavior.
     *
     * Use `Path.resolve()` instead.
     *
     * @internal
     */
    child(pathPart, opts) {
      if (pathPart === '' || pathPart === '.') {
        return this
      }
      if (pathPart === '..') {
        return this.parent || this
      }
      // find the child
      const children = this.children()
      const name = this.nocase ? normalizeNocase(pathPart) : normalize(pathPart)
      for (const p of children) {
        if (p.#matchName === name) {
          return p
        }
      }
      // didn't find it, create provisional child, since it might not
      // actually exist.  If we know the parent isn't a dir, then
      // in fact it CAN'T exist.
      const s = this.parent ? this.sep : ''
      const fullpath = this.#fullpath
        ? this.#fullpath + s + pathPart
        : undefined
      const pchild = this.newChild(pathPart, UNKNOWN, {
        ...opts,
        parent: this,
        fullpath
      })
      if (!this.canReaddir()) {
        pchild.#type |= ENOENT
      }
      // don't have to update provisional, because if we have real children,
      // then provisional is set to children.length, otherwise a lower number
      children.push(pchild)
      return pchild
    }
    /**
     * The relative path from the cwd. If it does not share an ancestor with
     * the cwd, then this ends up being equivalent to the fullpath()
     */
    relative() {
      if (this.isCWD) {
        return ''
      }
      if (this.#relative !== undefined) {
        return this.#relative
      }
      const name = this.name
      const p = this.parent
      if (!p) {
        return (this.#relative = this.name)
      }
      const pv = p.relative()
      return pv + (!pv || !p.parent ? '' : this.sep) + name
    }
    /**
     * The relative path from the cwd, using / as the path separator.
     * If it does not share an ancestor with
     * the cwd, then this ends up being equivalent to the fullpathPosix()
     * On posix systems, this is identical to relative().
     */
    relativePosix() {
      if (this.sep === '/') {
        return this.relative()
      }
      if (this.isCWD) {
        return ''
      }
      if (this.#relativePosix !== undefined) {
        return this.#relativePosix
      }
      const name = this.name
      const p = this.parent
      if (!p) {
        return (this.#relativePosix = this.fullpathPosix())
      }
      const pv = p.relativePosix()
      return pv + (!pv || !p.parent ? '' : '/') + name
    }
    /**
     * The fully resolved path string for this Path entry
     */
    fullpath() {
      if (this.#fullpath !== undefined) {
        return this.#fullpath
      }
      const name = this.name
      const p = this.parent
      if (!p) {
        return (this.#fullpath = this.name)
      }
      const pv = p.fullpath()
      const fp = pv + (!p.parent ? '' : this.sep) + name
      return (this.#fullpath = fp)
    }
    /**
     * On platforms other than windows, this is identical to fullpath.
     *
     * On windows, this is overridden to return the forward-slash form of the
     * full UNC path.
     */
    fullpathPosix() {
      if (this.#fullpathPosix !== undefined) {
        return this.#fullpathPosix
      }
      if (this.sep === '/') {
        return (this.#fullpathPosix = this.fullpath())
      }
      if (!this.parent) {
        const p = this.fullpath().replace(/\\/g, '/')
        if (/^[a-z]:\//i.test(p)) {
          return (this.#fullpathPosix = `//?/${p}`)
        } else {
          return (this.#fullpathPosix = p)
        }
      }
      const p = this.parent
      const pfpp = p.fullpathPosix()
      const fpp = pfpp + (!pfpp || !p.parent ? '' : '/') + this.name
      return (this.#fullpathPosix = fpp)
    }
    /**
     * Is the Path of an unknown type?
     *
     * Note that we might know *something* about it if there has been a previous
     * filesystem operation, for example that it does not exist, or is not a
     * link, or whether it has child entries.
     */
    isUnknown() {
      return (this.#type & IFMT) === UNKNOWN
    }
    isType(type) {
      return this[`is${type}`]()
    }
    getType() {
      return this.isUnknown()
        ? 'Unknown'
        : this.isDirectory()
          ? 'Directory'
          : this.isFile()
            ? 'File'
            : this.isSymbolicLink()
              ? 'SymbolicLink'
              : this.isFIFO()
                ? 'FIFO'
                : this.isCharacterDevice()
                  ? 'CharacterDevice'
                  : this.isBlockDevice()
                    ? 'BlockDevice'
                    : /* c8 ignore start */ this.isSocket()
                      ? 'Socket'
                      : 'Unknown'
      /* c8 ignore stop */
    }
    /**
     * Is the Path a regular file?
     */
    isFile() {
      return (this.#type & IFMT) === IFREG
    }
    /**
     * Is the Path a directory?
     */
    isDirectory() {
      return (this.#type & IFMT) === IFDIR
    }
    /**
     * Is the path a character device?
     */
    isCharacterDevice() {
      return (this.#type & IFMT) === IFCHR
    }
    /**
     * Is the path a block device?
     */
    isBlockDevice() {
      return (this.#type & IFMT) === IFBLK
    }
    /**
     * Is the path a FIFO pipe?
     */
    isFIFO() {
      return (this.#type & IFMT) === IFIFO
    }
    /**
     * Is the path a socket?
     */
    isSocket() {
      return (this.#type & IFMT) === IFSOCK
    }
    /**
     * Is the path a symbolic link?
     */
    isSymbolicLink() {
      return (this.#type & IFLNK) === IFLNK
    }
    /**
     * Return the entry if it has been subject of a successful lstat, or
     * undefined otherwise.
     *
     * Does not read the filesystem, so an undefined result *could* simply
     * mean that we haven't called lstat on it.
     */
    lstatCached() {
      return this.#type & LSTAT_CALLED ? this : undefined
    }
    /**
     * Return the cached link target if the entry has been the subject of a
     * successful readlink, or undefined otherwise.
     *
     * Does not read the filesystem, so an undefined result *could* just mean we
     * don't have any cached data. Only use it if you are very sure that a
     * readlink() has been called at some point.
     */
    readlinkCached() {
      return this.#linkTarget
    }
    /**
     * Returns the cached realpath target if the entry has been the subject
     * of a successful realpath, or undefined otherwise.
     *
     * Does not read the filesystem, so an undefined result *could* just mean we
     * don't have any cached data. Only use it if you are very sure that a
     * realpath() has been called at some point.
     */
    realpathCached() {
      return this.#realpath
    }
    /**
     * Returns the cached child Path entries array if the entry has been the
     * subject of a successful readdir(), or [] otherwise.
     *
     * Does not read the filesystem, so an empty array *could* just mean we
     * don't have any cached data. Only use it if you are very sure that a
     * readdir() has been called recently enough to still be valid.
     */
    readdirCached() {
      const children = this.children()
      return children.slice(0, children.provisional)
    }
    /**
     * Return true if it's worth trying to readlink.  Ie, we don't (yet) have
     * any indication that readlink will definitely fail.
     *
     * Returns false if the path is known to not be a symlink, if a previous
     * readlink failed, or if the entry does not exist.
     */
    canReadlink() {
      if (this.#linkTarget) {
        return true
      }
      if (!this.parent) {
        return false
      }
      // cases where it cannot possibly succeed
      const ifmt = this.#type & IFMT
      return !(
        (ifmt !== UNKNOWN && ifmt !== IFLNK) ||
        this.#type & ENOREADLINK ||
        this.#type & ENOENT
      )
    }
    /**
     * Return true if readdir has previously been successfully called on this
     * path, indicating that cachedReaddir() is likely valid.
     */
    calledReaddir() {
      return !!(this.#type & READDIR_CALLED)
    }
    /**
     * Returns true if the path is known to not exist. That is, a previous lstat
     * or readdir failed to verify its existence when that would have been
     * expected, or a parent entry was marked either enoent or enotdir.
     */
    isENOENT() {
      return !!(this.#type & ENOENT)
    }
    /**
     * Return true if the path is a match for the given path name.  This handles
     * case sensitivity and unicode normalization.
     *
     * Note: even on case-sensitive systems, it is **not** safe to test the
     * equality of the `.name` property to determine whether a given pathname
     * matches, due to unicode normalization mismatches.
     *
     * Always use this method instead of testing the `path.name` property
     * directly.
     */
    isNamed(n) {
      return !this.nocase
        ? this.#matchName === normalize(n)
        : this.#matchName === normalizeNocase(n)
    }
    /**
     * Return the Path object corresponding to the target of a symbolic link.
     *
     * If the Path is not a symbolic link, or if the readlink call fails for any
     * reason, `undefined` is returned.
     *
     * Result is cached, and thus may be outdated if the filesystem is mutated.
     */
    async readlink() {
      const target = this.#linkTarget
      if (target) {
        return target
      }
      if (!this.canReadlink()) {
        return undefined
      }
      /* c8 ignore start */
      // already covered by the canReadlink test, here for ts grumples
      if (!this.parent) {
        return undefined
      }
      /* c8 ignore stop */
      try {
        const read = await this.#fs.promises.readlink(this.fullpath())
        const linkTarget = (await this.parent.realpath())?.resolve(read)
        if (linkTarget) {
          return (this.#linkTarget = linkTarget)
        }
      } catch (er) {
        this.#readlinkFail(er.code)
        return undefined
      }
    }
    /**
     * Synchronous {@link PathBase.readlink}
     */
    readlinkSync() {
      const target = this.#linkTarget
      if (target) {
        return target
      }
      if (!this.canReadlink()) {
        return undefined
      }
      /* c8 ignore start */
      // already covered by the canReadlink test, here for ts grumples
      if (!this.parent) {
        return undefined
      }
      /* c8 ignore stop */
      try {
        const read = this.#fs.readlinkSync(this.fullpath())
        const linkTarget = this.parent.realpathSync()?.resolve(read)
        if (linkTarget) {
          return (this.#linkTarget = linkTarget)
        }
      } catch (er) {
        this.#readlinkFail(er.code)
        return undefined
      }
    }
    #readdirSuccess(children) {
      // succeeded, mark readdir called bit
      this.#type |= READDIR_CALLED
      // mark all remaining provisional children as ENOENT
      for (let p = children.provisional; p < children.length; p++) {
        const c = children[p]
        if (c) {
          c.#markENOENT()
        }
      }
    }
    #markENOENT() {
      // mark as UNKNOWN and ENOENT
      if (this.#type & ENOENT) {
        return
      }
      this.#type = (this.#type | ENOENT) & IFMT_UNKNOWN
      this.#markChildrenENOENT()
    }
    #markChildrenENOENT() {
      // all children are provisional and do not exist
      const children = this.children()
      children.provisional = 0
      for (const p of children) {
        p.#markENOENT()
      }
    }
    #markENOREALPATH() {
      this.#type |= ENOREALPATH
      this.#markENOTDIR()
    }
    // save the information when we know the entry is not a dir
    #markENOTDIR() {
      // entry is not a directory, so any children can't exist.
      // this *should* be impossible, since any children created
      // after it's been marked ENOTDIR should be marked ENOENT,
      // so it won't even get to this point.
      /* c8 ignore start */
      if (this.#type & ENOTDIR) {
        return
      }
      /* c8 ignore stop */
      let t = this.#type
      // this could happen if we stat a dir, then delete it,
      // then try to read it or one of its children.
      if ((t & IFMT) === IFDIR) {
        t &= IFMT_UNKNOWN
      }
      this.#type = t | ENOTDIR
      this.#markChildrenENOENT()
    }
    #readdirFail(code = '') {
      // markENOTDIR and markENOENT also set provisional=0
      if (code === 'ENOTDIR' || code === 'EPERM') {
        this.#markENOTDIR()
      } else if (code === 'ENOENT') {
        this.#markENOENT()
      } else {
        this.children().provisional = 0
      }
    }
    #lstatFail(code = '') {
      // Windows just raises ENOENT in this case, disable for win CI
      /* c8 ignore start */
      if (code === 'ENOTDIR') {
        // already know it has a parent by this point
        const p = this.parent
        p.#markENOTDIR()
      } else if (code === 'ENOENT') {
        /* c8 ignore stop */
        this.#markENOENT()
      }
    }
    #readlinkFail(code = '') {
      let ter = this.#type
      ter |= ENOREADLINK
      if (code === 'ENOENT') {
        ter |= ENOENT
      }
      // windows gets a weird error when you try to readlink a file
      if (code === 'EINVAL' || code === 'UNKNOWN') {
        // exists, but not a symlink, we don't know WHAT it is, so remove
        // all IFMT bits.
        ter &= IFMT_UNKNOWN
      }
      this.#type = ter
      // windows just gets ENOENT in this case.  We do cover the case,
      // just disabled because it's impossible on Windows CI
      /* c8 ignore start */
      if (code === 'ENOTDIR' && this.parent) {
        this.parent.#markENOTDIR()
      }
      /* c8 ignore stop */
    }
    #readdirAddChild(e, c) {
      return (
        this.#readdirMaybePromoteChild(e, c) || this.#readdirAddNewChild(e, c)
      )
    }
    #readdirAddNewChild(e, c) {
      // alloc new entry at head, so it's never provisional
      const type = entToType(e)
      const child = this.newChild(e.name, type, {
        parent: this
      })
      const ifmt = child.#type & IFMT
      if (ifmt !== IFDIR && ifmt !== IFLNK && ifmt !== UNKNOWN) {
        child.#type |= ENOTDIR
      }
      c.unshift(child)
      c.provisional++
      return child
    }
    #readdirMaybePromoteChild(e, c) {
      for (let p = c.provisional; p < c.length; p++) {
        const pchild = c[p]
        const name = this.nocase ? normalizeNocase(e.name) : normalize(e.name)
        if (name !== pchild.#matchName) {
          continue
        }
        return this.#readdirPromoteChild(e, pchild, p, c)
      }
    }
    #readdirPromoteChild(e, p, index, c) {
      const v = p.name
      // retain any other flags, but set ifmt from dirent
      p.#type = (p.#type & IFMT_UNKNOWN) | entToType(e)
      // case sensitivity fixing when we learn the true name.
      if (v !== e.name) {
        p.name = e.name
      }
      // just advance provisional index (potentially off the list),
      // otherwise we have to splice/pop it out and re-insert at head
      if (index !== c.provisional) {
        if (index === c.length - 1) {
          c.pop()
        } else {
          c.splice(index, 1)
        }
        c.unshift(p)
      }
      c.provisional++
      return p
    }
    /**
     * Call lstat() on this Path, and update all known information that can be
     * determined.
     *
     * Note that unlike `fs.lstat()`, the returned value does not contain some
     * information, such as `mode`, `dev`, `nlink`, and `ino`.  If that
     * information is required, you will need to call `fs.lstat` yourself.
     *
     * If the Path refers to a nonexistent file, or if the lstat call fails for
     * any reason, `undefined` is returned.  Otherwise the updated Path object is
     * returned.
     *
     * Results are cached, and thus may be out of date if the filesystem is
     * mutated.
     */
    async lstat() {
      if ((this.#type & ENOENT) === 0) {
        try {
          this.#applyStat(await this.#fs.promises.lstat(this.fullpath()))
          return this
        } catch (er) {
          this.#lstatFail(er.code)
        }
      }
    }
    /**
     * synchronous {@link PathBase.lstat}
     */
    lstatSync() {
      if ((this.#type & ENOENT) === 0) {
        try {
          this.#applyStat(this.#fs.lstatSync(this.fullpath()))
          return this
        } catch (er) {
          this.#lstatFail(er.code)
        }
      }
    }
    #applyStat(st) {
      const {
        atime,
        atimeMs,
        birthtime,
        birthtimeMs,
        blksize,
        blocks,
        ctime,
        ctimeMs,
        dev,
        gid,
        ino,
        mode,
        mtime,
        mtimeMs,
        nlink,
        rdev,
        size,
        uid
      } = st
      this.#atime = atime
      this.#atimeMs = atimeMs
      this.#birthtime = birthtime
      this.#birthtimeMs = birthtimeMs
      this.#blksize = blksize
      this.#blocks = blocks
      this.#ctime = ctime
      this.#ctimeMs = ctimeMs
      this.#dev = dev
      this.#gid = gid
      this.#ino = ino
      this.#mode = mode
      this.#mtime = mtime
      this.#mtimeMs = mtimeMs
      this.#nlink = nlink
      this.#rdev = rdev
      this.#size = size
      this.#uid = uid
      const ifmt = entToType(st)
      // retain any other flags, but set the ifmt
      this.#type = (this.#type & IFMT_UNKNOWN) | ifmt | LSTAT_CALLED
      if (ifmt !== UNKNOWN && ifmt !== IFDIR && ifmt !== IFLNK) {
        this.#type |= ENOTDIR
      }
    }
    #onReaddirCB = []
    #readdirCBInFlight = false
    #callOnReaddirCB(children) {
      this.#readdirCBInFlight = false
      const cbs = this.#onReaddirCB.slice()
      this.#onReaddirCB.length = 0
      cbs.forEach(cb => cb(null, children))
    }
    /**
     * Standard node-style callback interface to get list of directory entries.
     *
     * If the Path cannot or does not contain any children, then an empty array
     * is returned.
     *
     * Results are cached, and thus may be out of date if the filesystem is
     * mutated.
     *
     * @param cb The callback called with (er, entries).  Note that the `er`
     * param is somewhat extraneous, as all readdir() errors are handled and
     * simply result in an empty set of entries being returned.
     * @param allowZalgo Boolean indicating that immediately known results should
     * *not* be deferred with `queueMicrotask`. Defaults to `false`. Release
     * zalgo at your peril, the dark pony lord is devious and unforgiving.
     */
    readdirCB(cb, allowZalgo = false) {
      if (!this.canReaddir()) {
        if (allowZalgo) {
          cb(null, [])
        } else {
          queueMicrotask(() => cb(null, []))
        }
        return
      }
      const children = this.children()
      if (this.calledReaddir()) {
        const c = children.slice(0, children.provisional)
        if (allowZalgo) {
          cb(null, c)
        } else {
          queueMicrotask(() => cb(null, c))
        }
        return
      }
      // don't have to worry about zalgo at this point.
      this.#onReaddirCB.push(cb)
      if (this.#readdirCBInFlight) {
        return
      }
      this.#readdirCBInFlight = true
      // else read the directory, fill up children
      // de-provisionalize any provisional children.
      const fullpath = this.fullpath()
      this.#fs.readdir(
        fullpath,
        {
          withFileTypes: true
        },
        (er, entries) => {
          if (er) {
            this.#readdirFail(er.code)
            children.provisional = 0
          } else {
            // if we didn't get an error, we always get entries.
            //@ts-ignore
            for (const e of entries) {
              this.#readdirAddChild(e, children)
            }
            this.#readdirSuccess(children)
          }
          this.#callOnReaddirCB(children.slice(0, children.provisional))
          return
        }
      )
    }
    #asyncReaddirInFlight
    /**
     * Return an array of known child entries.
     *
     * If the Path cannot or does not contain any children, then an empty array
     * is returned.
     *
     * Results are cached, and thus may be out of date if the filesystem is
     * mutated.
     */
    async readdir() {
      if (!this.canReaddir()) {
        return []
      }
      const children = this.children()
      if (this.calledReaddir()) {
        return children.slice(0, children.provisional)
      }
      // else read the directory, fill up children
      // de-provisionalize any provisional children.
      const fullpath = this.fullpath()
      if (this.#asyncReaddirInFlight) {
        await this.#asyncReaddirInFlight
      } else {
        /* c8 ignore start */
        let resolve = () => {}
        /* c8 ignore stop */
        this.#asyncReaddirInFlight = new Promise(res => (resolve = res))
        try {
          for (const e of await this.#fs.promises.readdir(fullpath, {
            withFileTypes: true
          })) {
            this.#readdirAddChild(e, children)
          }
          this.#readdirSuccess(children)
        } catch (er) {
          this.#readdirFail(er.code)
          children.provisional = 0
        }
        this.#asyncReaddirInFlight = undefined
        resolve()
      }
      return children.slice(0, children.provisional)
    }
    /**
     * synchronous {@link PathBase.readdir}
     */
    readdirSync() {
      if (!this.canReaddir()) {
        return []
      }
      const children = this.children()
      if (this.calledReaddir()) {
        return children.slice(0, children.provisional)
      }
      // else read the directory, fill up children
      // de-provisionalize any provisional children.
      const fullpath = this.fullpath()
      try {
        for (const e of this.#fs.readdirSync(fullpath, {
          withFileTypes: true
        })) {
          this.#readdirAddChild(e, children)
        }
        this.#readdirSuccess(children)
      } catch (er) {
        this.#readdirFail(er.code)
        children.provisional = 0
      }
      return children.slice(0, children.provisional)
    }
    canReaddir() {
      if (this.#type & ENOCHILD) {
        return false
      }
      const ifmt = IFMT & this.#type
      // we always set ENOTDIR when setting IFMT, so should be impossible
      /* c8 ignore start */
      if (!(ifmt === UNKNOWN || ifmt === IFDIR || ifmt === IFLNK)) {
        return false
      }
      /* c8 ignore stop */
      return true
    }
    shouldWalk(dirs, walkFilter) {
      return (
        (this.#type & IFDIR) === IFDIR &&
        !(this.#type & ENOCHILD) &&
        !dirs.has(this) &&
        (!walkFilter || walkFilter(this))
      )
    }
    /**
     * Return the Path object corresponding to path as resolved
     * by realpath(3).
     *
     * If the realpath call fails for any reason, `undefined` is returned.
     *
     * Result is cached, and thus may be outdated if the filesystem is mutated.
     * On success, returns a Path object.
     */
    async realpath() {
      if (this.#realpath) {
        return this.#realpath
      }
      if ((ENOREALPATH | ENOREADLINK | ENOENT) & this.#type) {
        return undefined
      }
      try {
        const rp = await this.#fs.promises.realpath(this.fullpath())
        return (this.#realpath = this.resolve(rp))
      } catch (_) {
        this.#markENOREALPATH()
      }
    }
    /**
     * Synchronous {@link realpath}
     */
    realpathSync() {
      if (this.#realpath) {
        return this.#realpath
      }
      if ((ENOREALPATH | ENOREADLINK | ENOENT) & this.#type) {
        return undefined
      }
      try {
        const rp = this.#fs.realpathSync(this.fullpath())
        return (this.#realpath = this.resolve(rp))
      } catch (_) {
        this.#markENOREALPATH()
      }
    }
    /**
     * Internal method to mark this Path object as the scurry cwd,
     * called by {@link PathScurry#chdir}
     *
     * @internal
     */
    [setAsCwd](oldCwd) {
      if (oldCwd === this) {
        return
      }
      oldCwd.isCWD = false
      this.isCWD = true
      const changed = new Set([])
      let rp = []
      let p = this
      while (p && p.parent) {
        changed.add(p)
        p.#relative = rp.join(this.sep)
        p.#relativePosix = rp.join('/')
        p = p.parent
        rp.push('..')
      }
      // now un-memoize parents of old cwd
      p = oldCwd
      while (p && p.parent && !changed.has(p)) {
        p.#relative = undefined
        p.#relativePosix = undefined
        p = p.parent
      }
    }
  }
  commonjs$1.PathBase = PathBase
  /**
   * Path class used on win32 systems
   *
   * Uses `'\\'` as the path separator for returned paths, either `'\\'` or `'/'`
   * as the path separator for parsing paths.
   */
  class PathWin32 extends PathBase {
    /**
     * Separator for generating path strings.
     */
    sep = '\\'
    /**
     * Separator for parsing path strings.
     */
    splitSep = eitherSep
    /**
     * Do not create new Path objects directly.  They should always be accessed
     * via the PathScurry class or other methods on the Path class.
     *
     * @internal
     */
    constructor(name, type = UNKNOWN, root, roots, nocase, children, opts) {
      super(name, type, root, roots, nocase, children, opts)
    }
    /**
     * @internal
     */
    newChild(name, type = UNKNOWN, opts = {}) {
      return new PathWin32(
        name,
        type,
        this.root,
        this.roots,
        this.nocase,
        this.childrenCache(),
        opts
      )
    }
    /**
     * @internal
     */
    getRootString(path) {
      return node_path_1.win32.parse(path).root
    }
    /**
     * @internal
     */
    getRoot(rootPath) {
      rootPath = uncToDrive(rootPath.toUpperCase())
      if (rootPath === this.root.name) {
        return this.root
      }
      // ok, not that one, check if it matches another we know about
      for (const [compare, root] of Object.entries(this.roots)) {
        if (this.sameRoot(rootPath, compare)) {
          return (this.roots[rootPath] = root)
        }
      }
      // otherwise, have to create a new one.
      return (this.roots[rootPath] = new PathScurryWin32(rootPath, this).root)
    }
    /**
     * @internal
     */
    sameRoot(rootPath, compare = this.root.name) {
      // windows can (rarely) have case-sensitive filesystem, but
      // UNC and drive letters are always case-insensitive, and canonically
      // represented uppercase.
      rootPath = rootPath
        .toUpperCase()
        .replace(/\//g, '\\')
        .replace(uncDriveRegexp, '$1\\')
      return rootPath === compare
    }
  }
  commonjs$1.PathWin32 = PathWin32
  /**
   * Path class used on all posix systems.
   *
   * Uses `'/'` as the path separator.
   */
  class PathPosix extends PathBase {
    /**
     * separator for parsing path strings
     */
    splitSep = '/'
    /**
     * separator for generating path strings
     */
    sep = '/'
    /**
     * Do not create new Path objects directly.  They should always be accessed
     * via the PathScurry class or other methods on the Path class.
     *
     * @internal
     */
    constructor(name, type = UNKNOWN, root, roots, nocase, children, opts) {
      super(name, type, root, roots, nocase, children, opts)
    }
    /**
     * @internal
     */
    getRootString(path) {
      return path.startsWith('/') ? '/' : ''
    }
    /**
     * @internal
     */
    getRoot(_rootPath) {
      return this.root
    }
    /**
     * @internal
     */
    newChild(name, type = UNKNOWN, opts = {}) {
      return new PathPosix(
        name,
        type,
        this.root,
        this.roots,
        this.nocase,
        this.childrenCache(),
        opts
      )
    }
  }
  commonjs$1.PathPosix = PathPosix
  /**
   * The base class for all PathScurry classes, providing the interface for path
   * resolution and filesystem operations.
   *
   * Typically, you should *not* instantiate this class directly, but rather one
   * of the platform-specific classes, or the exported {@link PathScurry} which
   * defaults to the current platform.
   */
  class PathScurryBase {
    /**
     * The root Path entry for the current working directory of this Scurry
     */
    root
    /**
     * The string path for the root of this Scurry's current working directory
     */
    rootPath
    /**
     * A collection of all roots encountered, referenced by rootPath
     */
    roots
    /**
     * The Path entry corresponding to this PathScurry's current working directory.
     */
    cwd
    #resolveCache
    #resolvePosixCache
    #children
    /**
     * Perform path comparisons case-insensitively.
     *
     * Defaults true on Darwin and Windows systems, false elsewhere.
     */
    nocase
    #fs
    /**
     * This class should not be instantiated directly.
     *
     * Use PathScurryWin32, PathScurryDarwin, PathScurryPosix, or PathScurry
     *
     * @internal
     */
    constructor(
      cwd = process.cwd(),
      pathImpl,
      sep,
      { nocase, childrenCacheSize = 16 * 1024, fs = defaultFS } = {}
    ) {
      this.#fs = fsFromOption(fs)
      if (cwd instanceof URL || cwd.startsWith('file://')) {
        cwd = (0, node_url_1.fileURLToPath)(cwd)
      }
      // resolve and split root, and then add to the store.
      // this is the only time we call path.resolve()
      const cwdPath = pathImpl.resolve(cwd)
      this.roots = Object.create(null)
      this.rootPath = this.parseRootPath(cwdPath)
      this.#resolveCache = new ResolveCache()
      this.#resolvePosixCache = new ResolveCache()
      this.#children = new ChildrenCache(childrenCacheSize)
      const split = cwdPath.substring(this.rootPath.length).split(sep)
      // resolve('/') leaves '', splits to [''], we don't want that.
      if (split.length === 1 && !split[0]) {
        split.pop()
      }
      /* c8 ignore start */
      if (nocase === undefined) {
        throw new TypeError(
          'must provide nocase setting to PathScurryBase ctor'
        )
      }
      /* c8 ignore stop */
      this.nocase = nocase
      this.root = this.newRoot(this.#fs)
      this.roots[this.rootPath] = this.root
      let prev = this.root
      let len = split.length - 1
      const joinSep = pathImpl.sep
      let abs = this.rootPath
      let sawFirst = false
      for (const part of split) {
        const l = len--
        prev = prev.child(part, {
          relative: new Array(l).fill('..').join(joinSep),
          relativePosix: new Array(l).fill('..').join('/'),
          fullpath: (abs += (sawFirst ? '' : joinSep) + part)
        })
        sawFirst = true
      }
      this.cwd = prev
    }
    /**
     * Get the depth of a provided path, string, or the cwd
     */
    depth(path = this.cwd) {
      if (typeof path === 'string') {
        path = this.cwd.resolve(path)
      }
      return path.depth()
    }
    /**
     * Return the cache of child entries.  Exposed so subclasses can create
     * child Path objects in a platform-specific way.
     *
     * @internal
     */
    childrenCache() {
      return this.#children
    }
    /**
     * Resolve one or more path strings to a resolved string
     *
     * Same interface as require('path').resolve.
     *
     * Much faster than path.resolve() when called multiple times for the same
     * path, because the resolved Path objects are cached.  Much slower
     * otherwise.
     */
    resolve(...paths) {
      // first figure out the minimum number of paths we have to test
      // we always start at cwd, but any absolutes will bump the start
      let r = ''
      for (let i = paths.length - 1; i >= 0; i--) {
        const p = paths[i]
        if (!p || p === '.') {
          continue
        }
        r = r ? `${p}/${r}` : p
        if (this.isAbsolute(p)) {
          break
        }
      }
      const cached = this.#resolveCache.get(r)
      if (cached !== undefined) {
        return cached
      }
      const result = this.cwd.resolve(r).fullpath()
      this.#resolveCache.set(r, result)
      return result
    }
    /**
     * Resolve one or more path strings to a resolved string, returning
     * the posix path.  Identical to .resolve() on posix systems, but on
     * windows will return a forward-slash separated UNC path.
     *
     * Same interface as require('path').resolve.
     *
     * Much faster than path.resolve() when called multiple times for the same
     * path, because the resolved Path objects are cached.  Much slower
     * otherwise.
     */
    resolvePosix(...paths) {
      // first figure out the minimum number of paths we have to test
      // we always start at cwd, but any absolutes will bump the start
      let r = ''
      for (let i = paths.length - 1; i >= 0; i--) {
        const p = paths[i]
        if (!p || p === '.') {
          continue
        }
        r = r ? `${p}/${r}` : p
        if (this.isAbsolute(p)) {
          break
        }
      }
      const cached = this.#resolvePosixCache.get(r)
      if (cached !== undefined) {
        return cached
      }
      const result = this.cwd.resolve(r).fullpathPosix()
      this.#resolvePosixCache.set(r, result)
      return result
    }
    /**
     * find the relative path from the cwd to the supplied path string or entry
     */
    relative(entry = this.cwd) {
      if (typeof entry === 'string') {
        entry = this.cwd.resolve(entry)
      }
      return entry.relative()
    }
    /**
     * find the relative path from the cwd to the supplied path string or
     * entry, using / as the path delimiter, even on Windows.
     */
    relativePosix(entry = this.cwd) {
      if (typeof entry === 'string') {
        entry = this.cwd.resolve(entry)
      }
      return entry.relativePosix()
    }
    /**
     * Return the basename for the provided string or Path object
     */
    basename(entry = this.cwd) {
      if (typeof entry === 'string') {
        entry = this.cwd.resolve(entry)
      }
      return entry.name
    }
    /**
     * Return the dirname for the provided string or Path object
     */
    dirname(entry = this.cwd) {
      if (typeof entry === 'string') {
        entry = this.cwd.resolve(entry)
      }
      return (entry.parent || entry).fullpath()
    }
    async readdir(
      entry = this.cwd,
      opts = {
        withFileTypes: true
      }
    ) {
      if (typeof entry === 'string') {
        entry = this.cwd.resolve(entry)
      } else if (!(entry instanceof PathBase)) {
        opts = entry
        entry = this.cwd
      }
      const { withFileTypes } = opts
      if (!entry.canReaddir()) {
        return []
      } else {
        const p = await entry.readdir()
        return withFileTypes ? p : p.map(e => e.name)
      }
    }
    readdirSync(
      entry = this.cwd,
      opts = {
        withFileTypes: true
      }
    ) {
      if (typeof entry === 'string') {
        entry = this.cwd.resolve(entry)
      } else if (!(entry instanceof PathBase)) {
        opts = entry
        entry = this.cwd
      }
      const { withFileTypes = true } = opts
      if (!entry.canReaddir()) {
        return []
      } else if (withFileTypes) {
        return entry.readdirSync()
      } else {
        return entry.readdirSync().map(e => e.name)
      }
    }
    /**
     * Call lstat() on the string or Path object, and update all known
     * information that can be determined.
     *
     * Note that unlike `fs.lstat()`, the returned value does not contain some
     * information, such as `mode`, `dev`, `nlink`, and `ino`.  If that
     * information is required, you will need to call `fs.lstat` yourself.
     *
     * If the Path refers to a nonexistent file, or if the lstat call fails for
     * any reason, `undefined` is returned.  Otherwise the updated Path object is
     * returned.
     *
     * Results are cached, and thus may be out of date if the filesystem is
     * mutated.
     */
    async lstat(entry = this.cwd) {
      if (typeof entry === 'string') {
        entry = this.cwd.resolve(entry)
      }
      return entry.lstat()
    }
    /**
     * synchronous {@link PathScurryBase.lstat}
     */
    lstatSync(entry = this.cwd) {
      if (typeof entry === 'string') {
        entry = this.cwd.resolve(entry)
      }
      return entry.lstatSync()
    }
    async readlink(
      entry = this.cwd,
      { withFileTypes } = {
        withFileTypes: false
      }
    ) {
      if (typeof entry === 'string') {
        entry = this.cwd.resolve(entry)
      } else if (!(entry instanceof PathBase)) {
        withFileTypes = entry.withFileTypes
        entry = this.cwd
      }
      const e = await entry.readlink()
      return withFileTypes ? e : e?.fullpath()
    }
    readlinkSync(
      entry = this.cwd,
      { withFileTypes } = {
        withFileTypes: false
      }
    ) {
      if (typeof entry === 'string') {
        entry = this.cwd.resolve(entry)
      } else if (!(entry instanceof PathBase)) {
        withFileTypes = entry.withFileTypes
        entry = this.cwd
      }
      const e = entry.readlinkSync()
      return withFileTypes ? e : e?.fullpath()
    }
    async realpath(
      entry = this.cwd,
      { withFileTypes } = {
        withFileTypes: false
      }
    ) {
      if (typeof entry === 'string') {
        entry = this.cwd.resolve(entry)
      } else if (!(entry instanceof PathBase)) {
        withFileTypes = entry.withFileTypes
        entry = this.cwd
      }
      const e = await entry.realpath()
      return withFileTypes ? e : e?.fullpath()
    }
    realpathSync(
      entry = this.cwd,
      { withFileTypes } = {
        withFileTypes: false
      }
    ) {
      if (typeof entry === 'string') {
        entry = this.cwd.resolve(entry)
      } else if (!(entry instanceof PathBase)) {
        withFileTypes = entry.withFileTypes
        entry = this.cwd
      }
      const e = entry.realpathSync()
      return withFileTypes ? e : e?.fullpath()
    }
    async walk(entry = this.cwd, opts = {}) {
      if (typeof entry === 'string') {
        entry = this.cwd.resolve(entry)
      } else if (!(entry instanceof PathBase)) {
        opts = entry
        entry = this.cwd
      }
      const { withFileTypes = true, follow = false, filter, walkFilter } = opts
      const results = []
      if (!filter || filter(entry)) {
        results.push(withFileTypes ? entry : entry.fullpath())
      }
      const dirs = new Set()
      const walk = (dir, cb) => {
        dirs.add(dir)
        dir.readdirCB((er, entries) => {
          /* c8 ignore start */
          if (er) {
            return cb(er)
          }
          /* c8 ignore stop */
          let len = entries.length
          if (!len) {
            return cb()
          }
          const next = () => {
            if (--len === 0) {
              cb()
            }
          }
          for (const e of entries) {
            if (!filter || filter(e)) {
              results.push(withFileTypes ? e : e.fullpath())
            }
            if (follow && e.isSymbolicLink()) {
              e.realpath()
                .then(r => (r?.isUnknown() ? r.lstat() : r))
                .then(r =>
                  r?.shouldWalk(dirs, walkFilter) ? walk(r, next) : next()
                )
            } else {
              if (e.shouldWalk(dirs, walkFilter)) {
                walk(e, next)
              } else {
                next()
              }
            }
          }
        }, true) // zalgooooooo
      }
      const start = entry
      return new Promise((res, rej) => {
        walk(start, er => {
          /* c8 ignore start */
          if (er) {
            return rej(er)
          }
          /* c8 ignore stop */
          res(results)
        })
      })
    }
    walkSync(entry = this.cwd, opts = {}) {
      if (typeof entry === 'string') {
        entry = this.cwd.resolve(entry)
      } else if (!(entry instanceof PathBase)) {
        opts = entry
        entry = this.cwd
      }
      const { withFileTypes = true, follow = false, filter, walkFilter } = opts
      const results = []
      if (!filter || filter(entry)) {
        results.push(withFileTypes ? entry : entry.fullpath())
      }
      const dirs = new Set([entry])
      for (const dir of dirs) {
        const entries = dir.readdirSync()
        for (const e of entries) {
          if (!filter || filter(e)) {
            results.push(withFileTypes ? e : e.fullpath())
          }
          let r = e
          if (e.isSymbolicLink()) {
            if (!(follow && (r = e.realpathSync()))) {
              continue
            }
            if (r.isUnknown()) {
              r.lstatSync()
            }
          }
          if (r.shouldWalk(dirs, walkFilter)) {
            dirs.add(r)
          }
        }
      }
      return results
    }
    /**
     * Support for `for await`
     *
     * Alias for {@link PathScurryBase.iterate}
     *
     * Note: As of Node 19, this is very slow, compared to other methods of
     * walking.  Consider using {@link PathScurryBase.stream} if memory overhead
     * and backpressure are concerns, or {@link PathScurryBase.walk} if not.
     */
    [Symbol.asyncIterator]() {
      return this.iterate()
    }
    iterate(entry = this.cwd, options = {}) {
      // iterating async over the stream is significantly more performant,
      // especially in the warm-cache scenario, because it buffers up directory
      // entries in the background instead of waiting for a yield for each one.
      if (typeof entry === 'string') {
        entry = this.cwd.resolve(entry)
      } else if (!(entry instanceof PathBase)) {
        options = entry
        entry = this.cwd
      }
      return this.stream(entry, options)[Symbol.asyncIterator]()
    }
    /**
     * Iterating over a PathScurry performs a synchronous walk.
     *
     * Alias for {@link PathScurryBase.iterateSync}
     */
    [Symbol.iterator]() {
      return this.iterateSync()
    }
    *iterateSync(entry = this.cwd, opts = {}) {
      if (typeof entry === 'string') {
        entry = this.cwd.resolve(entry)
      } else if (!(entry instanceof PathBase)) {
        opts = entry
        entry = this.cwd
      }
      const { withFileTypes = true, follow = false, filter, walkFilter } = opts
      if (!filter || filter(entry)) {
        yield withFileTypes ? entry : entry.fullpath()
      }
      const dirs = new Set([entry])
      for (const dir of dirs) {
        const entries = dir.readdirSync()
        for (const e of entries) {
          if (!filter || filter(e)) {
            yield withFileTypes ? e : e.fullpath()
          }
          let r = e
          if (e.isSymbolicLink()) {
            if (!(follow && (r = e.realpathSync()))) {
              continue
            }
            if (r.isUnknown()) {
              r.lstatSync()
            }
          }
          if (r.shouldWalk(dirs, walkFilter)) {
            dirs.add(r)
          }
        }
      }
    }
    stream(entry = this.cwd, opts = {}) {
      if (typeof entry === 'string') {
        entry = this.cwd.resolve(entry)
      } else if (!(entry instanceof PathBase)) {
        opts = entry
        entry = this.cwd
      }
      const { withFileTypes = true, follow = false, filter, walkFilter } = opts
      const results = new minipass_1.Minipass({
        objectMode: true
      })
      if (!filter || filter(entry)) {
        results.write(withFileTypes ? entry : entry.fullpath())
      }
      const dirs = new Set()
      const queue = [entry]
      let processing = 0
      const process = () => {
        let paused = false
        while (!paused) {
          const dir = queue.shift()
          if (!dir) {
            if (processing === 0) {
              results.end()
            }
            return
          }
          processing++
          dirs.add(dir)
          const onReaddir = (er, entries, didRealpaths = false) => {
            /* c8 ignore start */
            if (er) {
              return results.emit('error', er)
            }
            /* c8 ignore stop */
            if (follow && !didRealpaths) {
              const promises = []
              for (const e of entries) {
                if (e.isSymbolicLink()) {
                  promises.push(
                    e.realpath().then(r => (r?.isUnknown() ? r.lstat() : r))
                  )
                }
              }
              if (promises.length) {
                Promise.all(promises).then(() => onReaddir(null, entries, true))
                return
              }
            }
            for (const e of entries) {
              if (e && (!filter || filter(e))) {
                if (!results.write(withFileTypes ? e : e.fullpath())) {
                  paused = true
                }
              }
            }
            processing--
            for (const e of entries) {
              const r = e.realpathCached() || e
              if (r.shouldWalk(dirs, walkFilter)) {
                queue.push(r)
              }
            }
            if (paused && !results.flowing) {
              results.once('drain', process)
            } else if (!sync) {
              process()
            }
          }
          // zalgo containment
          let sync = true
          dir.readdirCB(onReaddir, true)
          sync = false
        }
      }
      process()
      return results
    }
    streamSync(entry = this.cwd, opts = {}) {
      if (typeof entry === 'string') {
        entry = this.cwd.resolve(entry)
      } else if (!(entry instanceof PathBase)) {
        opts = entry
        entry = this.cwd
      }
      const { withFileTypes = true, follow = false, filter, walkFilter } = opts
      const results = new minipass_1.Minipass({
        objectMode: true
      })
      const dirs = new Set()
      if (!filter || filter(entry)) {
        results.write(withFileTypes ? entry : entry.fullpath())
      }
      const queue = [entry]
      let processing = 0
      const process = () => {
        let paused = false
        while (!paused) {
          const dir = queue.shift()
          if (!dir) {
            if (processing === 0) {
              results.end()
            }
            return
          }
          processing++
          dirs.add(dir)
          const entries = dir.readdirSync()
          for (const e of entries) {
            if (!filter || filter(e)) {
              if (!results.write(withFileTypes ? e : e.fullpath())) {
                paused = true
              }
            }
          }
          processing--
          for (const e of entries) {
            let r = e
            if (e.isSymbolicLink()) {
              if (!(follow && (r = e.realpathSync()))) {
                continue
              }
              if (r.isUnknown()) {
                r.lstatSync()
              }
            }
            if (r.shouldWalk(dirs, walkFilter)) {
              queue.push(r)
            }
          }
        }
        if (paused && !results.flowing) {
          results.once('drain', process)
        }
      }
      process()
      return results
    }
    chdir(path = this.cwd) {
      const oldCwd = this.cwd
      this.cwd = typeof path === 'string' ? this.cwd.resolve(path) : path
      this.cwd[setAsCwd](oldCwd)
    }
  }
  commonjs$1.PathScurryBase = PathScurryBase
  /**
   * Windows implementation of {@link PathScurryBase}
   *
   * Defaults to case insensitve, uses `'\\'` to generate path strings.  Uses
   * {@link PathWin32} for Path objects.
   */
  class PathScurryWin32 extends PathScurryBase {
    /**
     * separator for generating path strings
     */
    sep = '\\'
    constructor(cwd = process.cwd(), opts = {}) {
      const { nocase = true } = opts
      super(cwd, node_path_1.win32, '\\', {
        ...opts,
        nocase
      })
      this.nocase = nocase
      for (let p = this.cwd; p; p = p.parent) {
        p.nocase = this.nocase
      }
    }
    /**
     * @internal
     */
    parseRootPath(dir) {
      // if the path starts with a single separator, it's not a UNC, and we'll
      // just get separator as the root, and driveFromUNC will return \
      // In that case, mount \ on the root from the cwd.
      return node_path_1.win32.parse(dir).root.toUpperCase()
    }
    /**
     * @internal
     */
    newRoot(fs) {
      return new PathWin32(
        this.rootPath,
        IFDIR,
        undefined,
        this.roots,
        this.nocase,
        this.childrenCache(),
        {
          fs
        }
      )
    }
    /**
     * Return true if the provided path string is an absolute path
     */
    isAbsolute(p) {
      return (
        p.startsWith('/') || p.startsWith('\\') || /^[a-z]:(\/|\\)/i.test(p)
      )
    }
  }
  commonjs$1.PathScurryWin32 = PathScurryWin32
  /**
   * {@link PathScurryBase} implementation for all posix systems other than Darwin.
   *
   * Defaults to case-sensitive matching, uses `'/'` to generate path strings.
   *
   * Uses {@link PathPosix} for Path objects.
   */
  class PathScurryPosix extends PathScurryBase {
    /**
     * separator for generating path strings
     */
    sep = '/'
    constructor(cwd = process.cwd(), opts = {}) {
      const { nocase = false } = opts
      super(cwd, node_path_1.posix, '/', {
        ...opts,
        nocase
      })
      this.nocase = nocase
    }
    /**
     * @internal
     */
    parseRootPath(_dir) {
      return '/'
    }
    /**
     * @internal
     */
    newRoot(fs) {
      return new PathPosix(
        this.rootPath,
        IFDIR,
        undefined,
        this.roots,
        this.nocase,
        this.childrenCache(),
        {
          fs
        }
      )
    }
    /**
     * Return true if the provided path string is an absolute path
     */
    isAbsolute(p) {
      return p.startsWith('/')
    }
  }
  commonjs$1.PathScurryPosix = PathScurryPosix
  /**
   * {@link PathScurryBase} implementation for Darwin (macOS) systems.
   *
   * Defaults to case-insensitive matching, uses `'/'` for generating path
   * strings.
   *
   * Uses {@link PathPosix} for Path objects.
   */
  class PathScurryDarwin extends PathScurryPosix {
    constructor(cwd = process.cwd(), opts = {}) {
      const { nocase = true } = opts
      super(cwd, {
        ...opts,
        nocase
      })
    }
  }
  commonjs$1.PathScurryDarwin = PathScurryDarwin
  /**
   * Default {@link PathBase} implementation for the current platform.
   *
   * {@link PathWin32} on Windows systems, {@link PathPosix} on all others.
   */
  commonjs$1.Path = process.platform === 'win32' ? PathWin32 : PathPosix
  /**
   * Default {@link PathScurryBase} implementation for the current platform.
   *
   * {@link PathScurryWin32} on Windows systems, {@link PathScurryDarwin} on
   * Darwin (macOS) systems, {@link PathScurryPosix} on all others.
   */
  commonjs$1.PathScurry =
    process.platform === 'win32'
      ? PathScurryWin32
      : process.platform === 'darwin'
        ? PathScurryDarwin
        : PathScurryPosix
  return commonjs$1
}

const pattern = {}

let hasRequiredPattern
function requirePattern() {
  if (hasRequiredPattern) {
    return pattern
  }
  hasRequiredPattern = 1
  // this is just a very light wrapper around 2 arrays with an offset index
  Object.defineProperty(pattern, '__esModule', {
    value: true
  })
  pattern.Pattern = void 0
  const minimatch_1 = requireCommonjs$3()
  const isPatternList = pl => pl.length >= 1
  const isGlobList = gl => gl.length >= 1
  /**
   * An immutable-ish view on an array of glob parts and their parsed
   * results
   */
  class Pattern {
    #patternList
    #globList
    #index
    length
    #platform
    #rest
    #globString
    #isDrive
    #isUNC
    #isAbsolute
    #followGlobstar = true
    constructor(patternList, globList, index, platform) {
      if (!isPatternList(patternList)) {
        throw new TypeError('empty pattern list')
      }
      if (!isGlobList(globList)) {
        throw new TypeError('empty glob list')
      }
      if (globList.length !== patternList.length) {
        throw new TypeError('mismatched pattern list and glob list lengths')
      }
      this.length = patternList.length
      if (index < 0 || index >= this.length) {
        throw new TypeError('index out of range')
      }
      this.#patternList = patternList
      this.#globList = globList
      this.#index = index
      this.#platform = platform
      // normalize root entries of absolute patterns on initial creation.
      if (this.#index === 0) {
        // c: => ['c:/']
        // C:/ => ['C:/']
        // C:/x => ['C:/', 'x']
        // //host/share => ['//host/share/']
        // //host/share/ => ['//host/share/']
        // //host/share/x => ['//host/share/', 'x']
        // /etc => ['/', 'etc']
        // / => ['/']
        if (this.isUNC()) {
          // '' / '' / 'host' / 'share'
          const [p0, p1, p2, p3, ...prest] = this.#patternList
          const [g0, g1, g2, g3, ...grest] = this.#globList
          if (prest[0] === '') {
            // ends in /
            prest.shift()
            grest.shift()
          }
          const p = [p0, p1, p2, p3, ''].join('/')
          const g = [g0, g1, g2, g3, ''].join('/')
          this.#patternList = [p, ...prest]
          this.#globList = [g, ...grest]
          this.length = this.#patternList.length
        } else if (this.isDrive() || this.isAbsolute()) {
          const [p1, ...prest] = this.#patternList
          const [g1, ...grest] = this.#globList
          if (prest[0] === '') {
            // ends in /
            prest.shift()
            grest.shift()
          }
          const p = p1 + '/'
          const g = g1 + '/'
          this.#patternList = [p, ...prest]
          this.#globList = [g, ...grest]
          this.length = this.#patternList.length
        }
      }
    }
    /**
     * The first entry in the parsed list of patterns
     */
    pattern() {
      return this.#patternList[this.#index]
    }
    /**
     * true of if pattern() returns a string
     */
    isString() {
      return typeof this.#patternList[this.#index] === 'string'
    }
    /**
     * true of if pattern() returns GLOBSTAR
     */
    isGlobstar() {
      return this.#patternList[this.#index] === minimatch_1.GLOBSTAR
    }
    /**
     * true if pattern() returns a regexp
     */
    isRegExp() {
      return this.#patternList[this.#index] instanceof RegExp
    }
    /**
     * The /-joined set of glob parts that make up this pattern
     */
    globString() {
      return (this.#globString =
        this.#globString ||
        (this.#index === 0
          ? this.isAbsolute()
            ? this.#globList[0] + this.#globList.slice(1).join('/')
            : this.#globList.join('/')
          : this.#globList.slice(this.#index).join('/')))
    }
    /**
     * true if there are more pattern parts after this one
     */
    hasMore() {
      return this.length > this.#index + 1
    }
    /**
     * The rest of the pattern after this part, or null if this is the end
     */
    rest() {
      if (this.#rest !== undefined) {
        return this.#rest
      }
      if (!this.hasMore()) {
        return (this.#rest = null)
      }
      this.#rest = new Pattern(
        this.#patternList,
        this.#globList,
        this.#index + 1,
        this.#platform
      )
      this.#rest.#isAbsolute = this.#isAbsolute
      this.#rest.#isUNC = this.#isUNC
      this.#rest.#isDrive = this.#isDrive
      return this.#rest
    }
    /**
     * true if the pattern represents a //unc/path/ on windows
     */
    isUNC() {
      const pl = this.#patternList
      return this.#isUNC !== undefined
        ? this.#isUNC
        : (this.#isUNC =
            this.#platform === 'win32' &&
            this.#index === 0 &&
            pl[0] === '' &&
            pl[1] === '' &&
            typeof pl[2] === 'string' &&
            !!pl[2] &&
            typeof pl[3] === 'string' &&
            !!pl[3])
    }
    // pattern like C:/...
    // split = ['C:', ...]
    // XXX: would be nice to handle patterns like `c:*` to test the cwd
    // in c: for *, but I don't know of a way to even figure out what that
    // cwd is without actually chdir'ing into it?
    /**
     * True if the pattern starts with a drive letter on Windows
     */
    isDrive() {
      const pl = this.#patternList
      return this.#isDrive !== undefined
        ? this.#isDrive
        : (this.#isDrive =
            this.#platform === 'win32' &&
            this.#index === 0 &&
            this.length > 1 &&
            typeof pl[0] === 'string' &&
            /^[a-z]:$/i.test(pl[0]))
    }
    // pattern = '/' or '/...' or '/x/...'
    // split = ['', ''] or ['', ...] or ['', 'x', ...]
    // Drive and UNC both considered absolute on windows
    /**
     * True if the pattern is rooted on an absolute path
     */
    isAbsolute() {
      const pl = this.#patternList
      return this.#isAbsolute !== undefined
        ? this.#isAbsolute
        : (this.#isAbsolute =
            (pl[0] === '' && pl.length > 1) || this.isDrive() || this.isUNC())
    }
    /**
     * consume the root of the pattern, and return it
     */
    root() {
      const p = this.#patternList[0]
      return typeof p === 'string' && this.isAbsolute() && this.#index === 0
        ? p
        : ''
    }
    /**
     * Check to see if the current globstar pattern is allowed to follow
     * a symbolic link.
     */
    checkFollowGlobstar() {
      return !(this.#index === 0 || !this.isGlobstar() || !this.#followGlobstar)
    }
    /**
     * Mark that the current globstar pattern is following a symbolic link
     */
    markFollowGlobstar() {
      if (this.#index === 0 || !this.isGlobstar() || !this.#followGlobstar) {
        return false
      }
      this.#followGlobstar = false
      return true
    }
  }
  pattern.Pattern = Pattern
  return pattern
}

const walker = {}

const ignore = {}

let hasRequiredIgnore
function requireIgnore() {
  if (hasRequiredIgnore) {
    return ignore
  }
  hasRequiredIgnore = 1
  // give it a pattern, and it'll be able to tell you if
  // a given path should be ignored.
  // Ignoring a path ignores its children if the pattern ends in /**
  // Ignores are always parsed in dot:true mode
  Object.defineProperty(ignore, '__esModule', {
    value: true
  })
  ignore.Ignore = void 0
  const minimatch_1 = requireCommonjs$3()
  const pattern_js_1 = requirePattern()
  const defaultPlatform =
    typeof process === 'object' &&
    process &&
    typeof process.platform === 'string'
      ? process.platform
      : 'linux'
  /**
   * Class used to process ignored patterns
   */
  class Ignore {
    relative
    relativeChildren
    absolute
    absoluteChildren
    platform
    mmopts
    constructor(
      ignored,
      { nobrace, nocase, noext, noglobstar, platform = defaultPlatform }
    ) {
      this.relative = []
      this.absolute = []
      this.relativeChildren = []
      this.absoluteChildren = []
      this.platform = platform
      this.mmopts = {
        dot: true,
        nobrace,
        nocase,
        noext,
        noglobstar,
        optimizationLevel: 2,
        platform,
        nocomment: true,
        nonegate: true
      }
      for (const ign of ignored) {
        this.add(ign)
      }
    }
    add(ign) {
      // this is a little weird, but it gives us a clean set of optimized
      // minimatch matchers, without getting tripped up if one of them
      // ends in /** inside a brace section, and it's only inefficient at
      // the start of the walk, not along it.
      // It'd be nice if the Pattern class just had a .test() method, but
      // handling globstars is a bit of a pita, and that code already lives
      // in minimatch anyway.
      // Another way would be if maybe Minimatch could take its set/globParts
      // as an option, and then we could at least just use Pattern to test
      // for absolute-ness.
      // Yet another way, Minimatch could take an array of glob strings, and
      // a cwd option, and do the right thing.
      const mm = new minimatch_1.Minimatch(ign, this.mmopts)
      for (let i = 0; i < mm.set.length; i++) {
        const parsed = mm.set[i]
        const globParts = mm.globParts[i]
        /* c8 ignore start */
        if (!parsed || !globParts) {
          throw new Error('invalid pattern object')
        }
        // strip off leading ./ portions
        // https://github.com/isaacs/node-glob/issues/570
        while (parsed[0] === '.' && globParts[0] === '.') {
          parsed.shift()
          globParts.shift()
        }
        /* c8 ignore stop */
        const p = new pattern_js_1.Pattern(parsed, globParts, 0, this.platform)
        const m = new minimatch_1.Minimatch(p.globString(), this.mmopts)
        const children = globParts[globParts.length - 1] === '**'
        const absolute = p.isAbsolute()
        if (absolute) {
          this.absolute.push(m)
        } else {
          this.relative.push(m)
        }
        if (children) {
          if (absolute) {
            this.absoluteChildren.push(m)
          } else {
            this.relativeChildren.push(m)
          }
        }
      }
    }
    ignored(p) {
      const fullpath = p.fullpath()
      const fullpaths = `${fullpath}/`
      const relative = p.relative() || '.'
      const relatives = `${relative}/`
      for (const m of this.relative) {
        if (m.match(relative) || m.match(relatives)) {
          return true
        }
      }
      for (const m of this.absolute) {
        if (m.match(fullpath) || m.match(fullpaths)) {
          return true
        }
      }
      return false
    }
    childrenIgnored(p) {
      const fullpath = p.fullpath() + '/'
      const relative = (p.relative() || '.') + '/'
      for (const m of this.relativeChildren) {
        if (m.match(relative)) {
          return true
        }
      }
      for (const m of this.absoluteChildren) {
        if (m.match(fullpath)) {
          return true
        }
      }
      return false
    }
  }
  ignore.Ignore = Ignore
  return ignore
}

const processor = {}

let hasRequiredProcessor
function requireProcessor() {
  if (hasRequiredProcessor) {
    return processor
  }
  hasRequiredProcessor = 1
  // synchronous utility for filtering entries and calculating subwalks
  Object.defineProperty(processor, '__esModule', {
    value: true
  })
  processor.Processor =
    processor.SubWalks =
    processor.MatchRecord =
    processor.HasWalkedCache =
      void 0
  const minimatch_1 = requireCommonjs$3()
  /**
   * A cache of which patterns have been processed for a given Path
   */
  class HasWalkedCache {
    store
    constructor(store = new Map()) {
      this.store = store
    }
    copy() {
      return new HasWalkedCache(new Map(this.store))
    }
    hasWalked(target, pattern) {
      return this.store.get(target.fullpath())?.has(pattern.globString())
    }
    storeWalked(target, pattern) {
      const fullpath = target.fullpath()
      const cached = this.store.get(fullpath)
      if (cached) {
        cached.add(pattern.globString())
      } else {
        this.store.set(fullpath, new Set([pattern.globString()]))
      }
    }
  }
  processor.HasWalkedCache = HasWalkedCache
  /**
   * A record of which paths have been matched in a given walk step,
   * and whether they only are considered a match if they are a directory,
   * and whether their absolute or relative path should be returned.
   */
  class MatchRecord {
    store = new Map()
    add(target, absolute, ifDir) {
      const n = (absolute ? 2 : 0) | (ifDir ? 1 : 0)
      const current = this.store.get(target)
      this.store.set(target, current === undefined ? n : n & current)
    }
    // match, absolute, ifdir
    entries() {
      return [...this.store.entries()].map(([path, n]) => [
        path,
        !!(n & 2),
        !!(n & 1)
      ])
    }
  }
  processor.MatchRecord = MatchRecord
  /**
   * A collection of patterns that must be processed in a subsequent step
   * for a given path.
   */
  class SubWalks {
    store = new Map()
    add(target, pattern) {
      if (!target.canReaddir()) {
        return
      }
      const subs = this.store.get(target)
      if (subs) {
        if (!subs.find(p => p.globString() === pattern.globString())) {
          subs.push(pattern)
        }
      } else {
        this.store.set(target, [pattern])
      }
    }
    get(target) {
      const subs = this.store.get(target)
      /* c8 ignore start */
      if (!subs) {
        throw new Error('attempting to walk unknown path')
      }
      /* c8 ignore stop */
      return subs
    }
    entries() {
      return this.keys().map(k => [k, this.store.get(k)])
    }
    keys() {
      return [...this.store.keys()].filter(t => t.canReaddir())
    }
  }
  processor.SubWalks = SubWalks
  /**
   * The class that processes patterns for a given path.
   *
   * Handles child entry filtering, and determining whether a path's
   * directory contents must be read.
   */
  class Processor {
    hasWalkedCache
    matches = new MatchRecord()
    subwalks = new SubWalks()
    patterns
    follow
    dot
    opts
    constructor(opts, hasWalkedCache) {
      this.opts = opts
      this.follow = !!opts.follow
      this.dot = !!opts.dot
      this.hasWalkedCache = hasWalkedCache
        ? hasWalkedCache.copy()
        : new HasWalkedCache()
    }
    processPatterns(target, patterns) {
      this.patterns = patterns
      const processingSet = patterns.map(p => [target, p])
      // map of paths to the magic-starting subwalks they need to walk
      // first item in patterns is the filter
      for (let [t, pattern] of processingSet) {
        this.hasWalkedCache.storeWalked(t, pattern)
        const root = pattern.root()
        const absolute = pattern.isAbsolute() && this.opts.absolute !== false
        // start absolute patterns at root
        if (root) {
          t = t.resolve(
            root === '/' && this.opts.root !== undefined ? this.opts.root : root
          )
          const rest = pattern.rest()
          if (!rest) {
            this.matches.add(t, true, false)
            continue
          } else {
            pattern = rest
          }
        }
        if (t.isENOENT()) {
          continue
        }
        let p
        let rest
        let changed = false
        while (
          typeof (p = pattern.pattern()) === 'string' &&
          (rest = pattern.rest())
        ) {
          const c = t.resolve(p)
          t = c
          pattern = rest
          changed = true
        }
        p = pattern.pattern()
        rest = pattern.rest()
        if (changed) {
          if (this.hasWalkedCache.hasWalked(t, pattern)) {
            continue
          }
          this.hasWalkedCache.storeWalked(t, pattern)
        }
        // now we have either a final string for a known entry,
        // more strings for an unknown entry,
        // or a pattern starting with magic, mounted on t.
        if (typeof p === 'string') {
          // must not be final entry, otherwise we would have
          // concatenated it earlier.
          const ifDir = p === '..' || p === '' || p === '.'
          this.matches.add(t.resolve(p), absolute, ifDir)
          continue
        } else if (p === minimatch_1.GLOBSTAR) {
          // if no rest, match and subwalk pattern
          // if rest, process rest and subwalk pattern
          // if it's a symlink, but we didn't get here by way of a
          // globstar match (meaning it's the first time THIS globstar
          // has traversed a symlink), then we follow it. Otherwise, stop.
          if (
            !t.isSymbolicLink() ||
            this.follow ||
            pattern.checkFollowGlobstar()
          ) {
            this.subwalks.add(t, pattern)
          }
          const rp = rest?.pattern()
          const rrest = rest?.rest()
          if (!rest || ((rp === '' || rp === '.') && !rrest)) {
            // only HAS to be a dir if it ends in **/ or **/.
            // but ending in ** will match files as well.
            this.matches.add(t, absolute, rp === '' || rp === '.')
          } else {
            if (rp === '..') {
              // this would mean you're matching **/.. at the fs root,
              // and no thanks, I'm not gonna test that specific case.
              /* c8 ignore start */
              const tp = t.parent || t
              /* c8 ignore stop */
              if (!rrest) {
                this.matches.add(tp, absolute, true)
              } else if (!this.hasWalkedCache.hasWalked(tp, rrest)) {
                this.subwalks.add(tp, rrest)
              }
            }
          }
        } else if (p instanceof RegExp) {
          this.subwalks.add(t, pattern)
        }
      }
      return this
    }
    subwalkTargets() {
      return this.subwalks.keys()
    }
    child() {
      return new Processor(this.opts, this.hasWalkedCache)
    }
    // return a new Processor containing the subwalks for each
    // child entry, and a set of matches, and
    // a hasWalkedCache that's a copy of this one
    // then we're going to call
    filterEntries(parent, entries) {
      const patterns = this.subwalks.get(parent)
      // put matches and entry walks into the results processor
      const results = this.child()
      for (const e of entries) {
        for (const pattern of patterns) {
          const absolute = pattern.isAbsolute()
          const p = pattern.pattern()
          const rest = pattern.rest()
          if (p === minimatch_1.GLOBSTAR) {
            results.testGlobstar(e, pattern, rest, absolute)
          } else if (p instanceof RegExp) {
            results.testRegExp(e, p, rest, absolute)
          } else {
            results.testString(e, p, rest, absolute)
          }
        }
      }
      return results
    }
    testGlobstar(e, pattern, rest, absolute) {
      if (this.dot || !e.name.startsWith('.')) {
        if (!pattern.hasMore()) {
          this.matches.add(e, absolute, false)
        }
        if (e.canReaddir()) {
          // if we're in follow mode or it's not a symlink, just keep
          // testing the same pattern. If there's more after the globstar,
          // then this symlink consumes the globstar. If not, then we can
          // follow at most ONE symlink along the way, so we mark it, which
          // also checks to ensure that it wasn't already marked.
          if (this.follow || !e.isSymbolicLink()) {
            this.subwalks.add(e, pattern)
          } else if (e.isSymbolicLink()) {
            if (rest && pattern.checkFollowGlobstar()) {
              this.subwalks.add(e, rest)
            } else if (pattern.markFollowGlobstar()) {
              this.subwalks.add(e, pattern)
            }
          }
        }
      }
      // if the NEXT thing matches this entry, then also add
      // the rest.
      if (rest) {
        const rp = rest.pattern()
        if (
          typeof rp === 'string' &&
          // dots and empty were handled already
          rp !== '..' &&
          rp !== '' &&
          rp !== '.'
        ) {
          this.testString(e, rp, rest.rest(), absolute)
        } else if (rp === '..') {
          /* c8 ignore start */
          const ep = e.parent || e
          /* c8 ignore stop */
          this.subwalks.add(ep, rest)
        } else if (rp instanceof RegExp) {
          this.testRegExp(e, rp, rest.rest(), absolute)
        }
      }
    }
    testRegExp(e, p, rest, absolute) {
      if (!p.test(e.name)) {
        return
      }
      if (!rest) {
        this.matches.add(e, absolute, false)
      } else {
        this.subwalks.add(e, rest)
      }
    }
    testString(e, p, rest, absolute) {
      // should never happen?
      if (!e.isNamed(p)) {
        return
      }
      if (!rest) {
        this.matches.add(e, absolute, false)
      } else {
        this.subwalks.add(e, rest)
      }
    }
  }
  processor.Processor = Processor
  return processor
}

let hasRequiredWalker
function requireWalker() {
  if (hasRequiredWalker) {
    return walker
  }
  hasRequiredWalker = 1
  Object.defineProperty(walker, '__esModule', {
    value: true
  })
  walker.GlobStream = walker.GlobWalker = walker.GlobUtil = void 0
  /**
   * Single-use utility classes to provide functionality to the {@link Glob}
   * methods.
   *
   * @module
   */
  const minipass_1 = requireCommonjs$2()
  const ignore_js_1 = requireIgnore()
  const processor_js_1 = requireProcessor()
  const makeIgnore = (ignore, opts) =>
    typeof ignore === 'string'
      ? new ignore_js_1.Ignore([ignore], opts)
      : Array.isArray(ignore)
        ? new ignore_js_1.Ignore(ignore, opts)
        : ignore
  /**
   * basic walking utilities that all the glob walker types use
   */
  class GlobUtil {
    path
    patterns
    opts
    seen = new Set()
    paused = false
    aborted = false
    #onResume = []
    #ignore
    #sep
    signal
    maxDepth
    includeChildMatches
    constructor(patterns, path, opts) {
      this.patterns = patterns
      this.path = path
      this.opts = opts
      this.#sep = !opts.posix && opts.platform === 'win32' ? '\\' : '/'
      this.includeChildMatches = opts.includeChildMatches !== false
      if (opts.ignore || !this.includeChildMatches) {
        this.#ignore = makeIgnore(opts.ignore ?? [], opts)
        if (
          !this.includeChildMatches &&
          typeof this.#ignore.add !== 'function'
        ) {
          const m = 'cannot ignore child matches, ignore lacks add() method.'
          throw new Error(m)
        }
      }
      // ignore, always set with maxDepth, but it's optional on the
      // GlobOptions type
      /* c8 ignore start */
      this.maxDepth = opts.maxDepth || Infinity
      /* c8 ignore stop */
      if (opts.signal) {
        this.signal = opts.signal
        this.signal.addEventListener('abort', () => {
          this.#onResume.length = 0
        })
      }
    }
    #ignored(path) {
      return this.seen.has(path) || !!this.#ignore?.ignored?.(path)
    }
    #childrenIgnored(path) {
      return !!this.#ignore?.childrenIgnored?.(path)
    }
    // backpressure mechanism
    pause() {
      this.paused = true
    }
    resume() {
      /* c8 ignore start */
      if (this.signal?.aborted) {
        return
      }
      /* c8 ignore stop */
      this.paused = false
      let fn = undefined
      while (!this.paused && (fn = this.#onResume.shift())) {
        fn()
      }
    }
    onResume(fn) {
      if (this.signal?.aborted) {
        return
      }
      /* c8 ignore start */
      if (!this.paused) {
        fn()
      } else {
        /* c8 ignore stop */
        this.#onResume.push(fn)
      }
    }
    // do the requisite realpath/stat checking, and return the path
    // to add or undefined to filter it out.
    async matchCheck(e, ifDir) {
      if (ifDir && this.opts.nodir) {
        return undefined
      }
      let rpc
      if (this.opts.realpath) {
        rpc = e.realpathCached() || (await e.realpath())
        if (!rpc) {
          return undefined
        }
        e = rpc
      }
      const needStat = e.isUnknown() || this.opts.stat
      const s = needStat ? await e.lstat() : e
      if (this.opts.follow && this.opts.nodir && s?.isSymbolicLink()) {
        const target = await s.realpath()
        /* c8 ignore start */
        if (target && (target.isUnknown() || this.opts.stat)) {
          await target.lstat()
        }
        /* c8 ignore stop */
      }
      return this.matchCheckTest(s, ifDir)
    }
    matchCheckTest(e, ifDir) {
      return e &&
        (this.maxDepth === Infinity || e.depth() <= this.maxDepth) &&
        (!ifDir || e.canReaddir()) &&
        (!this.opts.nodir || !e.isDirectory()) &&
        (!this.opts.nodir ||
          !this.opts.follow ||
          !e.isSymbolicLink() ||
          !e.realpathCached()?.isDirectory()) &&
        !this.#ignored(e)
        ? e
        : undefined
    }
    matchCheckSync(e, ifDir) {
      if (ifDir && this.opts.nodir) {
        return undefined
      }
      let rpc
      if (this.opts.realpath) {
        rpc = e.realpathCached() || e.realpathSync()
        if (!rpc) {
          return undefined
        }
        e = rpc
      }
      const needStat = e.isUnknown() || this.opts.stat
      const s = needStat ? e.lstatSync() : e
      if (this.opts.follow && this.opts.nodir && s?.isSymbolicLink()) {
        const target = s.realpathSync()
        if (target && (target?.isUnknown() || this.opts.stat)) {
          target.lstatSync()
        }
      }
      return this.matchCheckTest(s, ifDir)
    }
    matchFinish(e, absolute) {
      if (this.#ignored(e)) {
        return
      }
      // we know we have an ignore if this is false, but TS doesn't
      if (!this.includeChildMatches && this.#ignore?.add) {
        const ign = `${e.relativePosix()}/**`
        this.#ignore.add(ign)
      }
      const abs =
        this.opts.absolute === undefined ? absolute : this.opts.absolute
      this.seen.add(e)
      const mark = this.opts.mark && e.isDirectory() ? this.#sep : ''
      // ok, we have what we need!
      if (this.opts.withFileTypes) {
        this.matchEmit(e)
      } else if (abs) {
        const abs = this.opts.posix ? e.fullpathPosix() : e.fullpath()
        this.matchEmit(abs + mark)
      } else {
        const rel = this.opts.posix ? e.relativePosix() : e.relative()
        const pre =
          this.opts.dotRelative && !rel.startsWith('..' + this.#sep)
            ? '.' + this.#sep
            : ''
        this.matchEmit(!rel ? '.' + mark : pre + rel + mark)
      }
    }
    async match(e, absolute, ifDir) {
      const p = await this.matchCheck(e, ifDir)
      if (p) {
        this.matchFinish(p, absolute)
      }
    }
    matchSync(e, absolute, ifDir) {
      const p = this.matchCheckSync(e, ifDir)
      if (p) {
        this.matchFinish(p, absolute)
      }
    }
    walkCB(target, patterns, cb) {
      /* c8 ignore start */
      if (this.signal?.aborted) {
        cb()
      }
      /* c8 ignore stop */
      this.walkCB2(
        target,
        patterns,
        new processor_js_1.Processor(this.opts),
        cb
      )
    }
    walkCB2(target, patterns, processor, cb) {
      if (this.#childrenIgnored(target)) {
        return cb()
      }
      if (this.signal?.aborted) {
        cb()
      }
      if (this.paused) {
        this.onResume(() => this.walkCB2(target, patterns, processor, cb))
        return
      }
      processor.processPatterns(target, patterns)
      // done processing.  all of the above is sync, can be abstracted out.
      // subwalks is a map of paths to the entry filters they need
      // matches is a map of paths to [absolute, ifDir] tuples.
      let tasks = 1
      const next = () => {
        if (--tasks === 0) {
          cb()
        }
      }
      for (const [m, absolute, ifDir] of processor.matches.entries()) {
        if (this.#ignored(m)) {
          continue
        }
        tasks++
        this.match(m, absolute, ifDir).then(() => next())
      }
      for (const t of processor.subwalkTargets()) {
        if (this.maxDepth !== Infinity && t.depth() >= this.maxDepth) {
          continue
        }
        tasks++
        const childrenCached = t.readdirCached()
        if (t.calledReaddir()) {
          this.walkCB3(t, childrenCached, processor, next)
        } else {
          t.readdirCB(
            (_, entries) => this.walkCB3(t, entries, processor, next),
            true
          )
        }
      }
      next()
    }
    walkCB3(target, entries, processor, cb) {
      processor = processor.filterEntries(target, entries)
      let tasks = 1
      const next = () => {
        if (--tasks === 0) {
          cb()
        }
      }
      for (const [m, absolute, ifDir] of processor.matches.entries()) {
        if (this.#ignored(m)) {
          continue
        }
        tasks++
        this.match(m, absolute, ifDir).then(() => next())
      }
      for (const [target, patterns] of processor.subwalks.entries()) {
        tasks++
        this.walkCB2(target, patterns, processor.child(), next)
      }
      next()
    }
    walkCBSync(target, patterns, cb) {
      /* c8 ignore start */
      if (this.signal?.aborted) {
        cb()
      }
      /* c8 ignore stop */
      this.walkCB2Sync(
        target,
        patterns,
        new processor_js_1.Processor(this.opts),
        cb
      )
    }
    walkCB2Sync(target, patterns, processor, cb) {
      if (this.#childrenIgnored(target)) {
        return cb()
      }
      if (this.signal?.aborted) {
        cb()
      }
      if (this.paused) {
        this.onResume(() => this.walkCB2Sync(target, patterns, processor, cb))
        return
      }
      processor.processPatterns(target, patterns)
      // done processing.  all of the above is sync, can be abstracted out.
      // subwalks is a map of paths to the entry filters they need
      // matches is a map of paths to [absolute, ifDir] tuples.
      let tasks = 1
      const next = () => {
        if (--tasks === 0) {
          cb()
        }
      }
      for (const [m, absolute, ifDir] of processor.matches.entries()) {
        if (this.#ignored(m)) {
          continue
        }
        this.matchSync(m, absolute, ifDir)
      }
      for (const t of processor.subwalkTargets()) {
        if (this.maxDepth !== Infinity && t.depth() >= this.maxDepth) {
          continue
        }
        tasks++
        const children = t.readdirSync()
        this.walkCB3Sync(t, children, processor, next)
      }
      next()
    }
    walkCB3Sync(target, entries, processor, cb) {
      processor = processor.filterEntries(target, entries)
      let tasks = 1
      const next = () => {
        if (--tasks === 0) {
          cb()
        }
      }
      for (const [m, absolute, ifDir] of processor.matches.entries()) {
        if (this.#ignored(m)) {
          continue
        }
        this.matchSync(m, absolute, ifDir)
      }
      for (const [target, patterns] of processor.subwalks.entries()) {
        tasks++
        this.walkCB2Sync(target, patterns, processor.child(), next)
      }
      next()
    }
  }
  walker.GlobUtil = GlobUtil
  class GlobWalker extends GlobUtil {
    matches = new Set()

    matchEmit(e) {
      this.matches.add(e)
    }
    async walk() {
      if (this.signal?.aborted) {
        throw this.signal.reason
      }
      if (this.path.isUnknown()) {
        await this.path.lstat()
      }
      await new Promise((res, rej) => {
        this.walkCB(this.path, this.patterns, () => {
          if (this.signal?.aborted) {
            rej(this.signal.reason)
          } else {
            res(this.matches)
          }
        })
      })
      return this.matches
    }
    walkSync() {
      if (this.signal?.aborted) {
        throw this.signal.reason
      }
      if (this.path.isUnknown()) {
        this.path.lstatSync()
      }
      // nothing for the callback to do, because this never pauses
      this.walkCBSync(this.path, this.patterns, () => {
        if (this.signal?.aborted) {
          throw this.signal.reason
        }
      })
      return this.matches
    }
  }
  walker.GlobWalker = GlobWalker
  class GlobStream extends GlobUtil {
    results
    constructor(patterns, path, opts) {
      super(patterns, path, opts)
      this.results = new minipass_1.Minipass({
        signal: this.signal,
        objectMode: true
      })
      this.results.on('drain', () => this.resume())
      this.results.on('resume', () => this.resume())
    }
    matchEmit(e) {
      this.results.write(e)
      if (!this.results.flowing) {
        this.pause()
      }
    }
    stream() {
      const target = this.path
      if (target.isUnknown()) {
        target.lstat().then(() => {
          this.walkCB(target, this.patterns, () => this.results.end())
        })
      } else {
        this.walkCB(target, this.patterns, () => this.results.end())
      }
      return this.results
    }
    streamSync() {
      if (this.path.isUnknown()) {
        this.path.lstatSync()
      }
      this.walkCBSync(this.path, this.patterns, () => this.results.end())
      return this.results
    }
  }
  walker.GlobStream = GlobStream
  return walker
}

let hasRequiredGlob
function requireGlob() {
  if (hasRequiredGlob) {
    return glob
  }
  hasRequiredGlob = 1
  Object.defineProperty(glob, '__esModule', {
    value: true
  })
  glob.Glob = void 0
  const minimatch_1 = requireCommonjs$3()
  const node_url_1 = require$$0$3
  const path_scurry_1 = requireCommonjs$1()
  const pattern_js_1 = requirePattern()
  const walker_js_1 = requireWalker()
  // if no process global, just call it linux.
  // so we default to case-sensitive, / separators
  const defaultPlatform =
    typeof process === 'object' &&
    process &&
    typeof process.platform === 'string'
      ? process.platform
      : 'linux'
  /**
   * An object that can perform glob pattern traversals.
   */
  class Glob {
    absolute
    cwd
    root
    dot
    dotRelative
    follow
    ignore
    magicalBraces
    mark
    matchBase
    maxDepth
    nobrace
    nocase
    nodir
    noext
    noglobstar
    pattern
    platform
    realpath
    scurry
    stat
    signal
    windowsPathsNoEscape
    withFileTypes
    includeChildMatches
    /**
     * The options provided to the constructor.
     */
    opts
    /**
     * An array of parsed immutable {@link Pattern} objects.
     */
    patterns
    /**
     * All options are stored as properties on the `Glob` object.
     *
     * See {@link GlobOptions} for full options descriptions.
     *
     * Note that a previous `Glob` object can be passed as the
     * `GlobOptions` to another `Glob` instantiation to re-use settings
     * and caches with a new pattern.
     *
     * Traversal functions can be called multiple times to run the walk
     * again.
     */
    constructor(pattern, opts) {
      /* c8 ignore start */
      if (!opts) {
        throw new TypeError('glob options required')
      }
      /* c8 ignore stop */
      this.withFileTypes = !!opts.withFileTypes
      this.signal = opts.signal
      this.follow = !!opts.follow
      this.dot = !!opts.dot
      this.dotRelative = !!opts.dotRelative
      this.nodir = !!opts.nodir
      this.mark = !!opts.mark
      if (!opts.cwd) {
        this.cwd = ''
      } else if (opts.cwd instanceof URL || opts.cwd.startsWith('file://')) {
        opts.cwd = (0, node_url_1.fileURLToPath)(opts.cwd)
      }
      this.cwd = opts.cwd || ''
      this.root = opts.root
      this.magicalBraces = !!opts.magicalBraces
      this.nobrace = !!opts.nobrace
      this.noext = !!opts.noext
      this.realpath = !!opts.realpath
      this.absolute = opts.absolute
      this.includeChildMatches = opts.includeChildMatches !== false
      this.noglobstar = !!opts.noglobstar
      this.matchBase = !!opts.matchBase
      this.maxDepth =
        typeof opts.maxDepth === 'number' ? opts.maxDepth : Infinity
      this.stat = !!opts.stat
      this.ignore = opts.ignore
      if (this.withFileTypes && this.absolute !== undefined) {
        throw new Error('cannot set absolute and withFileTypes:true')
      }
      if (typeof pattern === 'string') {
        pattern = [pattern]
      }
      this.windowsPathsNoEscape =
        !!opts.windowsPathsNoEscape || opts.allowWindowsEscape === false
      if (this.windowsPathsNoEscape) {
        pattern = pattern.map(p => p.replace(/\\/g, '/'))
      }
      if (this.matchBase) {
        if (opts.noglobstar) {
          throw new TypeError('base matching requires globstar')
        }
        pattern = pattern.map(p => (p.includes('/') ? p : `./**/${p}`))
      }
      this.pattern = pattern
      this.platform = opts.platform || defaultPlatform
      this.opts = {
        ...opts,
        platform: this.platform
      }
      if (opts.scurry) {
        this.scurry = opts.scurry
        if (opts.nocase !== undefined && opts.nocase !== opts.scurry.nocase) {
          throw new Error('nocase option contradicts provided scurry option')
        }
      } else {
        const Scurry =
          opts.platform === 'win32'
            ? path_scurry_1.PathScurryWin32
            : opts.platform === 'darwin'
              ? path_scurry_1.PathScurryDarwin
              : opts.platform
                ? path_scurry_1.PathScurryPosix
                : path_scurry_1.PathScurry
        this.scurry = new Scurry(this.cwd, {
          nocase: opts.nocase,
          fs: opts.fs
        })
      }
      this.nocase = this.scurry.nocase
      // If you do nocase:true on a case-sensitive file system, then
      // we need to use regexps instead of strings for non-magic
      // path portions, because statting `aBc` won't return results
      // for the file `AbC` for example.
      const nocaseMagicOnly =
        this.platform === 'darwin' || this.platform === 'win32'
      const mmo = {
        // default nocase based on platform
        ...opts,
        dot: this.dot,
        matchBase: this.matchBase,
        nobrace: this.nobrace,
        nocase: this.nocase,
        nocaseMagicOnly,
        nocomment: true,
        noext: this.noext,
        nonegate: true,
        optimizationLevel: 2,
        platform: this.platform,
        windowsPathsNoEscape: this.windowsPathsNoEscape,
        debug: !!this.opts.debug
      }
      const mms = this.pattern.map(p => new minimatch_1.Minimatch(p, mmo))
      const [matchSet, globParts] = mms.reduce(
        (set, m) => {
          set[0].push(...m.set)
          set[1].push(...m.globParts)
          return set
        },
        [[], []]
      )
      this.patterns = matchSet.map((set, i) => {
        const g = globParts[i]
        /* c8 ignore start */
        if (!g) {
          throw new Error('invalid pattern object')
        }
        /* c8 ignore stop */
        return new pattern_js_1.Pattern(set, g, 0, this.platform)
      })
    }
    async walk() {
      // Walkers always return array of Path objects, so we just have to
      // coerce them into the right shape.  It will have already called
      // realpath() if the option was set to do so, so we know that's cached.
      // start out knowing the cwd, at least
      return [
        ...(await new walker_js_1.GlobWalker(this.patterns, this.scurry.cwd, {
          ...this.opts,
          maxDepth:
            this.maxDepth !== Infinity
              ? this.maxDepth + this.scurry.cwd.depth()
              : Infinity,
          platform: this.platform,
          nocase: this.nocase,
          includeChildMatches: this.includeChildMatches
        }).walk())
      ]
    }
    walkSync() {
      return [
        ...new walker_js_1.GlobWalker(this.patterns, this.scurry.cwd, {
          ...this.opts,
          maxDepth:
            this.maxDepth !== Infinity
              ? this.maxDepth + this.scurry.cwd.depth()
              : Infinity,
          platform: this.platform,
          nocase: this.nocase,
          includeChildMatches: this.includeChildMatches
        }).walkSync()
      ]
    }
    stream() {
      return new walker_js_1.GlobStream(this.patterns, this.scurry.cwd, {
        ...this.opts,
        maxDepth:
          this.maxDepth !== Infinity
            ? this.maxDepth + this.scurry.cwd.depth()
            : Infinity,
        platform: this.platform,
        nocase: this.nocase,
        includeChildMatches: this.includeChildMatches
      }).stream()
    }
    streamSync() {
      return new walker_js_1.GlobStream(this.patterns, this.scurry.cwd, {
        ...this.opts,
        maxDepth:
          this.maxDepth !== Infinity
            ? this.maxDepth + this.scurry.cwd.depth()
            : Infinity,
        platform: this.platform,
        nocase: this.nocase,
        includeChildMatches: this.includeChildMatches
      }).streamSync()
    }
    /**
     * Default sync iteration function. Returns a Generator that
     * iterates over the results.
     */
    iterateSync() {
      return this.streamSync()[Symbol.iterator]()
    }
    [Symbol.iterator]() {
      return this.iterateSync()
    }
    /**
     * Default async iteration function. Returns an AsyncGenerator that
     * iterates over the results.
     */
    iterate() {
      return this.stream()[Symbol.asyncIterator]()
    }
    [Symbol.asyncIterator]() {
      return this.iterate()
    }
  }
  glob.Glob = Glob
  return glob
}

const hasMagic = {}

let hasRequiredHasMagic
function requireHasMagic() {
  if (hasRequiredHasMagic) {
    return hasMagic
  }
  hasRequiredHasMagic = 1
  Object.defineProperty(hasMagic, '__esModule', {
    value: true
  })
  hasMagic.hasMagic = void 0
  const minimatch_1 = requireCommonjs$3()
  /**
   * Return true if the patterns provided contain any magic glob characters,
   * given the options provided.
   *
   * Brace expansion is not considered "magic" unless the `magicalBraces` option
   * is set, as brace expansion just turns one string into an array of strings.
   * So a pattern like `'x{a,b}y'` would return `false`, because `'xay'` and
   * `'xby'` both do not contain any magic glob characters, and it's treated the
   * same as if you had called it on `['xay', 'xby']`. When `magicalBraces:true`
   * is in the options, brace expansion _is_ treated as a pattern having magic.
   */
  const hasMagic$1 = (pattern, options = {}) => {
    if (!Array.isArray(pattern)) {
      pattern = [pattern]
    }
    for (const p of pattern) {
      if (new minimatch_1.Minimatch(p, options).hasMagic()) {
        return true
      }
    }
    return false
  }
  hasMagic.hasMagic = hasMagic$1
  return hasMagic
}

let hasRequiredCommonjs
function requireCommonjs() {
  if (hasRequiredCommonjs) {
    return commonjs$3
  }
  hasRequiredCommonjs = 1
  ;(function (exports) {
    Object.defineProperty(exports, '__esModule', {
      value: true
    })
    exports.glob =
      exports.sync =
      exports.iterate =
      exports.iterateSync =
      exports.stream =
      exports.streamSync =
      exports.Ignore =
      exports.hasMagic =
      exports.Glob =
      exports.unescape =
      exports.escape =
        void 0
    exports.globStreamSync = globStreamSync
    exports.globStream = globStream
    exports.globSync = globSync
    exports.globIterateSync = globIterateSync
    exports.globIterate = globIterate
    const minimatch_1 = requireCommonjs$3()
    const glob_js_1 = requireGlob()
    const has_magic_js_1 = requireHasMagic()
    const minimatch_2 = requireCommonjs$3()
    Object.defineProperty(exports, 'escape', {
      enumerable: true,
      get: function () {
        return minimatch_2.escape
      }
    })
    Object.defineProperty(exports, 'unescape', {
      enumerable: true,
      get: function () {
        return minimatch_2.unescape
      }
    })
    const glob_js_2 = requireGlob()
    Object.defineProperty(exports, 'Glob', {
      enumerable: true,
      get: function () {
        return glob_js_2.Glob
      }
    })
    const has_magic_js_2 = requireHasMagic()
    Object.defineProperty(exports, 'hasMagic', {
      enumerable: true,
      get: function () {
        return has_magic_js_2.hasMagic
      }
    })
    const ignore_js_1 = requireIgnore()
    Object.defineProperty(exports, 'Ignore', {
      enumerable: true,
      get: function () {
        return ignore_js_1.Ignore
      }
    })
    function globStreamSync(pattern, options = {}) {
      return new glob_js_1.Glob(pattern, options).streamSync()
    }
    function globStream(pattern, options = {}) {
      return new glob_js_1.Glob(pattern, options).stream()
    }
    function globSync(pattern, options = {}) {
      return new glob_js_1.Glob(pattern, options).walkSync()
    }
    async function glob_(pattern, options = {}) {
      return new glob_js_1.Glob(pattern, options).walk()
    }
    function globIterateSync(pattern, options = {}) {
      return new glob_js_1.Glob(pattern, options).iterateSync()
    }
    function globIterate(pattern, options = {}) {
      return new glob_js_1.Glob(pattern, options).iterate()
    }
    // aliases: glob.sync.stream() glob.stream.sync() glob.sync() etc
    exports.streamSync = globStreamSync
    exports.stream = Object.assign(globStream, {
      sync: globStreamSync
    })
    exports.iterateSync = globIterateSync
    exports.iterate = Object.assign(globIterate, {
      sync: globIterateSync
    })
    exports.sync = Object.assign(globSync, {
      stream: globStreamSync,
      iterate: globIterateSync
    })
    exports.glob = Object.assign(glob_, {
      glob: glob_,
      globSync,
      sync: exports.sync,
      globStream,
      stream: exports.stream,
      globStreamSync,
      streamSync: exports.streamSync,
      globIterate,
      iterate: exports.iterate,
      globIterateSync,
      iterateSync: exports.iterateSync,
      Glob: glob_js_1.Glob,
      hasMagic: has_magic_js_1.hasMagic,
      escape: minimatch_1.escape,
      unescape: minimatch_1.unescape
    })
    exports.glob.glob = exports.glob
  })(commonjs$3)
  return commonjs$3
}

const cjs = {}

const posix = {}

let hasRequiredPosix
function requirePosix() {
  if (hasRequiredPosix) {
    return posix
  }
  hasRequiredPosix = 1
  /**
   * This is the Posix implementation of isexe, which uses the file
   * mode and uid/gid values.
   *
   * @module
   */
  Object.defineProperty(posix, '__esModule', {
    value: true
  })
  posix.sync = posix.isexe = void 0
  const fs_1 = require$$0$2
  const promises_1 = require$$1$3
  /**
   * Determine whether a path is executable according to the mode and
   * current (or specified) user and group IDs.
   */
  const isexe = async (path, options = {}) => {
    const { ignoreErrors = false } = options
    try {
      return checkStat(await (0, promises_1.stat)(path), options)
    } catch (e) {
      const er = e
      if (ignoreErrors || er.code === 'EACCES') {
        return false
      }
      throw er
    }
  }
  posix.isexe = isexe
  /**
   * Synchronously determine whether a path is executable according to
   * the mode and current (or specified) user and group IDs.
   */
  const sync = (path, options = {}) => {
    const { ignoreErrors = false } = options
    try {
      return checkStat((0, fs_1.statSync)(path), options)
    } catch (e) {
      const er = e
      if (ignoreErrors || er.code === 'EACCES') {
        return false
      }
      throw er
    }
  }
  posix.sync = sync
  const checkStat = (stat, options) => stat.isFile() && checkMode(stat, options)
  const checkMode = (stat, options) => {
    const myUid = options.uid ?? process.getuid?.()
    const myGroups = options.groups ?? process.getgroups?.() ?? []
    const myGid = options.gid ?? process.getgid?.() ?? myGroups[0]
    if (myUid === undefined || myGid === undefined) {
      throw new Error('cannot get uid or gid')
    }
    const groups = new Set([myGid, ...myGroups])
    const mod = stat.mode
    const uid = stat.uid
    const gid = stat.gid
    const u = parseInt('100', 8)
    const g = parseInt('010', 8)
    const o = parseInt('001', 8)
    const ug = u | g
    return !!(
      mod & o ||
      (mod & g && groups.has(gid)) ||
      (mod & u && uid === myUid) ||
      (mod & ug && myUid === 0)
    )
  }
  return posix
}

const win32 = {}

let hasRequiredWin32
function requireWin32() {
  if (hasRequiredWin32) {
    return win32
  }
  hasRequiredWin32 = 1
  /**
   * This is the Windows implementation of isexe, which uses the file
   * extension and PATHEXT setting.
   *
   * @module
   */
  Object.defineProperty(win32, '__esModule', {
    value: true
  })
  win32.sync = win32.isexe = void 0
  const fs_1 = require$$0$2
  const promises_1 = require$$1$3
  /**
   * Determine whether a path is executable based on the file extension
   * and PATHEXT environment variable (or specified pathExt option)
   */
  const isexe = async (path, options = {}) => {
    const { ignoreErrors = false } = options
    try {
      return checkStat(await (0, promises_1.stat)(path), path, options)
    } catch (e) {
      const er = e
      if (ignoreErrors || er.code === 'EACCES') {
        return false
      }
      throw er
    }
  }
  win32.isexe = isexe
  /**
   * Synchronously determine whether a path is executable based on the file
   * extension and PATHEXT environment variable (or specified pathExt option)
   */
  const sync = (path, options = {}) => {
    const { ignoreErrors = false } = options
    try {
      return checkStat((0, fs_1.statSync)(path), path, options)
    } catch (e) {
      const er = e
      if (ignoreErrors || er.code === 'EACCES') {
        return false
      }
      throw er
    }
  }
  win32.sync = sync
  const checkPathExt = (path, options) => {
    const { pathExt = process.env.PATHEXT || '' } = options
    const peSplit = pathExt.split(';')
    if (peSplit.indexOf('') !== -1) {
      return true
    }
    for (let i = 0; i < peSplit.length; i++) {
      const p = peSplit[i].toLowerCase()
      const ext = path.substring(path.length - p.length).toLowerCase()
      if (p && ext === p) {
        return true
      }
    }
    return false
  }
  const checkStat = (stat, path, options) =>
    stat.isFile() && checkPathExt(path, options)
  return win32
}

const options = {}

let hasRequiredOptions
function requireOptions() {
  if (hasRequiredOptions) {
    return options
  }
  hasRequiredOptions = 1
  Object.defineProperty(options, '__esModule', {
    value: true
  })
  return options
}

let hasRequiredCjs
function requireCjs() {
  if (hasRequiredCjs) {
    return cjs
  }
  hasRequiredCjs = 1
  ;(function (exports) {
    const __createBinding =
      (this && this.__createBinding) ||
      (Object.create
        ? function (o, m, k, k2) {
            if (k2 === undefined) {
              k2 = k
            }
            let desc = Object.getOwnPropertyDescriptor(m, k)
            if (
              !desc ||
              ('get' in desc
                ? !m.__esModule
                : desc.writable || desc.configurable)
            ) {
              desc = {
                enumerable: true,
                get: function () {
                  return m[k]
                }
              }
            }
            Object.defineProperty(o, k2, desc)
          }
        : function (o, m, k, k2) {
            if (k2 === undefined) {
              k2 = k
            }
            o[k2] = m[k]
          })
    const __setModuleDefault =
      (this && this.__setModuleDefault) ||
      (Object.create
        ? function (o, v) {
            Object.defineProperty(o, 'default', {
              enumerable: true,
              value: v
            })
          }
        : function (o, v) {
            o['default'] = v
          })
    const __importStar =
      (this && this.__importStar) ||
      function (mod) {
        if (mod && mod.__esModule) {
          return mod
        }
        const result = {}
        if (mod != null) {
          for (var k in mod)
            if (k !== 'default' && Object.prototype.hasOwnProperty.call(mod, k))
              __createBinding(result, mod, k)
        }
        __setModuleDefault(result, mod)
        return result
      }
    const __exportStar =
      (this && this.__exportStar) ||
      function (m, exports) {
        for (const p in m) {
          if (
            p !== 'default' &&
            !Object.prototype.hasOwnProperty.call(exports, p)
          )
            __createBinding(exports, m, p)
        }
      }
    Object.defineProperty(exports, '__esModule', {
      value: true
    })
    exports.sync = exports.isexe = exports.posix = exports.win32 = void 0
    const posix = __importStar(requirePosix())
    exports.posix = posix
    const win32 = __importStar(requireWin32())
    exports.win32 = win32
    __exportStar(requireOptions(), exports)
    const platform = process.env._ISEXE_TEST_PLATFORM_ || process.platform
    const impl = platform === 'win32' ? win32 : posix
    /**
     * Determine whether a path is executable on the current platform.
     */
    exports.isexe = impl.isexe
    /**
     * Synchronously determine whether a path is executable on the
     * current platform.
     */
    exports.sync = impl.sync
  })(cjs)
  return cjs
}

let lib$7
let hasRequiredLib$7
function requireLib$7() {
  if (hasRequiredLib$7) {
    return lib$7
  }
  hasRequiredLib$7 = 1
  const { isexe, sync: isexeSync } = requireCjs()
  const { join, delimiter, sep, posix } = require$$1$4
  const isWindows = process.platform === 'win32'

  // used to check for slashed in commands passed in. always checks for the posix
  // seperator on all platforms, and checks for the current separator when not on
  // a posix platform. don't use the isWindows check for this since that is mocked
  // in tests but we still need the code to actually work when called. that is also
  // why it is ignored from coverage.
  /* istanbul ignore next */
  const rSlash = new RegExp(
    `[${posix.sep}${sep === posix.sep ? '' : sep}]`.replace(/(\\)/g, '\\$1')
  )
  const rRel = new RegExp(`^\\.${rSlash.source}`)
  const getNotFoundError = cmd =>
    Object.assign(new Error(`not found: ${cmd}`), {
      code: 'ENOENT'
    })
  const getPathInfo = (
    cmd,
    {
      path: optPath = process.env.PATH,
      pathExt: optPathExt = process.env.PATHEXT,
      delimiter: optDelimiter = delimiter
    }
  ) => {
    // If it has a slash, then we don't bother searching the pathenv.
    // just check the file itself, and that's it.
    const pathEnv = cmd.match(rSlash)
      ? ['']
      : [
          // windows always checks the cwd first
          ...(isWindows ? [process.cwd()] : []),
          ...(optPath || /* istanbul ignore next: very unusual */ '').split(
            optDelimiter
          )
        ]
    if (isWindows) {
      const pathExtExe =
        optPathExt || ['.EXE', '.CMD', '.BAT', '.COM'].join(optDelimiter)
      const pathExt = pathExtExe
        .split(optDelimiter)
        .flatMap(item => [item, item.toLowerCase()])
      if (cmd.includes('.') && pathExt[0] !== '') {
        pathExt.unshift('')
      }
      return {
        pathEnv,
        pathExt,
        pathExtExe
      }
    }
    return {
      pathEnv,
      pathExt: ['']
    }
  }
  const getPathPart = (raw, cmd) => {
    const pathPart = /^".*"$/.test(raw) ? raw.slice(1, -1) : raw
    const prefix = !pathPart && rRel.test(cmd) ? cmd.slice(0, 2) : ''
    return prefix + join(pathPart, cmd)
  }
  const which = async (cmd, opt = {}) => {
    const { pathEnv, pathExt, pathExtExe } = getPathInfo(cmd, opt)
    const found = []
    for (const envPart of pathEnv) {
      const p = getPathPart(envPart, cmd)
      for (const ext of pathExt) {
        const withExt = p + ext
        const is = await isexe(withExt, {
          pathExt: pathExtExe,
          ignoreErrors: true
        })
        if (is) {
          if (!opt.all) {
            return withExt
          }
          found.push(withExt)
        }
      }
    }
    if (opt.all && found.length) {
      return found
    }
    if (opt.nothrow) {
      return null
    }
    throw getNotFoundError(cmd)
  }
  const whichSync = (cmd, opt = {}) => {
    const { pathEnv, pathExt, pathExtExe } = getPathInfo(cmd, opt)
    const found = []
    for (const pathEnvPart of pathEnv) {
      const p = getPathPart(pathEnvPart, cmd)
      for (const ext of pathExt) {
        const withExt = p + ext
        const is = isexeSync(withExt, {
          pathExt: pathExtExe,
          ignoreErrors: true
        })
        if (is) {
          if (!opt.all) {
            return withExt
          }
          found.push(withExt)
        }
      }
    }
    if (opt.all && found.length) {
      return found
    }
    if (opt.nothrow) {
      return null
    }
    throw getNotFoundError(cmd)
  }
  lib$7 = which
  which.sync = whichSync
  return lib$7
}

let _escape
let hasRequired_escape
function require_escape() {
  if (hasRequired_escape) {
    return _escape
  }
  hasRequired_escape = 1

  // eslint-disable-next-line max-len
  // this code adapted from: https://blogs.msdn.microsoft.com/twistylittlepassagesallalike/2011/04/23/everyone-quotes-command-line-arguments-the-wrong-way/
  const cmd = (input, doubleEscape) => {
    if (!input.length) {
      return '""'
    }
    let result
    if (!/[ \t\n\v"]/.test(input)) {
      result = input
    } else {
      result = '"'
      for (let i = 0; i <= input.length; ++i) {
        let slashCount = 0
        while (input[i] === '\\') {
          ++i
          ++slashCount
        }
        if (i === input.length) {
          result += '\\'.repeat(slashCount * 2)
          break
        }
        if (input[i] === '"') {
          result += '\\'.repeat(slashCount * 2 + 1)
          result += input[i]
        } else {
          result += '\\'.repeat(slashCount)
          result += input[i]
        }
      }
      result += '"'
    }

    // and finally, prefix shell meta chars with a ^
    result = result.replace(/[ !%^&()<>|"]/g, '^$&')
    if (doubleEscape) {
      result = result.replace(/[ !%^&()<>|"]/g, '^$&')
    }
    return result
  }
  const sh = input => {
    if (!input.length) {
      return `''`
    }
    if (!/[\t\n\r "#$&'()*;<>?\\`|~]/.test(input)) {
      return input
    }

    // replace single quotes with '\'' and wrap the whole result in a fresh set of quotes
    const result = `'${input.replace(/'/g, `'\\''`)}'`
      // if the input string already had single quotes around it, clean those up
      .replace(/^(?:'')+(?!$)/, '')
      .replace(/\\'''/g, `\\'`)
    return result
  }
  _escape = {
    cmd,
    sh
  }
  return _escape
}

let lib$6
let hasRequiredLib$6
function requireLib$6() {
  if (hasRequiredLib$6) {
    return lib$6
  }
  hasRequiredLib$6 = 1
  const { spawn } = require$$0$4
  const os = require$$1$5
  const which = requireLib$7()
  const escape = require_escape()

  // 'extra' object is for decorating the error a bit more
  const promiseSpawn = (cmd, args, opts = {}, extra = {}) => {
    if (opts.shell) {
      return spawnWithShell(cmd, args, opts, extra)
    }
    let resolve, reject
    const promise = new Promise((_resolve, _reject) => {
      resolve = _resolve
      reject = _reject
    })

    // Create error here so we have a more useful stack trace when rejecting
    const closeError = new Error('command failed')
    const stdout = []
    const stderr = []
    const getResult = result => ({
      cmd,
      args,
      ...result,
      ...stdioResult(stdout, stderr, opts),
      ...extra
    })
    const rejectWithOpts = (er, erOpts) => {
      const resultError = getResult(erOpts)
      reject(Object.assign(er, resultError))
    }
    const proc = spawn(cmd, args, opts)
    promise.stdin = proc.stdin
    promise.process = proc
    proc.on('error', rejectWithOpts)
    if (proc.stdout) {
      proc.stdout.on('data', c => stdout.push(c))
      proc.stdout.on('error', rejectWithOpts)
    }
    if (proc.stderr) {
      proc.stderr.on('data', c => stderr.push(c))
      proc.stderr.on('error', rejectWithOpts)
    }
    proc.on('close', (code, signal) => {
      if (code || signal) {
        rejectWithOpts(closeError, {
          code,
          signal
        })
      } else {
        resolve(
          getResult({
            code,
            signal
          })
        )
      }
    })
    return promise
  }
  const spawnWithShell = (cmd, args, opts, extra) => {
    let command = opts.shell
    // if shell is set to true, we use a platform default. we can't let the core
    // spawn method decide this for us because we need to know what shell is in use
    // ahead of time so that we can escape arguments properly. we don't need coverage here.
    if (command === true) {
      // istanbul ignore next
      command = process.platform === 'win32' ? process.env.ComSpec : 'sh'
    }
    const options = {
      ...opts,
      shell: false
    }
    const realArgs = []
    let script = cmd

    // first, determine if we're in windows because if we are we need to know if we're
    // running an .exe or a .cmd/.bat since the latter requires extra escaping
    const isCmd = /(?:^|\\)cmd(?:\.exe)?$/i.test(command)
    if (isCmd) {
      let doubleEscape = false

      // find the actual command we're running
      let initialCmd = ''
      let insideQuotes = false
      for (let i = 0; i < cmd.length; ++i) {
        const char = cmd.charAt(i)
        if (char === ' ' && !insideQuotes) {
          break
        }
        initialCmd += char
        if (char === '"' || char === "'") {
          insideQuotes = !insideQuotes
        }
      }
      let pathToInitial
      try {
        pathToInitial = which
          .sync(initialCmd, {
            path:
              (options.env && findInObject(options.env, 'PATH')) ||
              process.env.PATH,
            pathext:
              (options.env && findInObject(options.env, 'PATHEXT')) ||
              process.env.PATHEXT
          })
          .toLowerCase()
      } catch (err) {
        pathToInitial = initialCmd.toLowerCase()
      }
      doubleEscape =
        pathToInitial.endsWith('.cmd') || pathToInitial.endsWith('.bat')
      for (const arg of args) {
        script += ` ${escape.cmd(arg, doubleEscape)}`
      }
      realArgs.push('/d', '/s', '/c', script)
      options.windowsVerbatimArguments = true
    } else {
      for (const arg of args) {
        script += ` ${escape.sh(arg)}`
      }
      realArgs.push('-c', script)
    }
    return promiseSpawn(command, realArgs, options, extra)
  }

  // open a file with the default application as defined by the user's OS
  const open = (_args, opts = {}, extra = {}) => {
    const options = {
      ...opts,
      shell: true
    }
    const args = [].concat(_args)
    let platform = process.platform
    // process.platform === 'linux' may actually indicate WSL, if that's the case
    // open the argument with sensible-browser which is pre-installed
    // In WSL, set the default browser using, for example,
    // export BROWSER="/mnt/c/Program Files (x86)/Google/Chrome/Application/chrome.exe"
    // or
    // export BROWSER="/mnt/c/Program Files (x86)/Microsoft/Edge/Application/msedge.exe"
    // To permanently set the default browser, add the appropriate entry to your shell's
    // RC file, e.g. .bashrc or .zshrc.
    if (
      platform === 'linux' &&
      os.release().toLowerCase().includes('microsoft')
    ) {
      platform = 'wsl'
      if (!process.env.BROWSER) {
        return Promise.reject(
          new Error(
            'Set the BROWSER environment variable to your desired browser.'
          )
        )
      }
    }
    let command = options.command
    if (!command) {
      if (platform === 'win32') {
        // spawnWithShell does not do the additional os.release() check, so we
        // have to force the shell here to make sure we treat WSL as windows.
        options.shell = process.env.ComSpec
        // also, the start command accepts a title so to make sure that we don't
        // accidentally interpret the first arg as the title, we stick an empty
        // string immediately after the start command
        command = 'start ""'
      } else if (platform === 'wsl') {
        command = 'sensible-browser'
      } else if (platform === 'darwin') {
        command = 'open'
      } else {
        command = 'xdg-open'
      }
    }
    return spawnWithShell(command, args, options, extra)
  }
  promiseSpawn.open = open
  const isPipe = (stdio = 'pipe', fd) => {
    if (stdio === 'pipe' || stdio === null) {
      return true
    }
    if (Array.isArray(stdio)) {
      return isPipe(stdio[fd], fd)
    }
    return false
  }
  const stdioResult = (stdout, stderr, { stdioString = true, stdio }) => {
    const result = {
      stdout: null,
      stderr: null
    }

    // stdio is [stdin, stdout, stderr]
    if (isPipe(stdio, 1)) {
      result.stdout = Buffer.concat(stdout)
      if (stdioString) {
        result.stdout = result.stdout.toString().trim()
      }
    }
    if (isPipe(stdio, 2)) {
      result.stderr = Buffer.concat(stderr)
      if (stdioString) {
        result.stderr = result.stderr.toString().trim()
      }
    }
    return result
  }

  // case insensitive lookup in an object
  const findInObject = (obj, key) => {
    key = key.toLowerCase()
    for (const objKey of Object.keys(obj).sort()) {
      if (objKey.toLowerCase() === key) {
        return obj[objKey]
      }
    }
  }
  lib$6 = promiseSpawn
  return lib$6
}

let errCode
let hasRequiredErrCode
function requireErrCode() {
  if (hasRequiredErrCode) {
    return errCode
  }
  hasRequiredErrCode = 1
  function assign(obj, props) {
    for (const key in props) {
      Object.defineProperty(obj, key, {
        value: props[key],
        enumerable: true,
        configurable: true
      })
    }
    return obj
  }
  function createError(err, code, props) {
    if (!err || typeof err === 'string') {
      throw new TypeError('Please pass an Error to err-code')
    }
    if (!props) {
      props = {}
    }
    if (typeof code === 'object') {
      props = code
      code = undefined
    }
    if (code != null) {
      props.code = code
    }
    try {
      return assign(err, props)
    } catch (_) {
      props.message = err.message
      props.stack = err.stack
      const ErrClass = function () {}
      ErrClass.prototype = Object.create(Object.getPrototypeOf(err))
      return assign(new ErrClass(), props)
    }
  }
  errCode = createError
  return errCode
}

const retry$1 = {}

let retry_operation
let hasRequiredRetry_operation
function requireRetry_operation() {
  if (hasRequiredRetry_operation) {
    return retry_operation
  }
  hasRequiredRetry_operation = 1
  function RetryOperation(timeouts, options) {
    // Compatibility for the old (timeouts, retryForever) signature
    if (typeof options === 'boolean') {
      options = {
        forever: options
      }
    }
    this._originalTimeouts = JSON.parse(JSON.stringify(timeouts))
    this._timeouts = timeouts
    this._options = options || {}
    this._maxRetryTime = (options && options.maxRetryTime) || Infinity
    this._fn = null
    this._errors = []
    this._attempts = 1
    this._operationTimeout = null
    this._operationTimeoutCb = null
    this._timeout = null
    this._operationStart = null
    if (this._options.forever) {
      this._cachedTimeouts = this._timeouts.slice(0)
    }
  }
  retry_operation = RetryOperation
  RetryOperation.prototype.reset = function () {
    this._attempts = 1
    this._timeouts = this._originalTimeouts
  }
  RetryOperation.prototype.stop = function () {
    if (this._timeout) {
      clearTimeout(this._timeout)
    }
    this._timeouts = []
    this._cachedTimeouts = null
  }
  RetryOperation.prototype.retry = function (err) {
    if (this._timeout) {
      clearTimeout(this._timeout)
    }
    if (!err) {
      return false
    }
    const currentTime = new Date().getTime()
    if (err && currentTime - this._operationStart >= this._maxRetryTime) {
      this._errors.unshift(new Error('RetryOperation timeout occurred'))
      return false
    }
    this._errors.push(err)
    let timeout = this._timeouts.shift()
    if (timeout === undefined) {
      if (this._cachedTimeouts) {
        // retry forever, only keep last error
        this._errors.splice(this._errors.length - 1, this._errors.length)
        this._timeouts = this._cachedTimeouts.slice(0)
        timeout = this._timeouts.shift()
      } else {
        return false
      }
    }
    const self = this
    const timer = setTimeout(function () {
      self._attempts++
      if (self._operationTimeoutCb) {
        self._timeout = setTimeout(function () {
          self._operationTimeoutCb(self._attempts)
        }, self._operationTimeout)
        if (self._options.unref) {
          self._timeout.unref()
        }
      }
      self._fn(self._attempts)
    }, timeout)
    if (this._options.unref) {
      timer.unref()
    }
    return true
  }
  RetryOperation.prototype.attempt = function (fn, timeoutOps) {
    this._fn = fn
    if (timeoutOps) {
      if (timeoutOps.timeout) {
        this._operationTimeout = timeoutOps.timeout
      }
      if (timeoutOps.cb) {
        this._operationTimeoutCb = timeoutOps.cb
      }
    }
    const self = this
    if (this._operationTimeoutCb) {
      this._timeout = setTimeout(function () {
        self._operationTimeoutCb()
      }, self._operationTimeout)
    }
    this._operationStart = new Date().getTime()
    this._fn(this._attempts)
  }
  RetryOperation.prototype.try = function (fn) {
    console.log('Using RetryOperation.try() is deprecated')
    this.attempt(fn)
  }
  RetryOperation.prototype.start = function (fn) {
    console.log('Using RetryOperation.start() is deprecated')
    this.attempt(fn)
  }
  RetryOperation.prototype.start = RetryOperation.prototype.try
  RetryOperation.prototype.errors = function () {
    return this._errors
  }
  RetryOperation.prototype.attempts = function () {
    return this._attempts
  }
  RetryOperation.prototype.mainError = function () {
    if (this._errors.length === 0) {
      return null
    }
    const counts = {}
    let mainError = null
    let mainErrorCount = 0
    for (let i = 0; i < this._errors.length; i++) {
      const error = this._errors[i]
      const message = error.message
      const count = (counts[message] || 0) + 1
      counts[message] = count
      if (count >= mainErrorCount) {
        mainError = error
        mainErrorCount = count
      }
    }
    return mainError
  }
  return retry_operation
}

let hasRequiredRetry$1
function requireRetry$1() {
  if (hasRequiredRetry$1) {
    return retry$1
  }
  hasRequiredRetry$1 = 1
  ;(function (exports) {
    const RetryOperation = requireRetry_operation()
    exports.operation = function (options) {
      const timeouts = exports.timeouts(options)
      return new RetryOperation(timeouts, {
        forever: options && options.forever,
        unref: options && options.unref,
        maxRetryTime: options && options.maxRetryTime
      })
    }
    exports.timeouts = function (options) {
      if (options instanceof Array) {
        return [].concat(options)
      }
      const opts = {
        retries: 10,
        factor: 2,
        minTimeout: 1 * 1000,
        maxTimeout: Infinity,
        randomize: false
      }
      for (const key in options) {
        opts[key] = options[key]
      }
      if (opts.minTimeout > opts.maxTimeout) {
        throw new Error('minTimeout is greater than maxTimeout')
      }
      const timeouts = []
      for (var i = 0; i < opts.retries; i++) {
        timeouts.push(this.createTimeout(i, opts))
      }
      if (options && options.forever && !timeouts.length) {
        timeouts.push(this.createTimeout(i, opts))
      }

      // sort the array numerically ascending
      timeouts.sort(function (a, b) {
        return a - b
      })
      return timeouts
    }
    exports.createTimeout = function (attempt, opts) {
      const random = opts.randomize ? Math.random() + 1 : 1
      let timeout = Math.round(
        random * opts.minTimeout * Math.pow(opts.factor, attempt)
      )
      timeout = Math.min(timeout, opts.maxTimeout)
      return timeout
    }
    exports.wrap = function (obj, options, methods) {
      if (options instanceof Array) {
        methods = options
        options = null
      }
      if (!methods) {
        methods = []
        for (const key in obj) {
          if (typeof obj[key] === 'function') {
            methods.push(key)
          }
        }
      }
      for (let i = 0; i < methods.length; i++) {
        const method = methods[i]
        const original = obj[method]
        obj[method] = function retryWrapper(original) {
          const op = exports.operation(options)
          const args = Array.prototype.slice.call(arguments, 1)
          const callback = args.pop()
          args.push(function (err) {
            if (op.retry(err)) {
              return
            }
            if (err) {
              arguments[0] = op.mainError()
            }
            callback.apply(this, arguments)
          })
          op.attempt(function () {
            original.apply(obj, args)
          })
        }.bind(obj, original)
        obj[method].options = options
      }
    }
  })(retry$1)
  return retry$1
}

let retry
let hasRequiredRetry
function requireRetry() {
  if (hasRequiredRetry) {
    return retry
  }
  hasRequiredRetry = 1
  retry = requireRetry$1()
  return retry
}

let promiseRetry_1
let hasRequiredPromiseRetry
function requirePromiseRetry() {
  if (hasRequiredPromiseRetry) {
    return promiseRetry_1
  }
  hasRequiredPromiseRetry = 1
  const errcode = requireErrCode()
  const retry = requireRetry()
  const hasOwn = Object.prototype.hasOwnProperty
  function isRetryError(err) {
    return err && err.code === 'EPROMISERETRY' && hasOwn.call(err, 'retried')
  }
  function promiseRetry(fn, options) {
    let temp
    let operation
    if (typeof fn === 'object' && typeof options === 'function') {
      // Swap options and fn when using alternate signature (options, fn)
      temp = options
      options = fn
      fn = temp
    }
    operation = retry.operation(options)
    return new Promise(function (resolve, reject) {
      operation.attempt(function (number) {
        Promise.resolve()
          .then(function () {
            return fn(function (err) {
              if (isRetryError(err)) {
                err = err.retried
              }
              throw errcode(new Error('Retrying'), 'EPROMISERETRY', {
                retried: err
              })
            }, number)
          })
          .then(resolve, function (err) {
            if (isRetryError(err)) {
              err = err.retried
              if (operation.retry(err || new Error())) {
                return
              }
            }
            reject(err)
          })
      })
    })
  }
  promiseRetry_1 = promiseRetry
  return promiseRetry_1
}

let errors
let hasRequiredErrors
function requireErrors() {
  if (hasRequiredErrors) {
    return errors
  }
  hasRequiredErrors = 1
  const maxRetry = 3
  class GitError extends Error {
    shouldRetry() {
      return false
    }
  }
  class GitConnectionError extends GitError {
    constructor() {
      super('A git connection error occurred')
    }
    shouldRetry(number) {
      return number < maxRetry
    }
  }
  class GitPathspecError extends GitError {
    constructor() {
      super('The git reference could not be found')
    }
  }
  class GitUnknownError extends GitError {
    constructor() {
      super('An unknown git error occurred')
    }
  }
  errors = {
    GitConnectionError,
    GitPathspecError,
    GitUnknownError
  }
  return errors
}

let makeError_1
let hasRequiredMakeError
function requireMakeError() {
  if (hasRequiredMakeError) {
    return makeError_1
  }
  hasRequiredMakeError = 1
  const { GitConnectionError, GitPathspecError, GitUnknownError } =
    requireErrors()
  const connectionErrorRe = new RegExp(
    [
      'remote error: Internal Server Error',
      'The remote end hung up unexpectedly',
      'Connection timed out',
      'Operation timed out',
      'Failed to connect to .* Timed out',
      'Connection reset by peer',
      'SSL_ERROR_SYSCALL',
      'The requested URL returned error: 503'
    ].join('|')
  )
  const missingPathspecRe =
    /pathspec .* did not match any file\(s\) known to git/
  function makeError(er) {
    const message = er.stderr
    let gitEr
    if (connectionErrorRe.test(message)) {
      gitEr = new GitConnectionError(message)
    } else if (missingPathspecRe.test(message)) {
      gitEr = new GitPathspecError(message)
    } else {
      gitEr = new GitUnknownError(message)
    }
    return Object.assign(gitEr, er)
  }
  makeError_1 = makeError
  return makeError_1
}

const opts = { exports: {} }

let ini
let hasRequiredIni
function requireIni() {
  if (hasRequiredIni) {
    return ini
  }
  hasRequiredIni = 1
  const { hasOwnProperty } = Object.prototype
  const encode = (obj, opt = {}) => {
    if (typeof opt === 'string') {
      opt = {
        section: opt
      }
    }
    opt.align = opt.align === true
    opt.newline = opt.newline === true
    opt.sort = opt.sort === true
    opt.whitespace = opt.whitespace === true || opt.align === true
    // The `typeof` check is required because accessing the `process` directly fails on browsers.
    /* istanbul ignore next */
    opt.platform =
      opt.platform || (typeof process !== 'undefined' && process.platform)
    opt.bracketedArray = opt.bracketedArray !== false

    /* istanbul ignore next */
    const eol = opt.platform === 'win32' ? '\r\n' : '\n'
    const separator = opt.whitespace ? ' = ' : '='
    const children = []
    const keys = opt.sort ? Object.keys(obj).sort() : Object.keys(obj)
    let padToChars = 0
    // If aligning on the separator, then padToChars is determined as follows:
    // 1. Get the keys
    // 2. Exclude keys pointing to objects unless the value is null or an array
    // 3. Add `[]` to array keys
    // 4. Ensure non empty set of keys
    // 5. Reduce the set to the longest `safe` key
    // 6. Get the `safe` length
    if (opt.align) {
      padToChars = safe(
        keys
          .filter(
            k =>
              obj[k] === null ||
              Array.isArray(obj[k]) ||
              typeof obj[k] !== 'object'
          )
          .map(k => (Array.isArray(obj[k]) ? `${k}[]` : k))
          .concat([''])
          .reduce((a, b) => (safe(a).length >= safe(b).length ? a : b))
      ).length
    }
    let out = ''
    const arraySuffix = opt.bracketedArray ? '[]' : ''
    for (const k of keys) {
      const val = obj[k]
      if (val && Array.isArray(val)) {
        for (const item of val) {
          out +=
            safe(`${k}${arraySuffix}`).padEnd(padToChars, ' ') +
            separator +
            safe(item) +
            eol
        }
      } else if (val && typeof val === 'object') {
        children.push(k)
      } else {
        out += safe(k).padEnd(padToChars, ' ') + separator + safe(val) + eol
      }
    }
    if (opt.section && out.length) {
      out =
        '[' + safe(opt.section) + ']' + (opt.newline ? eol + eol : eol) + out
    }
    for (const k of children) {
      const nk = splitSections(k, '.').join('\\.')
      const section = (opt.section ? opt.section + '.' : '') + nk
      const child = encode(obj[k], {
        ...opt,
        section
      })
      if (out.length && child.length) {
        out += eol
      }
      out += child
    }
    return out
  }
  function splitSections(str, separator) {
    let lastMatchIndex = 0
    let lastSeparatorIndex = 0
    let nextIndex = 0
    const sections = []
    do {
      nextIndex = str.indexOf(separator, lastMatchIndex)
      if (nextIndex !== -1) {
        lastMatchIndex = nextIndex + separator.length
        if (nextIndex > 0 && str[nextIndex - 1] === '\\') {
          continue
        }
        sections.push(str.slice(lastSeparatorIndex, nextIndex))
        lastSeparatorIndex = nextIndex + separator.length
      }
    } while (nextIndex !== -1)
    sections.push(str.slice(lastSeparatorIndex))
    return sections
  }
  const decode = (str, opt = {}) => {
    opt.bracketedArray = opt.bracketedArray !== false
    const out = Object.create(null)
    let p = out
    let section = null
    //          section          |key      = value
    const re = /^\[([^\]]*)\]\s*$|^([^=]+)(=(.*))?$/i
    const lines = str.split(/[\r\n]+/g)
    const duplicates = {}
    for (const line of lines) {
      if (!line || line.match(/^\s*[;#]/) || line.match(/^\s*$/)) {
        continue
      }
      const match = line.match(re)
      if (!match) {
        continue
      }
      if (match[1] !== undefined) {
        section = unsafe(match[1])
        if (section === '__proto__') {
          // not allowed
          // keep parsing the section, but don't attach it.
          p = Object.create(null)
          continue
        }
        p = out[section] = out[section] || Object.create(null)
        continue
      }
      const keyRaw = unsafe(match[2])
      let isArray
      if (opt.bracketedArray) {
        isArray = keyRaw.length > 2 && keyRaw.slice(-2) === '[]'
      } else {
        duplicates[keyRaw] = (duplicates?.[keyRaw] || 0) + 1
        isArray = duplicates[keyRaw] > 1
      }
      const key =
        isArray && keyRaw.endsWith('[]') ? keyRaw.slice(0, -2) : keyRaw
      if (key === '__proto__') {
        continue
      }
      const valueRaw = match[3] ? unsafe(match[4]) : true
      const value =
        valueRaw === 'true' || valueRaw === 'false' || valueRaw === 'null'
          ? JSON.parse(valueRaw)
          : valueRaw

      // Convert keys with '[]' suffix to an array
      if (isArray) {
        if (!hasOwnProperty.call(p, key)) {
          p[key] = []
        } else if (!Array.isArray(p[key])) {
          p[key] = [p[key]]
        }
      }

      // safeguard against resetting a previously defined
      // array by accidentally forgetting the brackets
      if (Array.isArray(p[key])) {
        p[key].push(value)
      } else {
        p[key] = value
      }
    }

    // {a:{y:1},"a.b":{x:2}} --> {a:{y:1,b:{x:2}}}
    // use a filter to return the keys that have to be deleted.
    const remove = []
    for (const k of Object.keys(out)) {
      if (
        !hasOwnProperty.call(out, k) ||
        typeof out[k] !== 'object' ||
        Array.isArray(out[k])
      ) {
        continue
      }

      // see if the parent section is also an object.
      // if so, add it to that, and mark this one for deletion
      const parts = splitSections(k, '.')
      p = out
      const l = parts.pop()
      const nl = l.replace(/\\\./g, '.')
      for (const part of parts) {
        if (part === '__proto__') {
          continue
        }
        if (!hasOwnProperty.call(p, part) || typeof p[part] !== 'object') {
          p[part] = Object.create(null)
        }
        p = p[part]
      }
      if (p === out && nl === l) {
        continue
      }
      p[nl] = out[k]
      remove.push(k)
    }
    for (const del of remove) {
      delete out[del]
    }
    return out
  }
  const isQuoted = val => {
    return (
      (val.startsWith('"') && val.endsWith('"')) ||
      (val.startsWith("'") && val.endsWith("'"))
    )
  }
  const safe = val => {
    if (
      typeof val !== 'string' ||
      val.match(/[=\r\n]/) ||
      val.match(/^\[/) ||
      (val.length > 1 && isQuoted(val)) ||
      val !== val.trim()
    ) {
      return JSON.stringify(val)
    }
    return val.split(';').join('\\;').split('#').join('\\#')
  }
  const unsafe = val => {
    val = (val || '').trim()
    if (isQuoted(val)) {
      // remove the single quotes before calling JSON.parse
      if (val.charAt(0) === "'") {
        val = val.slice(1, -1)
      }
      try {
        val = JSON.parse(val)
      } catch {
        // ignore errors
      }
    } else {
      // walk the val to find the first not-escaped ; character
      let esc = false
      let unesc = ''
      for (let i = 0, l = val.length; i < l; i++) {
        const c = val.charAt(i)
        if (esc) {
          if ('\\;#'.indexOf(c) !== -1) {
            unesc += c
          } else {
            unesc += '\\' + c
          }
          esc = false
        } else if (';#'.indexOf(c) !== -1) {
          break
        } else if (c === '\\') {
          esc = true
        } else {
          unesc += c
        }
      }
      if (esc) {
        unesc += '\\'
      }
      return unesc.trim()
    }
    return val
  }
  ini = {
    parse: decode,
    decode,
    stringify: encode,
    encode,
    safe,
    unsafe
  }
  return ini
}

let hasRequiredOpts
function requireOpts() {
  if (hasRequiredOpts) {
    return opts.exports
  }
  hasRequiredOpts = 1
  const fs = require$$4
  const os = require$$1$6
  const path = require$$2$2
  const ini = requireIni()
  const gitConfigPath = path.join(os.homedir(), '.gitconfig')
  let cachedConfig = null

  // Function to load and cache the git config
  const loadGitConfig = () => {
    if (cachedConfig === null) {
      try {
        cachedConfig = {}
        if (fs.existsSync(gitConfigPath)) {
          const configContent = fs.readFileSync(gitConfigPath, 'utf-8')
          cachedConfig = ini.parse(configContent)
        }
      } catch (error) {
        cachedConfig = {}
      }
    }
    return cachedConfig
  }
  const checkGitConfigs = () => {
    const config = loadGitConfig()
    return {
      sshCommandSetInConfig: config?.core?.sshCommand !== undefined,
      askPassSetInConfig: config?.core?.askpass !== undefined
    }
  }
  const sshCommandSetInEnv = process.env.GIT_SSH_COMMAND !== undefined
  const askPassSetInEnv = process.env.GIT_ASKPASS !== undefined
  const { sshCommandSetInConfig, askPassSetInConfig } = checkGitConfigs()

  // Values we want to set if they're not already defined by the end user
  // This defaults to accepting new ssh host key fingerprints
  const finalGitEnv = {
    ...(askPassSetInEnv || askPassSetInConfig
      ? {}
      : {
          GIT_ASKPASS: 'echo'
        }),
    ...(sshCommandSetInEnv || sshCommandSetInConfig
      ? {}
      : {
          GIT_SSH_COMMAND: 'ssh -oStrictHostKeyChecking=accept-new'
        })
  }
  opts.exports = (opts = {}) => ({
    stdioString: true,
    ...opts,
    shell: false,
    env: opts.env || {
      ...finalGitEnv,
      ...process.env
    }
  })

  // Export the loadGitConfig function for testing
  opts.exports.loadGitConfig = loadGitConfig
  return opts.exports
}

let which_1
let hasRequiredWhich
function requireWhich() {
  if (hasRequiredWhich) {
    return which_1
  }
  hasRequiredWhich = 1
  const which = requireLib$7()
  let gitPath
  try {
    gitPath = which.sync('git')
  } catch {
    // ignore errors
  }
  which_1 = (opts = {}) => {
    if (opts.git) {
      return opts.git
    }
    if (!gitPath || opts.git === false) {
      return Object.assign(new Error('No git binary found in $PATH'), {
        code: 'ENOGIT'
      })
    }
    return gitPath
  }
  return which_1
}

let spawn_1
let hasRequiredSpawn
function requireSpawn() {
  if (hasRequiredSpawn) {
    return spawn_1
  }
  hasRequiredSpawn = 1
  const spawn = requireLib$6()
  const promiseRetry = requirePromiseRetry()
  const { log } = requireLib$9()
  const makeError = requireMakeError()
  const makeOpts = requireOpts()
  spawn_1 = (gitArgs, opts = {}) => {
    const whichGit = requireWhich()
    const gitPath = whichGit(opts)
    if (gitPath instanceof Error) {
      return Promise.reject(gitPath)
    }

    // undocumented option, mostly only here for tests
    const args =
      opts.allowReplace || gitArgs[0] === '--no-replace-objects'
        ? gitArgs
        : ['--no-replace-objects', ...gitArgs]
    let retryOpts = opts.retry
    if (retryOpts === null || retryOpts === undefined) {
      retryOpts = {
        retries: opts.fetchRetries || 2,
        factor: opts.fetchRetryFactor || 10,
        maxTimeout: opts.fetchRetryMaxtimeout || 60000,
        minTimeout: opts.fetchRetryMintimeout || 1000
      }
    }
    return promiseRetry((retryFn, number) => {
      if (number !== 1) {
        log.silly(
          'git',
          `Retrying git command: ${args.join(' ')} attempt # ${number}`
        )
      }
      return spawn(gitPath, args, makeOpts(opts)).catch(er => {
        const gitError = makeError(er)
        if (!gitError.shouldRetry(number)) {
          throw gitError
        }
        retryFn(gitError)
      })
    }, retryOpts)
  }
  return spawn_1
}

let inc_1
let hasRequiredInc
function requireInc() {
  if (hasRequiredInc) {
    return inc_1
  }
  hasRequiredInc = 1
  const SemVer = requireSemver$1()
  const inc = (version, release, options, identifier, identifierBase) => {
    if (typeof options === 'string') {
      identifierBase = identifier
      identifier = options
      options = undefined
    }
    try {
      return new SemVer(
        version instanceof SemVer ? version.version : version,
        options
      ).inc(release, identifier, identifierBase).version
    } catch (er) {
      return null
    }
  }
  inc_1 = inc
  return inc_1
}

let diff_1
let hasRequiredDiff
function requireDiff() {
  if (hasRequiredDiff) {
    return diff_1
  }
  hasRequiredDiff = 1
  const parse = requireParse$2()
  const diff = (version1, version2) => {
    const v1 = parse(version1, null, true)
    const v2 = parse(version2, null, true)
    const comparison = v1.compare(v2)
    if (comparison === 0) {
      return null
    }
    const v1Higher = comparison > 0
    const highVersion = v1Higher ? v1 : v2
    const lowVersion = v1Higher ? v2 : v1
    const highHasPre = !!highVersion.prerelease.length
    const lowHasPre = !!lowVersion.prerelease.length
    if (lowHasPre && !highHasPre) {
      // Going from prerelease -> no prerelease requires some special casing

      // If the low version has only a major, then it will always be a major
      // Some examples:
      // 1.0.0-1 -> 1.0.0
      // 1.0.0-1 -> 1.1.1
      // 1.0.0-1 -> 2.0.0
      if (!lowVersion.patch && !lowVersion.minor) {
        return 'major'
      }

      // If the main part has no difference
      if (lowVersion.compareMain(highVersion) === 0) {
        if (lowVersion.minor && !lowVersion.patch) {
          return 'minor'
        }
        return 'patch'
      }
    }

    // add the `pre` prefix if we are going to a prerelease version
    const prefix = highHasPre ? 'pre' : ''
    if (v1.major !== v2.major) {
      return prefix + 'major'
    }
    if (v1.minor !== v2.minor) {
      return prefix + 'minor'
    }
    if (v1.patch !== v2.patch) {
      return prefix + 'patch'
    }

    // high and low are preleases
    return 'prerelease'
  }
  diff_1 = diff
  return diff_1
}

let major_1
let hasRequiredMajor
function requireMajor() {
  if (hasRequiredMajor) {
    return major_1
  }
  hasRequiredMajor = 1
  const SemVer = requireSemver$1()
  const major = (a, loose) => new SemVer(a, loose).major
  major_1 = major
  return major_1
}

let minor_1
let hasRequiredMinor
function requireMinor() {
  if (hasRequiredMinor) {
    return minor_1
  }
  hasRequiredMinor = 1
  const SemVer = requireSemver$1()
  const minor = (a, loose) => new SemVer(a, loose).minor
  minor_1 = minor
  return minor_1
}

let patch_1
let hasRequiredPatch
function requirePatch() {
  if (hasRequiredPatch) {
    return patch_1
  }
  hasRequiredPatch = 1
  const SemVer = requireSemver$1()
  const patch = (a, loose) => new SemVer(a, loose).patch
  patch_1 = patch
  return patch_1
}

let prerelease_1
let hasRequiredPrerelease
function requirePrerelease() {
  if (hasRequiredPrerelease) {
    return prerelease_1
  }
  hasRequiredPrerelease = 1
  const parse = requireParse$2()
  const prerelease = (version, options) => {
    const parsed = parse(version, options)
    return parsed && parsed.prerelease.length ? parsed.prerelease : null
  }
  prerelease_1 = prerelease
  return prerelease_1
}

let compare_1
let hasRequiredCompare
function requireCompare() {
  if (hasRequiredCompare) {
    return compare_1
  }
  hasRequiredCompare = 1
  const SemVer = requireSemver$1()
  const compare = (a, b, loose) =>
    new SemVer(a, loose).compare(new SemVer(b, loose))
  compare_1 = compare
  return compare_1
}

let rcompare_1
let hasRequiredRcompare
function requireRcompare() {
  if (hasRequiredRcompare) {
    return rcompare_1
  }
  hasRequiredRcompare = 1
  const compare = requireCompare()
  const rcompare = (a, b, loose) => compare(b, a, loose)
  rcompare_1 = rcompare
  return rcompare_1
}

let compareLoose_1
let hasRequiredCompareLoose
function requireCompareLoose() {
  if (hasRequiredCompareLoose) {
    return compareLoose_1
  }
  hasRequiredCompareLoose = 1
  const compare = requireCompare()
  const compareLoose = (a, b) => compare(a, b, true)
  compareLoose_1 = compareLoose
  return compareLoose_1
}

let compareBuild_1
let hasRequiredCompareBuild
function requireCompareBuild() {
  if (hasRequiredCompareBuild) {
    return compareBuild_1
  }
  hasRequiredCompareBuild = 1
  const SemVer = requireSemver$1()
  const compareBuild = (a, b, loose) => {
    const versionA = new SemVer(a, loose)
    const versionB = new SemVer(b, loose)
    return versionA.compare(versionB) || versionA.compareBuild(versionB)
  }
  compareBuild_1 = compareBuild
  return compareBuild_1
}

let sort_1
let hasRequiredSort$1
function requireSort$1() {
  if (hasRequiredSort$1) {
    return sort_1
  }
  hasRequiredSort$1 = 1
  const compareBuild = requireCompareBuild()
  const sort = (list, loose) => list.sort((a, b) => compareBuild(a, b, loose))
  sort_1 = sort
  return sort_1
}

let rsort_1
let hasRequiredRsort
function requireRsort() {
  if (hasRequiredRsort) {
    return rsort_1
  }
  hasRequiredRsort = 1
  const compareBuild = requireCompareBuild()
  const rsort = (list, loose) => list.sort((a, b) => compareBuild(b, a, loose))
  rsort_1 = rsort
  return rsort_1
}

let gt_1
let hasRequiredGt
function requireGt() {
  if (hasRequiredGt) {
    return gt_1
  }
  hasRequiredGt = 1
  const compare = requireCompare()
  const gt = (a, b, loose) => compare(a, b, loose) > 0
  gt_1 = gt
  return gt_1
}

let lt_1
let hasRequiredLt
function requireLt() {
  if (hasRequiredLt) {
    return lt_1
  }
  hasRequiredLt = 1
  const compare = requireCompare()
  const lt = (a, b, loose) => compare(a, b, loose) < 0
  lt_1 = lt
  return lt_1
}

let eq_1
let hasRequiredEq
function requireEq() {
  if (hasRequiredEq) {
    return eq_1
  }
  hasRequiredEq = 1
  const compare = requireCompare()
  const eq = (a, b, loose) => compare(a, b, loose) === 0
  eq_1 = eq
  return eq_1
}

let neq_1
let hasRequiredNeq
function requireNeq() {
  if (hasRequiredNeq) {
    return neq_1
  }
  hasRequiredNeq = 1
  const compare = requireCompare()
  const neq = (a, b, loose) => compare(a, b, loose) !== 0
  neq_1 = neq
  return neq_1
}

let gte_1
let hasRequiredGte
function requireGte() {
  if (hasRequiredGte) {
    return gte_1
  }
  hasRequiredGte = 1
  const compare = requireCompare()
  const gte = (a, b, loose) => compare(a, b, loose) >= 0
  gte_1 = gte
  return gte_1
}

let lte_1
let hasRequiredLte
function requireLte() {
  if (hasRequiredLte) {
    return lte_1
  }
  hasRequiredLte = 1
  const compare = requireCompare()
  const lte = (a, b, loose) => compare(a, b, loose) <= 0
  lte_1 = lte
  return lte_1
}

let cmp_1
let hasRequiredCmp
function requireCmp() {
  if (hasRequiredCmp) {
    return cmp_1
  }
  hasRequiredCmp = 1
  const eq = requireEq()
  const neq = requireNeq()
  const gt = requireGt()
  const gte = requireGte()
  const lt = requireLt()
  const lte = requireLte()
  const cmp = (a, op, b, loose) => {
    switch (op) {
      case '===':
        if (typeof a === 'object') {
          a = a.version
        }
        if (typeof b === 'object') {
          b = b.version
        }
        return a === b
      case '!==':
        if (typeof a === 'object') {
          a = a.version
        }
        if (typeof b === 'object') {
          b = b.version
        }
        return a !== b
      case '':
      case '=':
      case '==':
        return eq(a, b, loose)
      case '!=':
        return neq(a, b, loose)
      case '>':
        return gt(a, b, loose)
      case '>=':
        return gte(a, b, loose)
      case '<':
        return lt(a, b, loose)
      case '<=':
        return lte(a, b, loose)
      default:
        throw new TypeError(`Invalid operator: ${op}`)
    }
  }
  cmp_1 = cmp
  return cmp_1
}

let coerce_1
let hasRequiredCoerce
function requireCoerce() {
  if (hasRequiredCoerce) {
    return coerce_1
  }
  hasRequiredCoerce = 1
  const SemVer = requireSemver$1()
  const parse = requireParse$2()
  const { safeRe: re, t } = requireRe()
  const coerce = (version, options) => {
    if (version instanceof SemVer) {
      return version
    }
    if (typeof version === 'number') {
      version = String(version)
    }
    if (typeof version !== 'string') {
      return null
    }
    options = options || {}
    let match = null
    if (!options.rtl) {
      match = version.match(
        options.includePrerelease ? re[t.COERCEFULL] : re[t.COERCE]
      )
    } else {
      // Find the right-most coercible string that does not share
      // a terminus with a more left-ward coercible string.
      // Eg, '1.2.3.4' wants to coerce '2.3.4', not '3.4' or '4'
      // With includePrerelease option set, '1.2.3.4-rc' wants to coerce '2.3.4-rc', not '2.3.4'
      //
      // Walk through the string checking with a /g regexp
      // Manually set the index so as to pick up overlapping matches.
      // Stop when we get a match that ends at the string end, since no
      // coercible string can be more right-ward without the same terminus.
      const coerceRtlRegex = options.includePrerelease
        ? re[t.COERCERTLFULL]
        : re[t.COERCERTL]
      let next
      while (
        (next = coerceRtlRegex.exec(version)) &&
        (!match || match.index + match[0].length !== version.length)
      ) {
        if (
          !match ||
          next.index + next[0].length !== match.index + match[0].length
        ) {
          match = next
        }
        coerceRtlRegex.lastIndex = next.index + next[1].length + next[2].length
      }
      // leave it in a clean state
      coerceRtlRegex.lastIndex = -1
    }
    if (match === null) {
      return null
    }
    const major = match[2]
    const minor = match[3] || '0'
    const patch = match[4] || '0'
    const prerelease =
      options.includePrerelease && match[5] ? `-${match[5]}` : ''
    const build = options.includePrerelease && match[6] ? `+${match[6]}` : ''
    return parse(`${major}.${minor}.${patch}${prerelease}${build}`, options)
  }
  coerce_1 = coerce
  return coerce_1
}

let lrucache
let hasRequiredLrucache
function requireLrucache() {
  if (hasRequiredLrucache) {
    return lrucache
  }
  hasRequiredLrucache = 1
  class LRUCache {
    constructor() {
      this.max = 1000
      this.map = new Map()
    }
    get(key) {
      const value = this.map.get(key)
      if (value === undefined) {
        return undefined
      } else {
        // Remove the key from the map and add it to the end
        this.map.delete(key)
        this.map.set(key, value)
        return value
      }
    }
    delete(key) {
      return this.map.delete(key)
    }
    set(key, value) {
      const deleted = this.delete(key)
      if (!deleted && value !== undefined) {
        // If cache is full, delete the least recently used item
        if (this.map.size >= this.max) {
          const firstKey = this.map.keys().next().value
          this.delete(firstKey)
        }
        this.map.set(key, value)
      }
      return this
    }
  }
  lrucache = LRUCache
  return lrucache
}

let range
let hasRequiredRange
function requireRange() {
  if (hasRequiredRange) {
    return range
  }
  hasRequiredRange = 1
  const SPACE_CHARACTERS = /\s+/g

  // hoisted class for cyclic dependency
  class Range {
    constructor(range, options) {
      options = parseOptions(options)
      if (range instanceof Range) {
        if (
          range.loose === !!options.loose &&
          range.includePrerelease === !!options.includePrerelease
        ) {
          return range
        } else {
          return new Range(range.raw, options)
        }
      }
      if (range instanceof Comparator) {
        // just put it in the set and return
        this.raw = range.value
        this.set = [[range]]
        this.formatted = undefined
        return this
      }
      this.options = options
      this.loose = !!options.loose
      this.includePrerelease = !!options.includePrerelease

      // First reduce all whitespace as much as possible so we do not have to rely
      // on potentially slow regexes like \s*. This is then stored and used for
      // future error messages as well.
      this.raw = range.trim().replace(SPACE_CHARACTERS, ' ')

      // First, split on ||
      this.set = this.raw
        .split('||')
        // map the range to a 2d array of comparators
        .map(r => this.parseRange(r.trim()))
        // throw out any comparator lists that are empty
        // this generally means that it was not a valid range, which is allowed
        // in loose mode, but will still throw if the WHOLE range is invalid.
        .filter(c => c.length)
      if (!this.set.length) {
        throw new TypeError(`Invalid SemVer Range: ${this.raw}`)
      }

      // if we have any that are not the null set, throw out null sets.
      if (this.set.length > 1) {
        // keep the first one, in case they're all null sets
        const first = this.set[0]
        this.set = this.set.filter(c => !isNullSet(c[0]))
        if (this.set.length === 0) {
          this.set = [first]
        } else if (this.set.length > 1) {
          // if we have any that are *, then the range is just *
          for (const c of this.set) {
            if (c.length === 1 && isAny(c[0])) {
              this.set = [c]
              break
            }
          }
        }
      }
      this.formatted = undefined
    }
    get range() {
      if (this.formatted === undefined) {
        this.formatted = ''
        for (let i = 0; i < this.set.length; i++) {
          if (i > 0) {
            this.formatted += '||'
          }
          const comps = this.set[i]
          for (let k = 0; k < comps.length; k++) {
            if (k > 0) {
              this.formatted += ' '
            }
            this.formatted += comps[k].toString().trim()
          }
        }
      }
      return this.formatted
    }
    format() {
      return this.range
    }
    toString() {
      return this.range
    }
    parseRange(range) {
      // memoize range parsing for performance.
      // this is a very hot path, and fully deterministic.
      const memoOpts =
        (this.options.includePrerelease && FLAG_INCLUDE_PRERELEASE) |
        (this.options.loose && FLAG_LOOSE)
      const memoKey = memoOpts + ':' + range
      const cached = cache.get(memoKey)
      if (cached) {
        return cached
      }
      const loose = this.options.loose
      // `1.2.3 - 1.2.4` => `>=1.2.3 <=1.2.4`
      const hr = loose ? re[t.HYPHENRANGELOOSE] : re[t.HYPHENRANGE]
      range = range.replace(hr, hyphenReplace(this.options.includePrerelease))
      debug('hyphen replace', range)

      // `> 1.2.3 < 1.2.5` => `>1.2.3 <1.2.5`
      range = range.replace(re[t.COMPARATORTRIM], comparatorTrimReplace)
      debug('comparator trim', range)

      // `~ 1.2.3` => `~1.2.3`
      range = range.replace(re[t.TILDETRIM], tildeTrimReplace)
      debug('tilde trim', range)

      // `^ 1.2.3` => `^1.2.3`
      range = range.replace(re[t.CARETTRIM], caretTrimReplace)
      debug('caret trim', range)

      // At this point, the range is completely trimmed and
      // ready to be split into comparators.

      let rangeList = range
        .split(' ')
        .map(comp => parseComparator(comp, this.options))
        .join(' ')
        .split(/\s+/)
        // >=0.0.0 is equivalent to *
        .map(comp => replaceGTE0(comp, this.options))
      if (loose) {
        // in loose mode, throw out any that are not valid comparators
        rangeList = rangeList.filter(comp => {
          debug('loose invalid filter', comp, this.options)
          return !!comp.match(re[t.COMPARATORLOOSE])
        })
      }
      debug('range list', rangeList)

      // if any comparators are the null set, then replace with JUST null set
      // if more than one comparator, remove any * comparators
      // also, don't include the same comparator more than once
      const rangeMap = new Map()
      const comparators = rangeList.map(
        comp => new Comparator(comp, this.options)
      )
      for (const comp of comparators) {
        if (isNullSet(comp)) {
          return [comp]
        }
        rangeMap.set(comp.value, comp)
      }
      if (rangeMap.size > 1 && rangeMap.has('')) {
        rangeMap.delete('')
      }
      const result = [...rangeMap.values()]
      cache.set(memoKey, result)
      return result
    }
    intersects(range, options) {
      if (!(range instanceof Range)) {
        throw new TypeError('a Range is required')
      }
      return this.set.some(thisComparators => {
        return (
          isSatisfiable(thisComparators, options) &&
          range.set.some(rangeComparators => {
            return (
              isSatisfiable(rangeComparators, options) &&
              thisComparators.every(thisComparator => {
                return rangeComparators.every(rangeComparator => {
                  return thisComparator.intersects(rangeComparator, options)
                })
              })
            )
          })
        )
      })
    }

    // if ANY of the sets match ALL of its comparators, then pass
    test(version) {
      if (!version) {
        return false
      }
      if (typeof version === 'string') {
        try {
          version = new SemVer(version, this.options)
        } catch (er) {
          return false
        }
      }
      for (let i = 0; i < this.set.length; i++) {
        if (testSet(this.set[i], version, this.options)) {
          return true
        }
      }
      return false
    }
  }
  range = Range
  const LRU = requireLrucache()
  const cache = new LRU()
  const parseOptions = requireParseOptions()
  const Comparator = requireComparator()
  const debug = requireDebug()
  const SemVer = requireSemver$1()
  const {
    safeRe: re,
    t,
    comparatorTrimReplace,
    tildeTrimReplace,
    caretTrimReplace
  } = requireRe()
  const { FLAG_INCLUDE_PRERELEASE, FLAG_LOOSE } = requireConstants()
  const isNullSet = c => c.value === '<0.0.0-0'
  const isAny = c => c.value === ''

  // take a set of comparators and determine whether there
  // exists a version which can satisfy it
  const isSatisfiable = (comparators, options) => {
    let result = true
    const remainingComparators = comparators.slice()
    let testComparator = remainingComparators.pop()
    while (result && remainingComparators.length) {
      result = remainingComparators.every(otherComparator => {
        return testComparator.intersects(otherComparator, options)
      })
      testComparator = remainingComparators.pop()
    }
    return result
  }

  // comprised of xranges, tildes, stars, and gtlt's at this point.
  // already replaced the hyphen ranges
  // turn into a set of JUST comparators.
  const parseComparator = (comp, options) => {
    debug('comp', comp, options)
    comp = replaceCarets(comp, options)
    debug('caret', comp)
    comp = replaceTildes(comp, options)
    debug('tildes', comp)
    comp = replaceXRanges(comp, options)
    debug('xrange', comp)
    comp = replaceStars(comp, options)
    debug('stars', comp)
    return comp
  }
  const isX = id => !id || id.toLowerCase() === 'x' || id === '*'

  // ~, ~> --> * (any, kinda silly)
  // ~2, ~2.x, ~2.x.x, ~>2, ~>2.x ~>2.x.x --> >=2.0.0 <3.0.0-0
  // ~2.0, ~2.0.x, ~>2.0, ~>2.0.x --> >=2.0.0 <2.1.0-0
  // ~1.2, ~1.2.x, ~>1.2, ~>1.2.x --> >=1.2.0 <1.3.0-0
  // ~1.2.3, ~>1.2.3 --> >=1.2.3 <1.3.0-0
  // ~1.2.0, ~>1.2.0 --> >=1.2.0 <1.3.0-0
  // ~0.0.1 --> >=0.0.1 <0.1.0-0
  const replaceTildes = (comp, options) => {
    return comp
      .trim()
      .split(/\s+/)
      .map(c => replaceTilde(c, options))
      .join(' ')
  }
  const replaceTilde = (comp, options) => {
    const r = options.loose ? re[t.TILDELOOSE] : re[t.TILDE]
    return comp.replace(r, (_, M, m, p, pr) => {
      debug('tilde', comp, _, M, m, p, pr)
      let ret
      if (isX(M)) {
        ret = ''
      } else if (isX(m)) {
        ret = `>=${M}.0.0 <${+M + 1}.0.0-0`
      } else if (isX(p)) {
        // ~1.2 == >=1.2.0 <1.3.0-0
        ret = `>=${M}.${m}.0 <${M}.${+m + 1}.0-0`
      } else if (pr) {
        debug('replaceTilde pr', pr)
        ret = `>=${M}.${m}.${p}-${pr} <${M}.${+m + 1}.0-0`
      } else {
        // ~1.2.3 == >=1.2.3 <1.3.0-0
        ret = `>=${M}.${m}.${p} <${M}.${+m + 1}.0-0`
      }
      debug('tilde return', ret)
      return ret
    })
  }

  // ^ --> * (any, kinda silly)
  // ^2, ^2.x, ^2.x.x --> >=2.0.0 <3.0.0-0
  // ^2.0, ^2.0.x --> >=2.0.0 <3.0.0-0
  // ^1.2, ^1.2.x --> >=1.2.0 <2.0.0-0
  // ^1.2.3 --> >=1.2.3 <2.0.0-0
  // ^1.2.0 --> >=1.2.0 <2.0.0-0
  // ^0.0.1 --> >=0.0.1 <0.0.2-0
  // ^0.1.0 --> >=0.1.0 <0.2.0-0
  const replaceCarets = (comp, options) => {
    return comp
      .trim()
      .split(/\s+/)
      .map(c => replaceCaret(c, options))
      .join(' ')
  }
  const replaceCaret = (comp, options) => {
    debug('caret', comp, options)
    const r = options.loose ? re[t.CARETLOOSE] : re[t.CARET]
    const z = options.includePrerelease ? '-0' : ''
    return comp.replace(r, (_, M, m, p, pr) => {
      debug('caret', comp, _, M, m, p, pr)
      let ret
      if (isX(M)) {
        ret = ''
      } else if (isX(m)) {
        ret = `>=${M}.0.0${z} <${+M + 1}.0.0-0`
      } else if (isX(p)) {
        if (M === '0') {
          ret = `>=${M}.${m}.0${z} <${M}.${+m + 1}.0-0`
        } else {
          ret = `>=${M}.${m}.0${z} <${+M + 1}.0.0-0`
        }
      } else if (pr) {
        debug('replaceCaret pr', pr)
        if (M === '0') {
          if (m === '0') {
            ret = `>=${M}.${m}.${p}-${pr} <${M}.${m}.${+p + 1}-0`
          } else {
            ret = `>=${M}.${m}.${p}-${pr} <${M}.${+m + 1}.0-0`
          }
        } else {
          ret = `>=${M}.${m}.${p}-${pr} <${+M + 1}.0.0-0`
        }
      } else {
        debug('no pr')
        if (M === '0') {
          if (m === '0') {
            ret = `>=${M}.${m}.${p}${z} <${M}.${m}.${+p + 1}-0`
          } else {
            ret = `>=${M}.${m}.${p}${z} <${M}.${+m + 1}.0-0`
          }
        } else {
          ret = `>=${M}.${m}.${p} <${+M + 1}.0.0-0`
        }
      }
      debug('caret return', ret)
      return ret
    })
  }
  const replaceXRanges = (comp, options) => {
    debug('replaceXRanges', comp, options)
    return comp
      .split(/\s+/)
      .map(c => replaceXRange(c, options))
      .join(' ')
  }
  const replaceXRange = (comp, options) => {
    comp = comp.trim()
    const r = options.loose ? re[t.XRANGELOOSE] : re[t.XRANGE]
    return comp.replace(r, (ret, gtlt, M, m, p, pr) => {
      debug('xRange', comp, ret, gtlt, M, m, p, pr)
      const xM = isX(M)
      const xm = xM || isX(m)
      const xp = xm || isX(p)
      const anyX = xp
      if (gtlt === '=' && anyX) {
        gtlt = ''
      }

      // if we're including prereleases in the match, then we need
      // to fix this to -0, the lowest possible prerelease value
      pr = options.includePrerelease ? '-0' : ''
      if (xM) {
        if (gtlt === '>' || gtlt === '<') {
          // nothing is allowed
          ret = '<0.0.0-0'
        } else {
          // nothing is forbidden
          ret = '*'
        }
      } else if (gtlt && anyX) {
        // we know patch is an x, because we have any x at all.
        // replace X with 0
        if (xm) {
          m = 0
        }
        p = 0
        if (gtlt === '>') {
          // >1 => >=2.0.0
          // >1.2 => >=1.3.0
          gtlt = '>='
          if (xm) {
            M = +M + 1
            m = 0
            p = 0
          } else {
            m = +m + 1
            p = 0
          }
        } else if (gtlt === '<=') {
          // <=0.7.x is actually <0.8.0, since any 0.7.x should
          // pass.  Similarly, <=7.x is actually <8.0.0, etc.
          gtlt = '<'
          if (xm) {
            M = +M + 1
          } else {
            m = +m + 1
          }
        }
        if (gtlt === '<') {
          pr = '-0'
        }
        ret = `${gtlt + M}.${m}.${p}${pr}`
      } else if (xm) {
        ret = `>=${M}.0.0${pr} <${+M + 1}.0.0-0`
      } else if (xp) {
        ret = `>=${M}.${m}.0${pr} <${M}.${+m + 1}.0-0`
      }
      debug('xRange return', ret)
      return ret
    })
  }

  // Because * is AND-ed with everything else in the comparator,
  // and '' means "any version", just remove the *s entirely.
  const replaceStars = (comp, options) => {
    debug('replaceStars', comp, options)
    // Looseness is ignored here.  star is always as loose as it gets!
    return comp.trim().replace(re[t.STAR], '')
  }
  const replaceGTE0 = (comp, options) => {
    debug('replaceGTE0', comp, options)
    return comp
      .trim()
      .replace(re[options.includePrerelease ? t.GTE0PRE : t.GTE0], '')
  }

  // This function is passed to string.replace(re[t.HYPHENRANGE])
  // M, m, patch, prerelease, build
  // 1.2 - 3.4.5 => >=1.2.0 <=3.4.5
  // 1.2.3 - 3.4 => >=1.2.0 <3.5.0-0 Any 3.4.x will do
  // 1.2 - 3.4 => >=1.2.0 <3.5.0-0
  // TODO build?
  const hyphenReplace =
    incPr => ($0, from, fM, fm, fp, fpr, fb, to, tM, tm, tp, tpr) => {
      if (isX(fM)) {
        from = ''
      } else if (isX(fm)) {
        from = `>=${fM}.0.0${incPr ? '-0' : ''}`
      } else if (isX(fp)) {
        from = `>=${fM}.${fm}.0${incPr ? '-0' : ''}`
      } else if (fpr) {
        from = `>=${from}`
      } else {
        from = `>=${from}${incPr ? '-0' : ''}`
      }
      if (isX(tM)) {
        to = ''
      } else if (isX(tm)) {
        to = `<${+tM + 1}.0.0-0`
      } else if (isX(tp)) {
        to = `<${tM}.${+tm + 1}.0-0`
      } else if (tpr) {
        to = `<=${tM}.${tm}.${tp}-${tpr}`
      } else if (incPr) {
        to = `<${tM}.${tm}.${+tp + 1}-0`
      } else {
        to = `<=${to}`
      }
      return `${from} ${to}`.trim()
    }
  const testSet = (set, version, options) => {
    for (let i = 0; i < set.length; i++) {
      if (!set[i].test(version)) {
        return false
      }
    }
    if (version.prerelease.length && !options.includePrerelease) {
      // Find the set of versions that are allowed to have prereleases
      // For example, ^1.2.3-pr.1 desugars to >=1.2.3-pr.1 <2.0.0
      // That should allow `1.2.3-pr.2` to pass.
      // However, `1.2.4-alpha.notready` should NOT be allowed,
      // even though it's within the range set by the comparators.
      for (let i = 0; i < set.length; i++) {
        debug(set[i].semver)
        if (set[i].semver === Comparator.ANY) {
          continue
        }
        if (set[i].semver.prerelease.length > 0) {
          const allowed = set[i].semver
          if (
            allowed.major === version.major &&
            allowed.minor === version.minor &&
            allowed.patch === version.patch
          ) {
            return true
          }
        }
      }

      // Version has a -pre, but it's not one of the ones we like.
      return false
    }
    return true
  }
  return range
}

let comparator
let hasRequiredComparator
function requireComparator() {
  if (hasRequiredComparator) {
    return comparator
  }
  hasRequiredComparator = 1
  const ANY = Symbol('SemVer ANY')
  // hoisted class for cyclic dependency
  class Comparator {
    static get ANY() {
      return ANY
    }
    constructor(comp, options) {
      options = parseOptions(options)
      if (comp instanceof Comparator) {
        if (comp.loose === !!options.loose) {
          return comp
        } else {
          comp = comp.value
        }
      }
      comp = comp.trim().split(/\s+/).join(' ')
      debug('comparator', comp, options)
      this.options = options
      this.loose = !!options.loose
      this.parse(comp)
      if (this.semver === ANY) {
        this.value = ''
      } else {
        this.value = this.operator + this.semver.version
      }
      debug('comp', this)
    }
    parse(comp) {
      const r = this.options.loose ? re[t.COMPARATORLOOSE] : re[t.COMPARATOR]
      const m = comp.match(r)
      if (!m) {
        throw new TypeError(`Invalid comparator: ${comp}`)
      }
      this.operator = m[1] !== undefined ? m[1] : ''
      if (this.operator === '=') {
        this.operator = ''
      }

      // if it literally is just '>' or '' then allow anything.
      if (!m[2]) {
        this.semver = ANY
      } else {
        this.semver = new SemVer(m[2], this.options.loose)
      }
    }
    toString() {
      return this.value
    }
    test(version) {
      debug('Comparator.test', version, this.options.loose)
      if (this.semver === ANY || version === ANY) {
        return true
      }
      if (typeof version === 'string') {
        try {
          version = new SemVer(version, this.options)
        } catch (er) {
          return false
        }
      }
      return cmp(version, this.operator, this.semver, this.options)
    }
    intersects(comp, options) {
      if (!(comp instanceof Comparator)) {
        throw new TypeError('a Comparator is required')
      }
      if (this.operator === '') {
        if (this.value === '') {
          return true
        }
        return new Range(comp.value, options).test(this.value)
      } else if (comp.operator === '') {
        if (comp.value === '') {
          return true
        }
        return new Range(this.value, options).test(comp.semver)
      }
      options = parseOptions(options)

      // Special cases where nothing can possibly be lower
      if (
        options.includePrerelease &&
        (this.value === '<0.0.0-0' || comp.value === '<0.0.0-0')
      ) {
        return false
      }
      if (
        !options.includePrerelease &&
        (this.value.startsWith('<0.0.0') || comp.value.startsWith('<0.0.0'))
      ) {
        return false
      }

      // Same direction increasing (> or >=)
      if (this.operator.startsWith('>') && comp.operator.startsWith('>')) {
        return true
      }
      // Same direction decreasing (< or <=)
      if (this.operator.startsWith('<') && comp.operator.startsWith('<')) {
        return true
      }
      // same SemVer and both sides are inclusive (<= or >=)
      if (
        this.semver.version === comp.semver.version &&
        this.operator.includes('=') &&
        comp.operator.includes('=')
      ) {
        return true
      }
      // opposite directions less than
      if (
        cmp(this.semver, '<', comp.semver, options) &&
        this.operator.startsWith('>') &&
        comp.operator.startsWith('<')
      ) {
        return true
      }
      // opposite directions greater than
      if (
        cmp(this.semver, '>', comp.semver, options) &&
        this.operator.startsWith('<') &&
        comp.operator.startsWith('>')
      ) {
        return true
      }
      return false
    }
  }
  comparator = Comparator
  const parseOptions = requireParseOptions()
  const { safeRe: re, t } = requireRe()
  const cmp = requireCmp()
  const debug = requireDebug()
  const SemVer = requireSemver$1()
  const Range = requireRange()
  return comparator
}

let satisfies_1
let hasRequiredSatisfies
function requireSatisfies() {
  if (hasRequiredSatisfies) {
    return satisfies_1
  }
  hasRequiredSatisfies = 1
  const Range = requireRange()
  const satisfies = (version, range, options) => {
    try {
      range = new Range(range, options)
    } catch (er) {
      return false
    }
    return range.test(version)
  }
  satisfies_1 = satisfies
  return satisfies_1
}

let toComparators_1
let hasRequiredToComparators
function requireToComparators() {
  if (hasRequiredToComparators) {
    return toComparators_1
  }
  hasRequiredToComparators = 1
  const Range = requireRange()

  // Mostly just for testing and legacy API reasons
  const toComparators = (range, options) =>
    new Range(range, options).set.map(comp =>
      comp
        .map(c => c.value)
        .join(' ')
        .trim()
        .split(' ')
    )
  toComparators_1 = toComparators
  return toComparators_1
}

let maxSatisfying_1
let hasRequiredMaxSatisfying
function requireMaxSatisfying() {
  if (hasRequiredMaxSatisfying) {
    return maxSatisfying_1
  }
  hasRequiredMaxSatisfying = 1
  const SemVer = requireSemver$1()
  const Range = requireRange()
  const maxSatisfying = (versions, range, options) => {
    let max = null
    let maxSV = null
    let rangeObj = null
    try {
      rangeObj = new Range(range, options)
    } catch (er) {
      return null
    }
    versions.forEach(v => {
      if (rangeObj.test(v)) {
        // satisfies(v, range, options)
        if (!max || maxSV.compare(v) === -1) {
          // compare(max, v, true)
          max = v
          maxSV = new SemVer(max, options)
        }
      }
    })
    return max
  }
  maxSatisfying_1 = maxSatisfying
  return maxSatisfying_1
}

let minSatisfying_1
let hasRequiredMinSatisfying
function requireMinSatisfying() {
  if (hasRequiredMinSatisfying) {
    return minSatisfying_1
  }
  hasRequiredMinSatisfying = 1
  const SemVer = requireSemver$1()
  const Range = requireRange()
  const minSatisfying = (versions, range, options) => {
    let min = null
    let minSV = null
    let rangeObj = null
    try {
      rangeObj = new Range(range, options)
    } catch (er) {
      return null
    }
    versions.forEach(v => {
      if (rangeObj.test(v)) {
        // satisfies(v, range, options)
        if (!min || minSV.compare(v) === 1) {
          // compare(min, v, true)
          min = v
          minSV = new SemVer(min, options)
        }
      }
    })
    return min
  }
  minSatisfying_1 = minSatisfying
  return minSatisfying_1
}

let minVersion_1
let hasRequiredMinVersion
function requireMinVersion() {
  if (hasRequiredMinVersion) {
    return minVersion_1
  }
  hasRequiredMinVersion = 1
  const SemVer = requireSemver$1()
  const Range = requireRange()
  const gt = requireGt()
  const minVersion = (range, loose) => {
    range = new Range(range, loose)
    let minver = new SemVer('0.0.0')
    if (range.test(minver)) {
      return minver
    }
    minver = new SemVer('0.0.0-0')
    if (range.test(minver)) {
      return minver
    }
    minver = null
    for (let i = 0; i < range.set.length; ++i) {
      const comparators = range.set[i]
      let setMin = null
      comparators.forEach(comparator => {
        // Clone to avoid manipulating the comparator's semver object.
        const compver = new SemVer(comparator.semver.version)
        switch (comparator.operator) {
          case '>':
            if (compver.prerelease.length === 0) {
              compver.patch++
            } else {
              compver.prerelease.push(0)
            }
            compver.raw = compver.format()
          /* fallthrough */
          case '':
          case '>=':
            if (!setMin || gt(compver, setMin)) {
              setMin = compver
            }
            break
          case '<':
          case '<=':
            /* Ignore maximum versions */
            break
          /* istanbul ignore next */
          default:
            throw new Error(`Unexpected operation: ${comparator.operator}`)
        }
      })
      if (setMin && (!minver || gt(minver, setMin))) {
        minver = setMin
      }
    }
    if (minver && range.test(minver)) {
      return minver
    }
    return null
  }
  minVersion_1 = minVersion
  return minVersion_1
}

let valid
let hasRequiredValid
function requireValid() {
  if (hasRequiredValid) {
    return valid
  }
  hasRequiredValid = 1
  const Range = requireRange()
  const validRange = (range, options) => {
    try {
      // Return '*' instead of '' so that truthiness works.
      // This will throw if it's invalid anyway
      return new Range(range, options).range || '*'
    } catch (er) {
      return null
    }
  }
  valid = validRange
  return valid
}

let outside_1
let hasRequiredOutside
function requireOutside() {
  if (hasRequiredOutside) {
    return outside_1
  }
  hasRequiredOutside = 1
  const SemVer = requireSemver$1()
  const Comparator = requireComparator()
  const { ANY } = Comparator
  const Range = requireRange()
  const satisfies = requireSatisfies()
  const gt = requireGt()
  const lt = requireLt()
  const lte = requireLte()
  const gte = requireGte()
  const outside = (version, range, hilo, options) => {
    version = new SemVer(version, options)
    range = new Range(range, options)
    let gtfn, ltefn, ltfn, comp, ecomp
    switch (hilo) {
      case '>':
        gtfn = gt
        ltefn = lte
        ltfn = lt
        comp = '>'
        ecomp = '>='
        break
      case '<':
        gtfn = lt
        ltefn = gte
        ltfn = gt
        comp = '<'
        ecomp = '<='
        break
      default:
        throw new TypeError('Must provide a hilo val of "<" or ">"')
    }

    // If it satisfies the range it is not outside
    if (satisfies(version, range, options)) {
      return false
    }

    // From now on, variable terms are as if we're in "gtr" mode.
    // but note that everything is flipped for the "ltr" function.

    for (let i = 0; i < range.set.length; ++i) {
      const comparators = range.set[i]
      let high = null
      let low = null
      comparators.forEach(comparator => {
        if (comparator.semver === ANY) {
          comparator = new Comparator('>=0.0.0')
        }
        high = high || comparator
        low = low || comparator
        if (gtfn(comparator.semver, high.semver, options)) {
          high = comparator
        } else if (ltfn(comparator.semver, low.semver, options)) {
          low = comparator
        }
      })

      // If the edge version comparator has a operator then our version
      // isn't outside it
      if (high.operator === comp || high.operator === ecomp) {
        return false
      }

      // If the lowest version comparator has an operator and our version
      // is less than it then it isn't higher than the range
      if (
        (!low.operator || low.operator === comp) &&
        ltefn(version, low.semver)
      ) {
        return false
      } else if (low.operator === ecomp && ltfn(version, low.semver)) {
        return false
      }
    }
    return true
  }
  outside_1 = outside
  return outside_1
}

let gtr_1
let hasRequiredGtr
function requireGtr() {
  if (hasRequiredGtr) {
    return gtr_1
  }
  hasRequiredGtr = 1

  // Determine if version is greater than all the versions possible in the range.
  const outside = requireOutside()
  const gtr = (version, range, options) => outside(version, range, '>', options)
  gtr_1 = gtr
  return gtr_1
}

let ltr_1
let hasRequiredLtr
function requireLtr() {
  if (hasRequiredLtr) {
    return ltr_1
  }
  hasRequiredLtr = 1
  const outside = requireOutside()
  // Determine if version is less than all the versions possible in the range
  const ltr = (version, range, options) => outside(version, range, '<', options)
  ltr_1 = ltr
  return ltr_1
}

let intersects_1
let hasRequiredIntersects
function requireIntersects() {
  if (hasRequiredIntersects) {
    return intersects_1
  }
  hasRequiredIntersects = 1
  const Range = requireRange()
  const intersects = (r1, r2, options) => {
    r1 = new Range(r1, options)
    r2 = new Range(r2, options)
    return r1.intersects(r2, options)
  }
  intersects_1 = intersects
  return intersects_1
}

let simplify
let hasRequiredSimplify
function requireSimplify() {
  if (hasRequiredSimplify) {
    return simplify
  }
  hasRequiredSimplify = 1

  // given a set of versions and a range, create a "simplified" range
  // that includes the same versions that the original range does
  // If the original range is shorter than the simplified one, return that.
  const satisfies = requireSatisfies()
  const compare = requireCompare()
  simplify = (versions, range, options) => {
    const set = []
    let first = null
    let prev = null
    const v = versions.sort((a, b) => compare(a, b, options))
    for (const version of v) {
      const included = satisfies(version, range, options)
      if (included) {
        prev = version
        if (!first) {
          first = version
        }
      } else {
        if (prev) {
          set.push([first, prev])
        }
        prev = null
        first = null
      }
    }
    if (first) {
      set.push([first, null])
    }
    const ranges = []
    for (const [min, max] of set) {
      if (min === max) {
        ranges.push(min)
      } else if (!max && min === v[0]) {
        ranges.push('*')
      } else if (!max) {
        ranges.push(`>=${min}`)
      } else if (min === v[0]) {
        ranges.push(`<=${max}`)
      } else {
        ranges.push(`${min} - ${max}`)
      }
    }
    const simplified = ranges.join(' || ')
    const original = typeof range.raw === 'string' ? range.raw : String(range)
    return simplified.length < original.length ? simplified : range
  }
  return simplify
}

let subset_1
let hasRequiredSubset
function requireSubset() {
  if (hasRequiredSubset) {
    return subset_1
  }
  hasRequiredSubset = 1
  const Range = requireRange()
  const Comparator = requireComparator()
  const { ANY } = Comparator
  const satisfies = requireSatisfies()
  const compare = requireCompare()

  // Complex range `r1 || r2 || ...` is a subset of `R1 || R2 || ...` iff:
  // - Every simple range `r1, r2, ...` is a null set, OR
  // - Every simple range `r1, r2, ...` which is not a null set is a subset of
  //   some `R1, R2, ...`
  //
  // Simple range `c1 c2 ...` is a subset of simple range `C1 C2 ...` iff:
  // - If c is only the ANY comparator
  //   - If C is only the ANY comparator, return true
  //   - Else if in prerelease mode, return false
  //   - else replace c with `[>=0.0.0]`
  // - If C is only the ANY comparator
  //   - if in prerelease mode, return true
  //   - else replace C with `[>=0.0.0]`
  // - Let EQ be the set of = comparators in c
  // - If EQ is more than one, return true (null set)
  // - Let GT be the highest > or >= comparator in c
  // - Let LT be the lowest < or <= comparator in c
  // - If GT and LT, and GT.semver > LT.semver, return true (null set)
  // - If any C is a = range, and GT or LT are set, return false
  // - If EQ
  //   - If GT, and EQ does not satisfy GT, return true (null set)
  //   - If LT, and EQ does not satisfy LT, return true (null set)
  //   - If EQ satisfies every C, return true
  //   - Else return false
  // - If GT
  //   - If GT.semver is lower than any > or >= comp in C, return false
  //   - If GT is >=, and GT.semver does not satisfy every C, return false
  //   - If GT.semver has a prerelease, and not in prerelease mode
  //     - If no C has a prerelease and the GT.semver tuple, return false
  // - If LT
  //   - If LT.semver is greater than any < or <= comp in C, return false
  //   - If LT is <=, and LT.semver does not satisfy every C, return false
  //   - If GT.semver has a prerelease, and not in prerelease mode
  //     - If no C has a prerelease and the LT.semver tuple, return false
  // - Else return true

  const subset = (sub, dom, options = {}) => {
    if (sub === dom) {
      return true
    }
    sub = new Range(sub, options)
    dom = new Range(dom, options)
    let sawNonNull = false
    OUTER: for (const simpleSub of sub.set) {
      for (const simpleDom of dom.set) {
        const isSub = simpleSubset(simpleSub, simpleDom, options)
        sawNonNull = sawNonNull || isSub !== null
        if (isSub) {
          continue OUTER
        }
      }
      // the null set is a subset of everything, but null simple ranges in
      // a complex range should be ignored.  so if we saw a non-null range,
      // then we know this isn't a subset, but if EVERY simple range was null,
      // then it is a subset.
      if (sawNonNull) {
        return false
      }
    }
    return true
  }
  const minimumVersionWithPreRelease = [new Comparator('>=0.0.0-0')]
  const minimumVersion = [new Comparator('>=0.0.0')]
  const simpleSubset = (sub, dom, options) => {
    if (sub === dom) {
      return true
    }
    if (sub.length === 1 && sub[0].semver === ANY) {
      if (dom.length === 1 && dom[0].semver === ANY) {
        return true
      } else if (options.includePrerelease) {
        sub = minimumVersionWithPreRelease
      } else {
        sub = minimumVersion
      }
    }
    if (dom.length === 1 && dom[0].semver === ANY) {
      if (options.includePrerelease) {
        return true
      } else {
        dom = minimumVersion
      }
    }
    const eqSet = new Set()
    let gt, lt
    for (const c of sub) {
      if (c.operator === '>' || c.operator === '>=') {
        gt = higherGT(gt, c, options)
      } else if (c.operator === '<' || c.operator === '<=') {
        lt = lowerLT(lt, c, options)
      } else {
        eqSet.add(c.semver)
      }
    }
    if (eqSet.size > 1) {
      return null
    }
    let gtltComp
    if (gt && lt) {
      gtltComp = compare(gt.semver, lt.semver, options)
      if (gtltComp > 0) {
        return null
      } else if (
        gtltComp === 0 &&
        (gt.operator !== '>=' || lt.operator !== '<=')
      ) {
        return null
      }
    }

    // will iterate one or zero times
    for (const eq of eqSet) {
      if (gt && !satisfies(eq, String(gt), options)) {
        return null
      }
      if (lt && !satisfies(eq, String(lt), options)) {
        return null
      }
      for (const c of dom) {
        if (!satisfies(eq, String(c), options)) {
          return false
        }
      }
      return true
    }
    let higher, lower
    let hasDomLT, hasDomGT
    // if the subset has a prerelease, we need a comparator in the superset
    // with the same tuple and a prerelease, or it's not a subset
    let needDomLTPre =
      lt && !options.includePrerelease && lt.semver.prerelease.length
        ? lt.semver
        : false
    let needDomGTPre =
      gt && !options.includePrerelease && gt.semver.prerelease.length
        ? gt.semver
        : false
    // exception: <1.2.3-0 is the same as <1.2.3
    if (
      needDomLTPre &&
      needDomLTPre.prerelease.length === 1 &&
      lt.operator === '<' &&
      needDomLTPre.prerelease[0] === 0
    ) {
      needDomLTPre = false
    }
    for (const c of dom) {
      hasDomGT = hasDomGT || c.operator === '>' || c.operator === '>='
      hasDomLT = hasDomLT || c.operator === '<' || c.operator === '<='
      if (gt) {
        if (needDomGTPre) {
          if (
            c.semver.prerelease &&
            c.semver.prerelease.length &&
            c.semver.major === needDomGTPre.major &&
            c.semver.minor === needDomGTPre.minor &&
            c.semver.patch === needDomGTPre.patch
          ) {
            needDomGTPre = false
          }
        }
        if (c.operator === '>' || c.operator === '>=') {
          higher = higherGT(gt, c, options)
          if (higher === c && higher !== gt) {
            return false
          }
        } else if (
          gt.operator === '>=' &&
          !satisfies(gt.semver, String(c), options)
        ) {
          return false
        }
      }
      if (lt) {
        if (needDomLTPre) {
          if (
            c.semver.prerelease &&
            c.semver.prerelease.length &&
            c.semver.major === needDomLTPre.major &&
            c.semver.minor === needDomLTPre.minor &&
            c.semver.patch === needDomLTPre.patch
          ) {
            needDomLTPre = false
          }
        }
        if (c.operator === '<' || c.operator === '<=') {
          lower = lowerLT(lt, c, options)
          if (lower === c && lower !== lt) {
            return false
          }
        } else if (
          lt.operator === '<=' &&
          !satisfies(lt.semver, String(c), options)
        ) {
          return false
        }
      }
      if (!c.operator && (lt || gt) && gtltComp !== 0) {
        return false
      }
    }

    // if there was a < or >, and nothing in the dom, then must be false
    // UNLESS it was limited by another range in the other direction.
    // Eg, >1.0.0 <1.0.1 is still a subset of <2.0.0
    if (gt && hasDomLT && !lt && gtltComp !== 0) {
      return false
    }
    if (lt && hasDomGT && !gt && gtltComp !== 0) {
      return false
    }

    // we needed a prerelease range in a specific tuple, but didn't get one
    // then this isn't a subset.  eg >=1.2.3-pre is not a subset of >=1.0.0,
    // because it includes prereleases in the 1.2.3 tuple
    if (needDomGTPre || needDomLTPre) {
      return false
    }
    return true
  }

  // >=1.2.3 is lower than >1.2.3
  const higherGT = (a, b, options) => {
    if (!a) {
      return b
    }
    const comp = compare(a.semver, b.semver, options)
    return comp > 0
      ? a
      : comp < 0
        ? b
        : b.operator === '>' && a.operator === '>='
          ? b
          : a
  }

  // <=1.2.3 is higher than <1.2.3
  const lowerLT = (a, b, options) => {
    if (!a) {
      return b
    }
    const comp = compare(a.semver, b.semver, options)
    return comp < 0
      ? a
      : comp > 0
        ? b
        : b.operator === '<' && a.operator === '<='
          ? b
          : a
  }
  subset_1 = subset
  return subset_1
}

let semver
let hasRequiredSemver
function requireSemver() {
  if (hasRequiredSemver) {
    return semver
  }
  hasRequiredSemver = 1

  // just pre-load all the stuff that index.js lazily exports
  const internalRe = requireRe()
  const constants = requireConstants()
  const SemVer = requireSemver$1()
  const identifiers = requireIdentifiers()
  const parse = requireParse$2()
  const valid = requireValid$1()
  const clean = requireClean()
  const inc = requireInc()
  const diff = requireDiff()
  const major = requireMajor()
  const minor = requireMinor()
  const patch = requirePatch()
  const prerelease = requirePrerelease()
  const compare = requireCompare()
  const rcompare = requireRcompare()
  const compareLoose = requireCompareLoose()
  const compareBuild = requireCompareBuild()
  const sort = requireSort$1()
  const rsort = requireRsort()
  const gt = requireGt()
  const lt = requireLt()
  const eq = requireEq()
  const neq = requireNeq()
  const gte = requireGte()
  const lte = requireLte()
  const cmp = requireCmp()
  const coerce = requireCoerce()
  const Comparator = requireComparator()
  const Range = requireRange()
  const satisfies = requireSatisfies()
  const toComparators = requireToComparators()
  const maxSatisfying = requireMaxSatisfying()
  const minSatisfying = requireMinSatisfying()
  const minVersion = requireMinVersion()
  const validRange = requireValid()
  const outside = requireOutside()
  const gtr = requireGtr()
  const ltr = requireLtr()
  const intersects = requireIntersects()
  const simplifyRange = requireSimplify()
  const subset = requireSubset()
  semver = {
    parse,
    valid,
    clean,
    inc,
    diff,
    major,
    minor,
    patch,
    prerelease,
    compare,
    rcompare,
    compareLoose,
    compareBuild,
    sort,
    rsort,
    gt,
    lt,
    eq,
    neq,
    gte,
    lte,
    cmp,
    coerce,
    Comparator,
    Range,
    satisfies,
    toComparators,
    maxSatisfying,
    minSatisfying,
    minVersion,
    validRange,
    outside,
    gtr,
    ltr,
    intersects,
    simplifyRange,
    subset,
    SemVer,
    re: internalRe.re,
    src: internalRe.src,
    tokens: internalRe.t,
    SEMVER_SPEC_VERSION: constants.SEMVER_SPEC_VERSION,
    RELEASE_TYPES: constants.RELEASE_TYPES,
    compareIdentifiers: identifiers.compareIdentifiers,
    rcompareIdentifiers: identifiers.rcompareIdentifiers
  }
  return semver
}

let linesToRevs
let hasRequiredLinesToRevs
function requireLinesToRevs() {
  if (hasRequiredLinesToRevs) {
    return linesToRevs
  }
  hasRequiredLinesToRevs = 1
  // turn an array of lines from `git ls-remote` into a thing
  // vaguely resembling a packument, where docs are a resolved ref

  const semver = requireSemver()
  linesToRevs = lines =>
    finish(
      lines.reduce(linesToRevsReducer, {
        versions: {},
        'dist-tags': {},
        refs: {},
        shas: {}
      })
    )
  const finish = revs => distTags(shaList(peelTags(revs)))

  // We can check out shallow clones on specific SHAs if we have a ref
  const shaList = revs => {
    Object.keys(revs.refs).forEach(ref => {
      const doc = revs.refs[ref]
      if (!revs.shas[doc.sha]) {
        revs.shas[doc.sha] = [ref]
      } else {
        revs.shas[doc.sha].push(ref)
      }
    })
    return revs
  }

  // Replace any tags with their ^{} counterparts, if those exist
  const peelTags = revs => {
    Object.keys(revs.refs)
      .filter(ref => ref.endsWith('^{}'))
      .forEach(ref => {
        const peeled = revs.refs[ref]
        const unpeeled = revs.refs[ref.replace(/\^\{\}$/, '')]
        if (unpeeled) {
          unpeeled.sha = peeled.sha
          delete revs.refs[ref]
        }
      })
    return revs
  }
  const distTags = revs => {
    // not entirely sure what situations would result in an
    // ichabod repo, but best to be careful in Sleepy Hollow anyway
    const HEAD = revs.refs.HEAD || /* istanbul ignore next */ {}
    const versions = Object.keys(revs.versions)
    versions.forEach(v => {
      // simulate a dist-tags with latest pointing at the
      // 'latest' branch if one exists and is a version,
      // or HEAD if not.
      const ver = revs.versions[v]
      if (revs.refs.latest && ver.sha === revs.refs.latest.sha) {
        revs['dist-tags'].latest = v
      } else if (ver.sha === HEAD.sha) {
        revs['dist-tags'].HEAD = v
        if (!revs.refs.latest) {
          revs['dist-tags'].latest = v
        }
      }
    })
    return revs
  }
  const refType = ref => {
    if (ref.startsWith('refs/tags/')) {
      return 'tag'
    }
    if (ref.startsWith('refs/heads/')) {
      return 'branch'
    }
    if (ref.startsWith('refs/pull/')) {
      return 'pull'
    }
    if (ref === 'HEAD') {
      return 'head'
    }
    // Could be anything, ignore for now
    /* istanbul ignore next */
    return 'other'
  }

  // return the doc, or null if we should ignore it.
  const lineToRevDoc = line => {
    const split = line.trim().split(/\s+/, 2)
    if (split.length < 2) {
      return null
    }
    const sha = split[0].trim()
    const rawRef = split[1].trim()
    const type = refType(rawRef)
    if (type === 'tag') {
      // refs/tags/foo^{} is the 'peeled tag', ie the commit
      // that is tagged by refs/tags/foo they resolve to the same
      // content, just different objects in git's data structure.
      // But, we care about the thing the tag POINTS to, not the tag
      // object itself, so we only look at the peeled tag refs, and
      // ignore the pointer.
      // For now, though, we have to save both, because some tags
      // don't have peels, if they were not annotated.
      const ref = rawRef.slice('refs/tags/'.length)
      return {
        sha,
        ref,
        rawRef,
        type
      }
    }
    if (type === 'branch') {
      const ref = rawRef.slice('refs/heads/'.length)
      return {
        sha,
        ref,
        rawRef,
        type
      }
    }
    if (type === 'pull') {
      // NB: merged pull requests installable with #pull/123/merge
      // for the merged pr, or #pull/123 for the PR head
      const ref = rawRef.slice('refs/'.length).replace(/\/head$/, '')
      return {
        sha,
        ref,
        rawRef,
        type
      }
    }
    if (type === 'head') {
      const ref = 'HEAD'
      return {
        sha,
        ref,
        rawRef,
        type
      }
    }

    // at this point, all we can do is leave the ref un-munged
    return {
      sha,
      ref: rawRef,
      rawRef,
      type
    }
  }
  const linesToRevsReducer = (revs, line) => {
    const doc = lineToRevDoc(line)
    if (!doc) {
      return revs
    }
    revs.refs[doc.ref] = doc
    revs.refs[doc.rawRef] = doc
    if (doc.type === 'tag') {
      // try to pull a semver value out of tags like `release-v1.2.3`
      // which is a pretty common pattern.
      const match =
        !doc.ref.endsWith('^{}') &&
        doc.ref.match(/v?(\d+\.\d+\.\d+(?:[-+].+)?)$/)
      if (match && semver.valid(match[1], true)) {
        revs.versions[semver.clean(match[1], true)] = doc
      }
    }
    return revs
  }
  return linesToRevs
}

let revs
let hasRequiredRevs
function requireRevs() {
  if (hasRequiredRevs) {
    return revs
  }
  hasRequiredRevs = 1
  const spawn = requireSpawn()
  const { LRUCache } = /*@__PURE__*/ requireCommonjs$4()
  const linesToRevs = requireLinesToRevs()
  const revsCache = new LRUCache({
    max: 100,
    ttl: 5 * 60 * 1000
  })
  revs = async (repo, opts = {}) => {
    if (!opts.noGitRevCache) {
      const cached = revsCache.get(repo)
      if (cached) {
        return cached
      }
    }
    const { stdout } = await spawn(['ls-remote', repo], opts)
    const revs = linesToRevs(stdout.trim().split('\n'))
    revsCache.set(repo, revs)
    return revs
  }
  return revs
}

const utils = {}

let hasRequiredUtils
function requireUtils() {
  if (hasRequiredUtils) {
    return utils
  }
  hasRequiredUtils = 1
  const isWindows = opts => (opts.fakePlatform || process.platform) === 'win32'
  utils.isWindows = isWindows
  return utils
}

const npa = { exports: {} }

let lib$5
let hasRequiredLib$5
function requireLib$5() {
  if (hasRequiredLib$5) {
    return lib$5
  }
  hasRequiredLib$5 = 1
  const { builtinModules: builtins } = require$$0$5
  const scopedPackagePattern = new RegExp('^(?:@([^/]+?)[/])?([^/]+?)$')
  const exclusionList = ['node_modules', 'favicon.ico']
  function validate(name) {
    const warnings = []
    const errors = []
    if (name === null) {
      errors.push('name cannot be null')
      return done(warnings, errors)
    }
    if (name === undefined) {
      errors.push('name cannot be undefined')
      return done(warnings, errors)
    }
    if (typeof name !== 'string') {
      errors.push('name must be a string')
      return done(warnings, errors)
    }
    if (!name.length) {
      errors.push('name length must be greater than zero')
    }
    if (name.startsWith('.')) {
      errors.push('name cannot start with a period')
    }
    if (name.match(/^_/)) {
      errors.push('name cannot start with an underscore')
    }
    if (name.trim() !== name) {
      errors.push('name cannot contain leading or trailing spaces')
    }

    // No funny business
    exclusionList.forEach(function (excludedName) {
      if (name.toLowerCase() === excludedName) {
        errors.push(excludedName + ' is not a valid package name')
      }
    })

    // Generate warnings for stuff that used to be allowed

    // core module names like http, events, util, etc
    if (builtins.includes(name.toLowerCase())) {
      warnings.push(name + ' is a core module name')
    }
    if (name.length > 214) {
      warnings.push('name can no longer contain more than 214 characters')
    }

    // mIxeD CaSe nAMEs
    if (name.toLowerCase() !== name) {
      warnings.push('name can no longer contain capital letters')
    }
    if (/[~'!()*]/.test(name.split('/').slice(-1)[0])) {
      warnings.push('name can no longer contain special characters ("~\'!()*")')
    }
    if (encodeURIComponent(name) !== name) {
      // Maybe it's a scoped package name, like @user/package
      const nameMatch = name.match(scopedPackagePattern)
      if (nameMatch) {
        const user = nameMatch[1]
        const pkg = nameMatch[2]
        if (pkg.startsWith('.')) {
          errors.push('name cannot start with a period')
        }
        if (
          encodeURIComponent(user) === user &&
          encodeURIComponent(pkg) === pkg
        ) {
          return done(warnings, errors)
        }
      }
      errors.push('name can only contain URL-friendly characters')
    }
    return done(warnings, errors)
  }
  const done = function (warnings, errors) {
    const result = {
      validForNewPackages: errors.length === 0 && warnings.length === 0,
      validForOldPackages: errors.length === 0,
      warnings: warnings,
      errors: errors
    }
    if (!result.warnings.length) {
      delete result.warnings
    }
    if (!result.errors.length) {
      delete result.errors
    }
    return result
  }
  lib$5 = validate
  return lib$5
}

let hasRequiredNpa
function requireNpa() {
  if (hasRequiredNpa) {
    return npa.exports
  }
  hasRequiredNpa = 1
  const isWindows = process.platform === 'win32'
  const { URL } = require$$0$3
  // We need to use path/win32 so that we get consistent results in tests, but this also means we need to manually convert backslashes to forward slashes when generating file: urls with paths.
  const path = isWindows ? require$$1$7 : require$$2$2
  const { homedir } = require$$1$6
  const HostedGit = requireLib$8()
  const semver = requireSemver()
  const validatePackageName = requireLib$5()
  const { log } = requireLib$9()
  const hasSlashes = isWindows ? /\\|[/]/ : /[/]/
  const isURL = /^(?:git[+])?[a-z]+:/i
  const isGit = /^[^@]+@[^:.]+\.[^:]+:.+$/i
  const isFileType = /[.](?:tgz|tar.gz|tar)$/i
  const isPortNumber = /:[0-9]+(\/|$)/i
  const isWindowsFile = /^(?:[.]|~[/]|[/\\]|[a-zA-Z]:)/
  const isPosixFile = /^(?:[.]|~[/]|[/]|[a-zA-Z]:)/
  const defaultRegistry = 'https://registry.npmjs.org'
  function npa$1(arg, where) {
    let name
    let spec
    if (typeof arg === 'object') {
      if (arg instanceof Result && (!where || where === arg.where)) {
        return arg
      } else if (arg.name && arg.rawSpec) {
        return npa$1.resolve(arg.name, arg.rawSpec, where || arg.where)
      } else {
        return npa$1(arg.raw, where || arg.where)
      }
    }
    const nameEndsAt = arg.indexOf('@', 1) // Skip possible leading @
    const namePart = nameEndsAt > 0 ? arg.slice(0, nameEndsAt) : arg
    if (isURL.test(arg)) {
      spec = arg
    } else if (isGit.test(arg)) {
      spec = `git+ssh://${arg}`
      // eslint-disable-next-line max-len
    } else if (
      !namePart.startsWith('@') &&
      (hasSlashes.test(namePart) || isFileType.test(namePart))
    ) {
      spec = arg
    } else if (nameEndsAt > 0) {
      name = namePart
      spec = arg.slice(nameEndsAt + 1) || '*'
    } else {
      const valid = validatePackageName(arg)
      if (valid.validForOldPackages) {
        name = arg
        spec = '*'
      } else {
        spec = arg
      }
    }
    return resolve(name, spec, where, arg)
  }
  function isFileSpec(spec) {
    if (!spec) {
      return false
    }
    if (spec.toLowerCase().startsWith('file:')) {
      return true
    }
    if (isWindows) {
      return isWindowsFile.test(spec)
    }
    // We never hit this in windows tests, obviously
    /* istanbul ignore next */
    return isPosixFile.test(spec)
  }
  function isAliasSpec(spec) {
    if (!spec) {
      return false
    }
    return spec.toLowerCase().startsWith('npm:')
  }
  function resolve(name, spec, where, arg) {
    const res = new Result({
      raw: arg,
      name: name,
      rawSpec: spec,
      fromArgument: arg != null
    })
    if (name) {
      res.name = name
    }
    if (!where) {
      where = process.cwd()
    }
    if (isFileSpec(spec)) {
      return fromFile(res, where)
    } else if (isAliasSpec(spec)) {
      return fromAlias(res, where)
    }
    const hosted = HostedGit.fromUrl(spec, {
      noGitPlus: true,
      noCommittish: true
    })
    if (hosted) {
      return fromHostedGit(res, hosted)
    } else if (spec && isURL.test(spec)) {
      return fromURL(res)
    } else if (spec && (hasSlashes.test(spec) || isFileType.test(spec))) {
      return fromFile(res, where)
    } else {
      return fromRegistry(res)
    }
  }
  function toPurl(arg, reg = defaultRegistry) {
    const res = npa$1(arg)
    if (res.type !== 'version') {
      throw invalidPurlType(res.type, res.raw)
    }

    // URI-encode leading @ of scoped packages
    let purl = 'pkg:npm/' + res.name.replace(/^@/, '%40') + '@' + res.rawSpec
    if (reg !== defaultRegistry) {
      purl += '?repository_url=' + reg
    }
    return purl
  }
  function invalidPackageName(name, valid, raw) {
    // eslint-disable-next-line max-len
    const err = new Error(
      `Invalid package name "${name}" of package "${raw}": ${valid.errors.join('; ')}.`
    )
    err.code = 'EINVALIDPACKAGENAME'
    return err
  }
  function invalidTagName(name, raw) {
    // eslint-disable-next-line max-len
    const err = new Error(
      `Invalid tag name "${name}" of package "${raw}": Tags may not have any characters that encodeURIComponent encodes.`
    )
    err.code = 'EINVALIDTAGNAME'
    return err
  }
  function invalidPurlType(type, raw) {
    // eslint-disable-next-line max-len
    const err = new Error(
      `Invalid type "${type}" of package "${raw}": Purl can only be generated for "version" types.`
    )
    err.code = 'EINVALIDPURLTYPE'
    return err
  }
  class Result {
    constructor(opts) {
      this.type = opts.type
      this.registry = opts.registry
      this.where = opts.where
      if (opts.raw == null) {
        this.raw = opts.name ? `${opts.name}@${opts.rawSpec}` : opts.rawSpec
      } else {
        this.raw = opts.raw
      }
      this.name = undefined
      this.escapedName = undefined
      this.scope = undefined
      this.rawSpec = opts.rawSpec || ''
      this.saveSpec = opts.saveSpec
      this.fetchSpec = opts.fetchSpec
      if (opts.name) {
        this.setName(opts.name)
      }
      this.gitRange = opts.gitRange
      this.gitCommittish = opts.gitCommittish
      this.gitSubdir = opts.gitSubdir
      this.hosted = opts.hosted
    }

    // TODO move this to a getter/setter in a semver major
    setName(name) {
      const valid = validatePackageName(name)
      if (!valid.validForOldPackages) {
        throw invalidPackageName(name, valid, this.raw)
      }
      this.name = name
      this.scope =
        name[0] === '@' ? name.slice(0, name.indexOf('/')) : undefined
      // scoped packages in couch must have slash url-encoded, e.g. @foo%2Fbar
      this.escapedName = name.replace('/', '%2f')
      return this
    }
    toString() {
      const full = []
      if (this.name != null && this.name !== '') {
        full.push(this.name)
      }
      const spec = this.saveSpec || this.fetchSpec || this.rawSpec
      if (spec != null && spec !== '') {
        full.push(spec)
      }
      return full.length ? full.join('@') : this.raw
    }
    toJSON() {
      const result = Object.assign({}, this)
      delete result.hosted
      return result
    }
  }

  // sets res.gitCommittish, res.gitRange, and res.gitSubdir
  function setGitAttrs(res, committish) {
    if (!committish) {
      res.gitCommittish = null
      return
    }

    // for each :: separated item:
    for (const part of committish.split('::')) {
      // if the item has no : the n it is a commit-ish
      if (!part.includes(':')) {
        if (res.gitRange) {
          throw new Error(
            'cannot override existing semver range with a committish'
          )
        }
        if (res.gitCommittish) {
          throw new Error(
            'cannot override existing committish with a second committish'
          )
        }
        res.gitCommittish = part
        continue
      }
      // split on name:value
      const [name, value] = part.split(':')
      // if name is semver do semver lookup of ref or tag
      if (name === 'semver') {
        if (res.gitCommittish) {
          throw new Error(
            'cannot override existing committish with a semver range'
          )
        }
        if (res.gitRange) {
          throw new Error(
            'cannot override existing semver range with a second semver range'
          )
        }
        res.gitRange = decodeURIComponent(value)
        continue
      }
      if (name === 'path') {
        if (res.gitSubdir) {
          throw new Error('cannot override existing path with a second path')
        }
        res.gitSubdir = `/${value}`
        continue
      }
      log.warn('npm-package-arg', `ignoring unknown key "${name}"`)
    }
  }

  // Taken from: EncodePathChars and lookup_table in src/node_url.cc
  // url.pathToFileURL only returns absolute references.  We can't use it to encode paths.
  // encodeURI mangles windows paths. We can't use it to encode paths.
  // Under the hood, url.pathToFileURL does a limited set of encoding, with an extra windows step, and then calls path.resolve.
  // The encoding node does without path.resolve is not available outside of the source, so we are recreating it here.
  const encodedPathChars = new Map([
    ['\0', '%00'],
    ['\t', '%09'],
    ['\n', '%0A'],
    ['\r', '%0D'],
    [' ', '%20'],
    ['"', '%22'],
    ['#', '%23'],
    ['%', '%25'],
    ['?', '%3F'],
    ['[', '%5B'],
    ['\\', isWindows ? '/' : '%5C'],
    [']', '%5D'],
    ['^', '%5E'],
    ['|', '%7C'],
    ['~', '%7E']
  ])
  function pathToFileURL(str) {
    let result = ''
    for (let i = 0; i < str.length; i++) {
      result = `${result}${encodedPathChars.get(str[i]) ?? str[i]}`
    }
    if (result.startsWith('file:')) {
      return result
    }
    return `file:${result}`
  }
  function fromFile(res, where) {
    res.type = isFileType.test(res.rawSpec) ? 'file' : 'directory'
    res.where = where
    let rawSpec = pathToFileURL(res.rawSpec)
    if (rawSpec.startsWith('file:/')) {
      // XXX backwards compatibility lack of compliance with RFC 8089

      // turn file://path into file:/path
      if (/^file:\/\/[^/]/.test(rawSpec)) {
        rawSpec = `file:/${rawSpec.slice(5)}`
      }

      // turn file:/../path into file:../path
      // for 1 or 3 leading slashes (2 is already ruled out from handling file:// explicitly above)
      if (/^\/{1,3}\.\.?(\/|$)/.test(rawSpec.slice(5))) {
        rawSpec = rawSpec.replace(/^file:\/{1,3}/, 'file:')
      }
    }
    let resolvedUrl
    let specUrl
    try {
      // always put the '/' on "where", or else file:foo from /path/to/bar goes to /path/to/foo, when we want it to be /path/to/bar/foo
      resolvedUrl = new URL(rawSpec, `${pathToFileURL(path.resolve(where))}/`)
      specUrl = new URL(rawSpec)
    } catch (originalError) {
      const er = new Error('Invalid file: URL, must comply with RFC 8089')
      throw Object.assign(er, {
        raw: res.rawSpec,
        spec: res,
        where,
        originalError
      })
    }

    // turn /C:/blah into just C:/blah on windows
    let specPath = decodeURIComponent(specUrl.pathname)
    let resolvedPath = decodeURIComponent(resolvedUrl.pathname)
    if (isWindows) {
      specPath = specPath.replace(/^\/+([a-z]:\/)/i, '$1')
      resolvedPath = resolvedPath.replace(/^\/+([a-z]:\/)/i, '$1')
    }

    // replace ~ with homedir, but keep the ~ in the saveSpec
    // otherwise, make it relative to where param
    if (/^\/~(\/|$)/.test(specPath)) {
      res.saveSpec = `file:${specPath.substr(1)}`
      resolvedPath = path.resolve(homedir(), specPath.substr(3))
    } else if (!path.isAbsolute(rawSpec.slice(5))) {
      res.saveSpec = `file:${path.relative(where, resolvedPath)}`
    } else {
      res.saveSpec = `file:${path.resolve(resolvedPath)}`
    }
    res.fetchSpec = path.resolve(where, resolvedPath)
    // re-normalize the slashes in saveSpec due to node:path/win32 behavior in windows
    res.saveSpec = res.saveSpec.split('\\').join('/')
    // Ignoring because this only happens in windows
    /* istanbul ignore next */
    if (res.saveSpec.startsWith('file://')) {
      // normalization of \\win32\root paths can cause a double / which we don't want
      res.saveSpec = `file:/${res.saveSpec.slice(7)}`
    }
    return res
  }
  function fromHostedGit(res, hosted) {
    res.type = 'git'
    res.hosted = hosted
    res.saveSpec = hosted.toString({
      noGitPlus: false,
      noCommittish: false
    })
    res.fetchSpec =
      hosted.getDefaultRepresentation() === 'shortcut'
        ? null
        : hosted.toString()
    setGitAttrs(res, hosted.committish)
    return res
  }
  function unsupportedURLType(protocol, spec) {
    const err = new Error(`Unsupported URL Type "${protocol}": ${spec}`)
    err.code = 'EUNSUPPORTEDPROTOCOL'
    return err
  }
  function fromURL(res) {
    let rawSpec = res.rawSpec
    res.saveSpec = rawSpec
    if (rawSpec.startsWith('git+ssh:')) {
      // git ssh specifiers are overloaded to also use scp-style git
      // specifiers, so we have to parse those out and treat them special.
      // They are NOT true URIs, so we can't hand them to URL.

      // This regex looks for things that look like:
      // git+ssh://git@my.custom.git.com:username/project.git#deadbeef
      // ...and various combinations. The username in the beginning is *required*.
      const matched = rawSpec.match(
        /^git\+ssh:\/\/([^:#]+:[^#]+(?:\.git)?)(?:#(.*))?$/i
      )
      // Filter out all-number "usernames" which are really port numbers
      // They can either be :1234 :1234/ or :1234/path but not :12abc
      if (matched && !matched[1].match(isPortNumber)) {
        res.type = 'git'
        setGitAttrs(res, matched[2])
        res.fetchSpec = matched[1]
        return res
      }
    } else if (rawSpec.startsWith('git+file://')) {
      // URL can't handle windows paths
      rawSpec = rawSpec.replace(/\\/g, '/')
    }
    const parsedUrl = new URL(rawSpec)
    // check the protocol, and then see if it's git or not
    switch (parsedUrl.protocol) {
      case 'git:':
      case 'git+http:':
      case 'git+https:':
      case 'git+rsync:':
      case 'git+ftp:':
      case 'git+file:':
      case 'git+ssh:':
        res.type = 'git'
        setGitAttrs(res, parsedUrl.hash.slice(1))
        if (
          parsedUrl.protocol === 'git+file:' &&
          /^git\+file:\/\/[a-z]:/i.test(rawSpec)
        ) {
          // URL can't handle drive letters on windows file paths, the host can't contain a :
          res.fetchSpec = `git+file://${parsedUrl.host.toLowerCase()}:${parsedUrl.pathname}`
        } else {
          parsedUrl.hash = ''
          res.fetchSpec = parsedUrl.toString()
        }
        if (res.fetchSpec.startsWith('git+')) {
          res.fetchSpec = res.fetchSpec.slice(4)
        }
        break
      case 'http:':
      case 'https:':
        res.type = 'remote'
        res.fetchSpec = res.saveSpec
        break
      default:
        throw unsupportedURLType(parsedUrl.protocol, rawSpec)
    }
    return res
  }
  function fromAlias(res, where) {
    const subSpec = npa$1(res.rawSpec.substr(4), where)
    if (subSpec.type === 'alias') {
      throw new Error('nested aliases not supported')
    }
    if (!subSpec.registry) {
      throw new Error('aliases only work for registry deps')
    }
    if (!subSpec.name) {
      throw new Error('aliases must have a name')
    }
    res.subSpec = subSpec
    res.registry = true
    res.type = 'alias'
    res.saveSpec = null
    res.fetchSpec = null
    return res
  }
  function fromRegistry(res) {
    res.registry = true
    const spec = res.rawSpec.trim()
    // no save spec for registry components as we save based on the fetched
    // version, not on the argument so this can't compute that.
    res.saveSpec = null
    res.fetchSpec = spec
    const version = semver.valid(spec, true)
    const range = semver.validRange(spec, true)
    if (version) {
      res.type = 'version'
    } else if (range) {
      res.type = 'range'
    } else {
      if (encodeURIComponent(spec) !== spec) {
        throw invalidTagName(spec, res.raw)
      }
      res.type = 'tag'
    }
    return res
  }
  npa.exports = npa$1
  npa.exports.resolve = resolve
  npa.exports.toPurl = toPurl
  npa.exports.Result = Result
  return npa.exports
}

let currentEnv
let hasRequiredCurrentEnv
function requireCurrentEnv() {
  if (hasRequiredCurrentEnv) {
    return currentEnv
  }
  hasRequiredCurrentEnv = 1
  const process = require$$0$6
  const nodeOs = require$$1$6
  const fs = require$$4
  function isMusl(file) {
    return file.includes('libc.musl-') || file.includes('ld-musl-')
  }
  function os() {
    return process.platform
  }
  function cpu() {
    return process.arch
  }
  const LDD_PATH = '/usr/bin/ldd'
  function getFamilyFromFilesystem() {
    try {
      const content = fs.readFileSync(LDD_PATH, 'utf-8')
      if (content.includes('musl')) {
        return 'musl'
      }
      if (content.includes('GNU C Library')) {
        return 'glibc'
      }
      return null
    } catch {
      return undefined
    }
  }
  function getFamilyFromReport() {
    const originalExclude = process.report.excludeNetwork
    process.report.excludeNetwork = true
    const report = process.report.getReport()
    process.report.excludeNetwork = originalExclude
    if (report.header?.glibcVersionRuntime) {
      family = 'glibc'
    } else if (
      Array.isArray(report.sharedObjects) &&
      report.sharedObjects.some(isMusl)
    ) {
      family = 'musl'
    } else {
      family = null
    }
    return family
  }
  let family
  function libc(osName) {
    if (osName !== 'linux') {
      return undefined
    }
    if (family === undefined) {
      family = getFamilyFromFilesystem()
      if (family === undefined) {
        family = getFamilyFromReport()
      }
    }
    return family
  }
  function devEngines(env = {}) {
    const osName = env.os || os()
    return {
      cpu: {
        name: env.cpu || cpu()
      },
      libc: {
        name: env.libc || libc(osName)
      },
      os: {
        name: osName,
        version: env.osVersion || nodeOs.release()
      },
      packageManager: {
        name: 'npm',
        version: env.npmVersion
      },
      runtime: {
        name: 'node',
        version: env.nodeVersion || process.version
      }
    }
  }
  currentEnv = {
    cpu,
    libc,
    os,
    devEngines
  }
  return currentEnv
}

let devEngines
let hasRequiredDevEngines
function requireDevEngines() {
  if (hasRequiredDevEngines) {
    return devEngines
  }
  hasRequiredDevEngines = 1
  const satisfies = requireSatisfies()
  const validRange = requireValid()
  const recognizedOnFail = new Set(['ignore', 'warn', 'error', 'download'])
  const recognizedProperties = ['name', 'version', 'onFail']
  const recognizedEngines = ['packageManager', 'runtime', 'cpu', 'libc', 'os']

  /** checks a devEngine dependency */
  function checkDependency(wanted, current, opts) {
    const { engine } = opts
    if (
      typeof wanted !== 'object' ||
      wanted === null ||
      Array.isArray(wanted)
    ) {
      throw new Error(`Invalid non-object value for "${engine}"`)
    }
    const properties = Object.keys(wanted)
    for (const prop of properties) {
      if (!recognizedProperties.includes(prop)) {
        throw new Error(`Invalid property "${prop}" for "${engine}"`)
      }
    }
    if (!properties.includes('name')) {
      throw new Error(`Missing "name" property for "${engine}"`)
    }
    if (typeof wanted.name !== 'string') {
      throw new Error(`Invalid non-string value for "name" within "${engine}"`)
    }
    if (typeof current.name !== 'string' || current.name === '') {
      throw new Error(`Unable to determine "name" for "${engine}"`)
    }
    if (properties.includes('onFail')) {
      if (typeof wanted.onFail !== 'string') {
        throw new Error(
          `Invalid non-string value for "onFail" within "${engine}"`
        )
      }
      if (!recognizedOnFail.has(wanted.onFail)) {
        throw new Error(
          `Invalid onFail value "${wanted.onFail}" for "${engine}"`
        )
      }
    }
    if (wanted.name !== current.name) {
      return new Error(
        `Invalid name "${wanted.name}" does not match "${current.name}" for "${engine}"`
      )
    }
    if (properties.includes('version')) {
      if (typeof wanted.version !== 'string') {
        throw new Error(
          `Invalid non-string value for "version" within "${engine}"`
        )
      }
      if (typeof current.version !== 'string' || current.version === '') {
        throw new Error(
          `Unable to determine "version" for "${engine}" "${wanted.name}"`
        )
      }
      if (validRange(wanted.version)) {
        if (!satisfies(current.version, wanted.version, opts.semver)) {
          return new Error(
            // eslint-disable-next-line max-len
            `Invalid semver version "${wanted.version}" does not match "${current.version}" for "${engine}"`
          )
        }
      } else if (wanted.version !== current.version) {
        return new Error(
          `Invalid version "${wanted.version}" does not match "${current.version}" for "${engine}"`
        )
      }
    }
  }

  /** checks devEngines package property and returns array of warnings / errors */
  function checkDevEngines(wanted, current = {}, opts = {}) {
    if (
      typeof wanted !== 'object' ||
      wanted === null ||
      Array.isArray(wanted)
    ) {
      throw new Error(`Invalid non-object value for devEngines`)
    }
    const errors = []
    for (const engine of Object.keys(wanted)) {
      if (!recognizedEngines.includes(engine)) {
        throw new Error(`Invalid property "${engine}"`)
      }
      const dependencyAsAuthored = wanted[engine]
      const dependencies = [dependencyAsAuthored].flat()
      const currentEngine = current[engine] || {}

      // this accounts for empty array eg { runtime: [] } and ignores it
      if (dependencies.length === 0) {
        continue
      }
      const depErrors = []
      for (const dep of dependencies) {
        const result = checkDependency(dep, currentEngine, {
          ...opts,
          engine
        })
        if (result) {
          depErrors.push(result)
        }
      }
      const invalid = depErrors.length === dependencies.length
      if (invalid) {
        const lastDependency = dependencies[dependencies.length - 1]
        let onFail = lastDependency.onFail || 'error'
        if (onFail === 'download') {
          onFail = 'error'
        }
        const err = Object.assign(new Error(`Invalid engine "${engine}"`), {
          errors: depErrors,
          engine,
          isWarn: onFail === 'warn',
          isError: onFail === 'error',
          current: currentEngine,
          required: dependencyAsAuthored
        })
        errors.push(err)
      }
    }
    return errors
  }
  devEngines = {
    checkDevEngines
  }
  return devEngines
}

let lib$4
let hasRequiredLib$4
function requireLib$4() {
  if (hasRequiredLib$4) {
    return lib$4
  }
  hasRequiredLib$4 = 1
  const semver = requireSemver()
  const currentEnv = requireCurrentEnv()
  const { checkDevEngines } = requireDevEngines()
  const checkEngine = (target, npmVer, nodeVer, force = false) => {
    const nodev = force ? null : nodeVer
    const eng = target.engines
    const opt = {
      includePrerelease: true
    }
    if (!eng) {
      return
    }
    const nodeFail =
      nodev && eng.node && !semver.satisfies(nodev, eng.node, opt)
    const npmFail = npmVer && eng.npm && !semver.satisfies(npmVer, eng.npm, opt)
    if (nodeFail || npmFail) {
      throw Object.assign(new Error('Unsupported engine'), {
        pkgid: target._id,
        current: {
          node: nodeVer,
          npm: npmVer
        },
        required: eng,
        code: 'EBADENGINE'
      })
    }
  }
  const checkPlatform = (target, force = false, environment = {}) => {
    if (force) {
      return
    }
    const os = environment.os || currentEnv.os()
    const cpu = environment.cpu || currentEnv.cpu()
    const libc = environment.libc || currentEnv.libc(os)
    const osOk = target.os ? checkList(os, target.os) : true
    const cpuOk = target.cpu ? checkList(cpu, target.cpu) : true
    let libcOk = target.libc ? checkList(libc, target.libc) : true
    if (target.libc && !libc) {
      libcOk = false
    }
    if (!osOk || !cpuOk || !libcOk) {
      throw Object.assign(new Error('Unsupported platform'), {
        pkgid: target._id,
        current: {
          os,
          cpu,
          libc
        },
        required: {
          os: target.os,
          cpu: target.cpu,
          libc: target.libc
        },
        code: 'EBADPLATFORM'
      })
    }
  }
  const checkList = (value, list) => {
    if (typeof list === 'string') {
      list = [list]
    }
    if (list.length === 1 && list[0] === 'any') {
      return true
    }
    // match none of the negated values, and at least one of the
    // non-negated values, if any are present.
    let negated = 0
    let match = false
    for (const entry of list) {
      const negate = entry.charAt(0) === '!'
      const test = negate ? entry.slice(1) : entry
      if (negate) {
        negated++
        if (value === test) {
          return false
        }
      } else {
        match = match || value === test
      }
    }
    return match || negated === list.length
  }
  lib$4 = {
    checkEngine,
    checkPlatform,
    checkDevEngines,
    currentEnv
  }
  return lib$4
}

let lib$3
let hasRequiredLib$3
function requireLib$3() {
  if (hasRequiredLib$3) {
    return lib$3
  }
  hasRequiredLib$3 = 1
  // pass in a manifest with a 'bin' field here, and it'll turn it
  // into a properly santized bin object
  const { join, basename } = require$$1$4
  const normalize = pkg =>
    !pkg.bin
      ? removeBin(pkg)
      : typeof pkg.bin === 'string'
        ? normalizeString(pkg)
        : Array.isArray(pkg.bin)
          ? normalizeArray(pkg)
          : typeof pkg.bin === 'object'
            ? normalizeObject(pkg)
            : removeBin(pkg)
  const normalizeString = pkg => {
    if (!pkg.name) {
      return removeBin(pkg)
    }
    pkg.bin = {
      [pkg.name]: pkg.bin
    }
    return normalizeObject(pkg)
  }
  const normalizeArray = pkg => {
    pkg.bin = pkg.bin.reduce((acc, k) => {
      acc[basename(k)] = k
      return acc
    }, {})
    return normalizeObject(pkg)
  }
  const removeBin = pkg => {
    delete pkg.bin
    return pkg
  }
  const normalizeObject = pkg => {
    const orig = pkg.bin
    const clean = {}
    let hasBins = false
    Object.keys(orig).forEach(binKey => {
      const base = join('/', basename(binKey.replace(/\\|:/g, '/'))).slice(1)
      if (typeof orig[binKey] !== 'string' || !base) {
        return
      }
      const binTarget = join('/', orig[binKey].replace(/\\/g, '/'))
        .replace(/\\/g, '/')
        .slice(1)
      if (!binTarget) {
        return
      }
      clean[base] = binTarget
      hasBins = true
    })
    if (hasBins) {
      pkg.bin = clean
    } else {
      delete pkg.bin
    }
    return pkg
  }
  lib$3 = normalize
  return lib$3
}

let lib$2
let hasRequiredLib$2
function requireLib$2() {
  if (hasRequiredLib$2) {
    return lib$2
  }
  hasRequiredLib$2 = 1
  const npa = requireNpa()
  const semver = requireSemver()
  const { checkEngine } = requireLib$4()
  const normalizeBin = requireLib$3()
  const engineOk = (manifest, npmVersion, nodeVersion) => {
    try {
      checkEngine(manifest, npmVersion, nodeVersion)
      return true
    } catch (_) {
      return false
    }
  }
  const isBefore = (verTimes, ver, time) =>
    !verTimes || !verTimes[ver] || Date.parse(verTimes[ver]) <= time
  const avoidSemverOpt = {
    includePrerelease: true,
    loose: true
  }
  const shouldAvoid = (ver, avoid) =>
    avoid && semver.satisfies(ver, avoid, avoidSemverOpt)
  const decorateAvoid = (result, avoid) =>
    result && shouldAvoid(result.version, avoid)
      ? {
          ...result,
          _shouldAvoid: true
        }
      : result
  const pickManifest = (packument, wanted, opts) => {
    const {
      defaultTag = 'latest',
      before = null,
      nodeVersion = process.version,
      npmVersion = null,
      includeStaged = false,
      avoid = null,
      avoidStrict = false
    } = opts
    const { name, time: verTimes } = packument
    const versions = packument.versions || {}
    if (avoidStrict) {
      const looseOpts = {
        ...opts,
        avoidStrict: false
      }
      const result = pickManifest(packument, wanted, looseOpts)
      if (!result || !result._shouldAvoid) {
        return result
      }
      const caret = pickManifest(packument, `^${result.version}`, looseOpts)
      if (!caret || !caret._shouldAvoid) {
        return {
          ...caret,
          _outsideDependencyRange: true,
          _isSemVerMajor: false
        }
      }
      const star = pickManifest(packument, '*', looseOpts)
      if (!star || !star._shouldAvoid) {
        return {
          ...star,
          _outsideDependencyRange: true,
          _isSemVerMajor: true
        }
      }
      throw Object.assign(new Error(`No avoidable versions for ${name}`), {
        code: 'ETARGET',
        name,
        wanted,
        avoid,
        before,
        versions: Object.keys(versions)
      })
    }
    const staged =
      (includeStaged &&
        packument.stagedVersions &&
        packument.stagedVersions.versions) ||
      {}
    const restricted =
      (packument.policyRestrictions && packument.policyRestrictions.versions) ||
      {}
    const time = before && verTimes ? +new Date(before) : Infinity
    const spec = npa.resolve(name, wanted || defaultTag)
    const type = spec.type
    const distTags = packument['dist-tags'] || {}
    if (type !== 'tag' && type !== 'version' && type !== 'range') {
      throw new Error('Only tag, version, and range are supported')
    }

    // if the type is 'tag', and not just the implicit default, then it must
    // be that exactly, or nothing else will do.
    if (wanted && type === 'tag') {
      const ver = distTags[wanted]
      // if the version in the dist-tags is before the before date, then
      // we use that.  Otherwise, we get the highest precedence version
      // prior to the dist-tag.
      if (isBefore(verTimes, ver, time)) {
        return decorateAvoid(
          versions[ver] || staged[ver] || restricted[ver],
          avoid
        )
      } else {
        return pickManifest(packument, `<=${ver}`, opts)
      }
    }

    // similarly, if a specific version, then only that version will do
    if (wanted && type === 'version') {
      const ver = semver.clean(wanted, {
        loose: true
      })
      const mani = versions[ver] || staged[ver] || restricted[ver]
      return isBefore(verTimes, ver, time) ? decorateAvoid(mani, avoid) : null
    }

    // ok, sort based on our heuristics, and pick the best fit
    const range = type === 'range' ? wanted : '*'

    // if the range is *, then we prefer the 'latest' if available
    // but skip this if it should be avoided, in that case we have
    // to try a little harder.
    const defaultVer = distTags[defaultTag]
    if (
      defaultVer &&
      (range === '*' ||
        semver.satisfies(defaultVer, range, {
          loose: true
        })) &&
      !restricted[defaultVer] &&
      !shouldAvoid(defaultVer, avoid)
    ) {
      const mani = versions[defaultVer]
      const ok =
        mani &&
        isBefore(verTimes, defaultVer, time) &&
        engineOk(mani, npmVersion, nodeVersion) &&
        !mani.deprecated &&
        !staged[defaultVer]
      if (ok) {
        return mani
      }
    }

    // ok, actually have to sort the list and take the winner
    const allEntries = Object.entries(versions)
      .concat(Object.entries(staged))
      .concat(Object.entries(restricted))
      .filter(([ver]) => isBefore(verTimes, ver, time))
    if (!allEntries.length) {
      throw Object.assign(new Error(`No versions available for ${name}`), {
        code: 'ENOVERSIONS',
        name,
        type,
        wanted,
        before,
        versions: Object.keys(versions)
      })
    }
    const sortSemverOpt = {
      loose: true
    }
    const entries = allEntries
      .filter(([ver]) =>
        semver.satisfies(ver, range, {
          loose: true
        })
      )
      .sort((a, b) => {
        const [vera, mania] = a
        const [verb, manib] = b
        const notavoida = !shouldAvoid(vera, avoid)
        const notavoidb = !shouldAvoid(verb, avoid)
        const notrestra = !restricted[vera]
        const notrestrb = !restricted[verb]
        const notstagea = !staged[vera]
        const notstageb = !staged[verb]
        const notdepra = !mania.deprecated
        const notdeprb = !manib.deprecated
        const enginea = engineOk(mania, npmVersion, nodeVersion)
        const engineb = engineOk(manib, npmVersion, nodeVersion)
        // sort by:
        // - not an avoided version
        // - not restricted
        // - not staged
        // - not deprecated and engine ok
        // - engine ok
        // - not deprecated
        // - semver
        return (
          notavoidb - notavoida ||
          notrestrb - notrestra ||
          notstageb - notstagea ||
          (notdeprb && engineb) - (notdepra && enginea) ||
          engineb - enginea ||
          notdeprb - notdepra ||
          semver.rcompare(vera, verb, sortSemverOpt)
        )
      })
    return decorateAvoid(entries[0] && entries[0][1], avoid)
  }
  lib$2 = (packument, wanted, opts = {}) => {
    const mani = pickManifest(packument, wanted, opts)
    const picked = mani && normalizeBin(mani)
    const policyRestrictions = packument.policyRestrictions
    const restricted = (policyRestrictions && policyRestrictions.versions) || {}
    if (picked && !restricted[picked.version]) {
      return picked
    }
    const { before = null, defaultTag = 'latest' } = opts
    const bstr = before ? new Date(before).toLocaleString() : ''
    const { name } = packument
    const pckg =
      `${name}@${wanted}` + (before ? ` with a date before ${bstr}` : '')
    const isForbidden = picked && !!restricted[picked.version]
    const polMsg = isForbidden ? policyRestrictions.message : ''
    const msg = !isForbidden
      ? `No matching version found for ${pckg}.`
      : `Could not download ${pckg} due to policy violations:\n${polMsg}`
    const code = isForbidden ? 'E403' : 'ETARGET'
    throw Object.assign(new Error(msg), {
      code,
      type: npa.resolve(packument.name, wanted).type,
      wanted,
      versions: Object.keys(packument.versions ?? {}),
      name,
      distTags: packument['dist-tags'],
      defaultTag
    })
  }
  return lib$2
}

let clone_1
let hasRequiredClone
function requireClone() {
  if (hasRequiredClone) {
    return clone_1
  }
  hasRequiredClone = 1
  // The goal here is to minimize both git workload and
  // the number of refs we download over the network.
  //
  // Every method ends up with the checked out working dir
  // at the specified ref, and resolves with the git sha.

  // Only certain whitelisted hosts get shallow cloning.
  // Many hosts (including GHE) don't always support it.
  // A failed shallow fetch takes a LOT longer than a full
  // fetch in most cases, so we skip it entirely.
  // Set opts.gitShallow = true/false to force this behavior
  // one way or the other.
  const shallowHosts = new Set([
    'github.com',
    'gist.github.com',
    'gitlab.com',
    'bitbucket.com',
    'bitbucket.org'
  ])
  // we have to use url.parse until we add the same shim that hosted-git-info has
  // to handle scp:// urls
  const { parse } = require$$0 // eslint-disable-line node/no-deprecated-api
  const path = require$$1$4
  const getRevs = requireRevs()
  const spawn = requireSpawn()
  const { isWindows } = requireUtils()
  const pickManifest = requireLib$2()
  const fs = require$$1$3
  clone_1 = (repo, ref = 'HEAD', target = null, opts = {}) =>
    getRevs(repo, opts).then(revs =>
      clone(
        repo,
        revs,
        ref,
        resolveRef(revs, ref, opts),
        target || defaultTarget(repo, opts.cwd),
        opts
      )
    )
  const maybeShallow = (repo, opts) => {
    if (opts.gitShallow === false || opts.gitShallow) {
      return opts.gitShallow
    }
    return shallowHosts.has(parse(repo).host)
  }
  const defaultTarget = (
    repo,
    /* istanbul ignore next */ cwd = process.cwd()
  ) => path.resolve(cwd, path.basename(repo.replace(/[/\\]?\.git$/, '')))
  const clone = (repo, revs, ref, revDoc, target, opts) => {
    if (!revDoc) {
      return unresolved(repo, ref, target, opts)
    }
    if (revDoc.sha === revs.refs.HEAD.sha) {
      return plain(repo, revDoc, target, opts)
    }
    if (revDoc.type === 'tag' || revDoc.type === 'branch') {
      return branch(repo, revDoc, target, opts)
    }
    return other(repo, revDoc, target, opts)
  }
  const resolveRef = (revs, ref, opts) => {
    const { spec = {} } = opts
    ref = spec.gitCommittish || ref
    /* istanbul ignore next - will fail anyway, can't pull */
    if (!revs) {
      return null
    }
    if (spec.gitRange) {
      return pickManifest(revs, spec.gitRange, opts)
    }
    if (!ref) {
      return revs.refs.HEAD
    }
    if (revs.refs[ref]) {
      return revs.refs[ref]
    }
    if (revs.shas[ref]) {
      return revs.refs[revs.shas[ref][0]]
    }
    return null
  }

  // pull request or some other kind of advertised ref
  const other = (repo, revDoc, target, opts) => {
    const shallow = maybeShallow(repo, opts)
    const fetchOrigin = ['fetch', 'origin', revDoc.rawRef].concat(
      shallow ? ['--depth=1'] : []
    )
    const git = args =>
      spawn(args, {
        ...opts,
        cwd: target
      })
    return fs
      .mkdir(target, {
        recursive: true
      })
      .then(() => git(['init']))
      .then(() =>
        isWindows(opts)
          ? git(['config', '--local', '--add', 'core.longpaths', 'true'])
          : null
      )
      .then(() => git(['remote', 'add', 'origin', repo]))
      .then(() => git(fetchOrigin))
      .then(() => git(['checkout', revDoc.sha]))
      .then(() => updateSubmodules(target, opts))
      .then(() => revDoc.sha)
  }

  // tag or branches.  use -b
  const branch = (repo, revDoc, target, opts) => {
    const args = [
      'clone',
      '-b',
      revDoc.ref,
      repo,
      target,
      '--recurse-submodules'
    ]
    if (maybeShallow(repo, opts)) {
      args.push('--depth=1')
    }
    if (isWindows(opts)) {
      args.push('--config', 'core.longpaths=true')
    }
    return spawn(args, opts).then(() => revDoc.sha)
  }

  // just the head.  clone it
  const plain = (repo, revDoc, target, opts) => {
    const args = ['clone', repo, target, '--recurse-submodules']
    if (maybeShallow(repo, opts)) {
      args.push('--depth=1')
    }
    if (isWindows(opts)) {
      args.push('--config', 'core.longpaths=true')
    }
    return spawn(args, opts).then(() => revDoc.sha)
  }
  const updateSubmodules = async (target, opts) => {
    const hasSubmodules = await fs
      .stat(`${target}/.gitmodules`)
      .then(() => true)
      .catch(() => false)
    if (!hasSubmodules) {
      return null
    }
    return spawn(['submodule', 'update', '-q', '--init', '--recursive'], {
      ...opts,
      cwd: target
    })
  }
  const unresolved = (repo, ref, target, opts) => {
    // can't do this one shallowly, because the ref isn't advertised
    // but we can avoid checking out the working dir twice, at least
    const lp = isWindows(opts) ? ['--config', 'core.longpaths=true'] : []
    const cloneArgs = ['clone', '--mirror', '-q', repo, target + '/.git']
    const git = args =>
      spawn(args, {
        ...opts,
        cwd: target
      })
    return fs
      .mkdir(target, {
        recursive: true
      })
      .then(() => git(cloneArgs.concat(lp)))
      .then(() => git(['init']))
      .then(() => git(['checkout', ref]))
      .then(() => updateSubmodules(target, opts))
      .then(() => git(['rev-parse', '--revs-only', 'HEAD']))
      .then(({ stdout }) => stdout.trim())
  }
  return clone_1
}

let is
let hasRequiredIs
function requireIs() {
  if (hasRequiredIs) {
    return is
  }
  hasRequiredIs = 1
  // not an airtight indicator, but a good gut-check to even bother trying
  const { stat } = require$$1$3
  is = ({ cwd = process.cwd() } = {}) =>
    stat(cwd + '/.git').then(
      () => true,
      () => false
    )
  return is
}

let find
let hasRequiredFind
function requireFind() {
  if (hasRequiredFind) {
    return find
  }
  hasRequiredFind = 1
  const is = requireIs()
  const { dirname } = require$$1$4
  find = async ({ cwd = process.cwd(), root } = {}) => {
    while (true) {
      if (
        await is({
          cwd
        })
      ) {
        return cwd
      }
      const next = dirname(cwd)
      if (cwd === root || cwd === next) {
        return null
      }
      cwd = next
    }
  }
  return find
}

let isClean
let hasRequiredIsClean
function requireIsClean() {
  if (hasRequiredIsClean) {
    return isClean
  }
  hasRequiredIsClean = 1
  const spawn = requireSpawn()
  isClean = (opts = {}) =>
    spawn(['status', '--porcelain=v1', '-uno'], opts).then(
      res =>
        !res.stdout
          .trim()
          .split(/\r?\n+/)
          .map(l => l.trim())
          .filter(l => l).length
    )
  return isClean
}

let lib$1
let hasRequiredLib$1
function requireLib$1() {
  if (hasRequiredLib$1) {
    return lib$1
  }
  hasRequiredLib$1 = 1
  lib$1 = {
    clone: requireClone(),
    revs: requireRevs(),
    spawn: requireSpawn(),
    is: requireIs(),
    find: requireFind(),
    isClean: requireIsClean(),
    errors: requireErrors()
  }
  return lib$1
}

const require$$1$1 = [
  '0BSD',
  '3D-Slicer-1.0',
  'AAL',
  'ADSL',
  'AFL-1.1',
  'AFL-1.2',
  'AFL-2.0',
  'AFL-2.1',
  'AFL-3.0',
  'AGPL-1.0-only',
  'AGPL-1.0-or-later',
  'AGPL-3.0-only',
  'AGPL-3.0-or-later',
  'AMD-newlib',
  'AMDPLPA',
  'AML',
  'AML-glslang',
  'AMPAS',
  'ANTLR-PD',
  'ANTLR-PD-fallback',
  'APAFML',
  'APL-1.0',
  'APSL-1.0',
  'APSL-1.1',
  'APSL-1.2',
  'APSL-2.0',
  'ASWF-Digital-Assets-1.0',
  'ASWF-Digital-Assets-1.1',
  'Abstyles',
  'AdaCore-doc',
  'Adobe-2006',
  'Adobe-Display-PostScript',
  'Adobe-Glyph',
  'Adobe-Utopia',
  'Afmparse',
  'Aladdin',
  'Apache-1.0',
  'Apache-1.1',
  'Apache-2.0',
  'App-s2p',
  'Arphic-1999',
  'Artistic-1.0',
  'Artistic-1.0-Perl',
  'Artistic-1.0-cl8',
  'Artistic-2.0',
  'BSD-1-Clause',
  'BSD-2-Clause',
  'BSD-2-Clause-Darwin',
  'BSD-2-Clause-Patent',
  'BSD-2-Clause-Views',
  'BSD-2-Clause-first-lines',
  'BSD-3-Clause',
  'BSD-3-Clause-Attribution',
  'BSD-3-Clause-Clear',
  'BSD-3-Clause-HP',
  'BSD-3-Clause-LBNL',
  'BSD-3-Clause-Modification',
  'BSD-3-Clause-No-Military-License',
  'BSD-3-Clause-No-Nuclear-License',
  'BSD-3-Clause-No-Nuclear-License-2014',
  'BSD-3-Clause-No-Nuclear-Warranty',
  'BSD-3-Clause-Open-MPI',
  'BSD-3-Clause-Sun',
  'BSD-3-Clause-acpica',
  'BSD-3-Clause-flex',
  'BSD-4-Clause',
  'BSD-4-Clause-Shortened',
  'BSD-4-Clause-UC',
  'BSD-4.3RENO',
  'BSD-4.3TAHOE',
  'BSD-Advertising-Acknowledgement',
  'BSD-Attribution-HPND-disclaimer',
  'BSD-Inferno-Nettverk',
  'BSD-Protection',
  'BSD-Source-Code',
  'BSD-Source-beginning-file',
  'BSD-Systemics',
  'BSD-Systemics-W3Works',
  'BSL-1.0',
  'BUSL-1.1',
  'Baekmuk',
  'Bahyph',
  'Barr',
  'Beerware',
  'BitTorrent-1.0',
  'BitTorrent-1.1',
  'Bitstream-Charter',
  'Bitstream-Vera',
  'BlueOak-1.0.0',
  'Boehm-GC',
  'Boehm-GC-without-fee',
  'Borceux',
  'Brian-Gladman-2-Clause',
  'Brian-Gladman-3-Clause',
  'C-UDA-1.0',
  'CAL-1.0',
  'CAL-1.0-Combined-Work-Exception',
  'CATOSL-1.1',
  'CC-BY-1.0',
  'CC-BY-2.0',
  'CC-BY-2.5',
  'CC-BY-2.5-AU',
  'CC-BY-3.0',
  'CC-BY-3.0-AT',
  'CC-BY-3.0-AU',
  'CC-BY-3.0-DE',
  'CC-BY-3.0-IGO',
  'CC-BY-3.0-NL',
  'CC-BY-3.0-US',
  'CC-BY-4.0',
  'CC-BY-NC-1.0',
  'CC-BY-NC-2.0',
  'CC-BY-NC-2.5',
  'CC-BY-NC-3.0',
  'CC-BY-NC-3.0-DE',
  'CC-BY-NC-4.0',
  'CC-BY-NC-ND-1.0',
  'CC-BY-NC-ND-2.0',
  'CC-BY-NC-ND-2.5',
  'CC-BY-NC-ND-3.0',
  'CC-BY-NC-ND-3.0-DE',
  'CC-BY-NC-ND-3.0-IGO',
  'CC-BY-NC-ND-4.0',
  'CC-BY-NC-SA-1.0',
  'CC-BY-NC-SA-2.0',
  'CC-BY-NC-SA-2.0-DE',
  'CC-BY-NC-SA-2.0-FR',
  'CC-BY-NC-SA-2.0-UK',
  'CC-BY-NC-SA-2.5',
  'CC-BY-NC-SA-3.0',
  'CC-BY-NC-SA-3.0-DE',
  'CC-BY-NC-SA-3.0-IGO',
  'CC-BY-NC-SA-4.0',
  'CC-BY-ND-1.0',
  'CC-BY-ND-2.0',
  'CC-BY-ND-2.5',
  'CC-BY-ND-3.0',
  'CC-BY-ND-3.0-DE',
  'CC-BY-ND-4.0',
  'CC-BY-SA-1.0',
  'CC-BY-SA-2.0',
  'CC-BY-SA-2.0-UK',
  'CC-BY-SA-2.1-JP',
  'CC-BY-SA-2.5',
  'CC-BY-SA-3.0',
  'CC-BY-SA-3.0-AT',
  'CC-BY-SA-3.0-DE',
  'CC-BY-SA-3.0-IGO',
  'CC-BY-SA-4.0',
  'CC-PDDC',
  'CC-PDM-1.0',
  'CC-SA-1.0',
  'CC0-1.0',
  'CDDL-1.0',
  'CDDL-1.1',
  'CDL-1.0',
  'CDLA-Permissive-1.0',
  'CDLA-Permissive-2.0',
  'CDLA-Sharing-1.0',
  'CECILL-1.0',
  'CECILL-1.1',
  'CECILL-2.0',
  'CECILL-2.1',
  'CECILL-B',
  'CECILL-C',
  'CERN-OHL-1.1',
  'CERN-OHL-1.2',
  'CERN-OHL-P-2.0',
  'CERN-OHL-S-2.0',
  'CERN-OHL-W-2.0',
  'CFITSIO',
  'CMU-Mach',
  'CMU-Mach-nodoc',
  'CNRI-Jython',
  'CNRI-Python',
  'CNRI-Python-GPL-Compatible',
  'COIL-1.0',
  'CPAL-1.0',
  'CPL-1.0',
  'CPOL-1.02',
  'CUA-OPL-1.0',
  'Caldera',
  'Caldera-no-preamble',
  'Catharon',
  'ClArtistic',
  'Clips',
  'Community-Spec-1.0',
  'Condor-1.1',
  'Cornell-Lossless-JPEG',
  'Cronyx',
  'Crossword',
  'CrystalStacker',
  'Cube',
  'D-FSL-1.0',
  'DEC-3-Clause',
  'DL-DE-BY-2.0',
  'DL-DE-ZERO-2.0',
  'DOC',
  'DRL-1.0',
  'DRL-1.1',
  'DSDP',
  'DocBook-Schema',
  'DocBook-Stylesheet',
  'DocBook-XML',
  'Dotseqn',
  'ECL-1.0',
  'ECL-2.0',
  'EFL-1.0',
  'EFL-2.0',
  'EPICS',
  'EPL-1.0',
  'EPL-2.0',
  'EUDatagrid',
  'EUPL-1.0',
  'EUPL-1.1',
  'EUPL-1.2',
  'Elastic-2.0',
  'Entessa',
  'ErlPL-1.1',
  'Eurosym',
  'FBM',
  'FDK-AAC',
  'FSFAP',
  'FSFAP-no-warranty-disclaimer',
  'FSFUL',
  'FSFULLR',
  'FSFULLRWD',
  'FTL',
  'Fair',
  'Ferguson-Twofish',
  'Frameworx-1.0',
  'FreeBSD-DOC',
  'FreeImage',
  'Furuseth',
  'GCR-docs',
  'GD',
  'GFDL-1.1-invariants-only',
  'GFDL-1.1-invariants-or-later',
  'GFDL-1.1-no-invariants-only',
  'GFDL-1.1-no-invariants-or-later',
  'GFDL-1.1-only',
  'GFDL-1.1-or-later',
  'GFDL-1.2-invariants-only',
  'GFDL-1.2-invariants-or-later',
  'GFDL-1.2-no-invariants-only',
  'GFDL-1.2-no-invariants-or-later',
  'GFDL-1.2-only',
  'GFDL-1.2-or-later',
  'GFDL-1.3-invariants-only',
  'GFDL-1.3-invariants-or-later',
  'GFDL-1.3-no-invariants-only',
  'GFDL-1.3-no-invariants-or-later',
  'GFDL-1.3-only',
  'GFDL-1.3-or-later',
  'GL2PS',
  'GLWTPL',
  'GPL-1.0-only',
  'GPL-1.0-or-later',
  'GPL-2.0-only',
  'GPL-2.0-or-later',
  'GPL-3.0-only',
  'GPL-3.0-or-later',
  'Giftware',
  'Glide',
  'Glulxe',
  'Graphics-Gems',
  'Gutmann',
  'HIDAPI',
  'HP-1986',
  'HP-1989',
  'HPND',
  'HPND-DEC',
  'HPND-Fenneberg-Livingston',
  'HPND-INRIA-IMAG',
  'HPND-Intel',
  'HPND-Kevlin-Henney',
  'HPND-MIT-disclaimer',
  'HPND-Markus-Kuhn',
  'HPND-Netrek',
  'HPND-Pbmplus',
  'HPND-UC',
  'HPND-UC-export-US',
  'HPND-doc',
  'HPND-doc-sell',
  'HPND-export-US',
  'HPND-export-US-acknowledgement',
  'HPND-export-US-modify',
  'HPND-export2-US',
  'HPND-merchantability-variant',
  'HPND-sell-MIT-disclaimer-xserver',
  'HPND-sell-regexpr',
  'HPND-sell-variant',
  'HPND-sell-variant-MIT-disclaimer',
  'HPND-sell-variant-MIT-disclaimer-rev',
  'HTMLTIDY',
  'HaskellReport',
  'Hippocratic-2.1',
  'IBM-pibs',
  'ICU',
  'IEC-Code-Components-EULA',
  'IJG',
  'IJG-short',
  'IPA',
  'IPL-1.0',
  'ISC',
  'ISC-Veillard',
  'ImageMagick',
  'Imlib2',
  'Info-ZIP',
  'Inner-Net-2.0',
  'InnoSetup',
  'Intel',
  'Intel-ACPI',
  'Interbase-1.0',
  'JPL-image',
  'JPNIC',
  'JSON',
  'Jam',
  'JasPer-2.0',
  'Kastrup',
  'Kazlib',
  'Knuth-CTAN',
  'LAL-1.2',
  'LAL-1.3',
  'LGPL-2.0-only',
  'LGPL-2.0-or-later',
  'LGPL-2.1-only',
  'LGPL-2.1-or-later',
  'LGPL-3.0-only',
  'LGPL-3.0-or-later',
  'LGPLLR',
  'LOOP',
  'LPD-document',
  'LPL-1.0',
  'LPL-1.02',
  'LPPL-1.0',
  'LPPL-1.1',
  'LPPL-1.2',
  'LPPL-1.3a',
  'LPPL-1.3c',
  'LZMA-SDK-9.11-to-9.20',
  'LZMA-SDK-9.22',
  'Latex2e',
  'Latex2e-translated-notice',
  'Leptonica',
  'LiLiQ-P-1.1',
  'LiLiQ-R-1.1',
  'LiLiQ-Rplus-1.1',
  'Libpng',
  'Linux-OpenIB',
  'Linux-man-pages-1-para',
  'Linux-man-pages-copyleft',
  'Linux-man-pages-copyleft-2-para',
  'Linux-man-pages-copyleft-var',
  'Lucida-Bitmap-Fonts',
  'MIPS',
  'MIT',
  'MIT-0',
  'MIT-CMU',
  'MIT-Click',
  'MIT-Festival',
  'MIT-Khronos-old',
  'MIT-Modern-Variant',
  'MIT-Wu',
  'MIT-advertising',
  'MIT-enna',
  'MIT-feh',
  'MIT-open-group',
  'MIT-testregex',
  'MITNFA',
  'MMIXware',
  'MPEG-SSG',
  'MPL-1.0',
  'MPL-1.1',
  'MPL-2.0',
  'MPL-2.0-no-copyleft-exception',
  'MS-LPL',
  'MS-PL',
  'MS-RL',
  'MTLL',
  'Mackerras-3-Clause',
  'Mackerras-3-Clause-acknowledgment',
  'MakeIndex',
  'Martin-Birgmeier',
  'McPhee-slideshow',
  'Minpack',
  'MirOS',
  'Motosoto',
  'MulanPSL-1.0',
  'MulanPSL-2.0',
  'Multics',
  'Mup',
  'NAIST-2003',
  'NASA-1.3',
  'NBPL-1.0',
  'NCBI-PD',
  'NCGL-UK-2.0',
  'NCL',
  'NCSA',
  'NGPL',
  'NICTA-1.0',
  'NIST-PD',
  'NIST-PD-fallback',
  'NIST-Software',
  'NLOD-1.0',
  'NLOD-2.0',
  'NLPL',
  'NOSL',
  'NPL-1.0',
  'NPL-1.1',
  'NPOSL-3.0',
  'NRL',
  'NTP',
  'NTP-0',
  'Naumen',
  'NetCDF',
  'Newsletr',
  'Nokia',
  'Noweb',
  'O-UDA-1.0',
  'OAR',
  'OCCT-PL',
  'OCLC-2.0',
  'ODC-By-1.0',
  'ODbL-1.0',
  'OFFIS',
  'OFL-1.0',
  'OFL-1.0-RFN',
  'OFL-1.0-no-RFN',
  'OFL-1.1',
  'OFL-1.1-RFN',
  'OFL-1.1-no-RFN',
  'OGC-1.0',
  'OGDL-Taiwan-1.0',
  'OGL-Canada-2.0',
  'OGL-UK-1.0',
  'OGL-UK-2.0',
  'OGL-UK-3.0',
  'OGTSL',
  'OLDAP-1.1',
  'OLDAP-1.2',
  'OLDAP-1.3',
  'OLDAP-1.4',
  'OLDAP-2.0',
  'OLDAP-2.0.1',
  'OLDAP-2.1',
  'OLDAP-2.2',
  'OLDAP-2.2.1',
  'OLDAP-2.2.2',
  'OLDAP-2.3',
  'OLDAP-2.4',
  'OLDAP-2.5',
  'OLDAP-2.6',
  'OLDAP-2.7',
  'OLDAP-2.8',
  'OLFL-1.3',
  'OML',
  'OPL-1.0',
  'OPL-UK-3.0',
  'OPUBL-1.0',
  'OSET-PL-2.1',
  'OSL-1.0',
  'OSL-1.1',
  'OSL-2.0',
  'OSL-2.1',
  'OSL-3.0',
  'OpenPBS-2.3',
  'OpenSSL',
  'OpenSSL-standalone',
  'OpenVision',
  'PADL',
  'PDDL-1.0',
  'PHP-3.0',
  'PHP-3.01',
  'PPL',
  'PSF-2.0',
  'Parity-6.0.0',
  'Parity-7.0.0',
  'Pixar',
  'Plexus',
  'PolyForm-Noncommercial-1.0.0',
  'PolyForm-Small-Business-1.0.0',
  'PostgreSQL',
  'Python-2.0',
  'Python-2.0.1',
  'QPL-1.0',
  'QPL-1.0-INRIA-2004',
  'Qhull',
  'RHeCos-1.1',
  'RPL-1.1',
  'RPL-1.5',
  'RPSL-1.0',
  'RSA-MD',
  'RSCPL',
  'Rdisc',
  'Ruby',
  'Ruby-pty',
  'SAX-PD',
  'SAX-PD-2.0',
  'SCEA',
  'SGI-B-1.0',
  'SGI-B-1.1',
  'SGI-B-2.0',
  'SGI-OpenGL',
  'SGP4',
  'SHL-0.5',
  'SHL-0.51',
  'SISSL',
  'SISSL-1.2',
  'SL',
  'SMAIL-GPL',
  'SMLNJ',
  'SMPPL',
  'SNIA',
  'SPL-1.0',
  'SSH-OpenSSH',
  'SSH-short',
  'SSLeay-standalone',
  'SSPL-1.0',
  'SWL',
  'Saxpath',
  'SchemeReport',
  'Sendmail',
  'Sendmail-8.23',
  'Sendmail-Open-Source-1.1',
  'SimPL-2.0',
  'Sleepycat',
  'Soundex',
  'Spencer-86',
  'Spencer-94',
  'Spencer-99',
  'SugarCRM-1.1.3',
  'Sun-PPP',
  'Sun-PPP-2000',
  'SunPro',
  'Symlinks',
  'TAPR-OHL-1.0',
  'TCL',
  'TCP-wrappers',
  'TGPPL-1.0',
  'TMate',
  'TORQUE-1.1',
  'TOSL',
  'TPDL',
  'TPL-1.0',
  'TTWL',
  'TTYP0',
  'TU-Berlin-1.0',
  'TU-Berlin-2.0',
  'TermReadKey',
  'ThirdEye',
  'TrustedQSL',
  'UCAR',
  'UCL-1.0',
  'UMich-Merit',
  'UPL-1.0',
  'URT-RLE',
  'Ubuntu-font-1.0',
  'Unicode-3.0',
  'Unicode-DFS-2015',
  'Unicode-DFS-2016',
  'Unicode-TOU',
  'UnixCrypt',
  'Unlicense',
  'VOSTROM',
  'VSL-1.0',
  'Vim',
  'W3C',
  'W3C-19980720',
  'W3C-20150513',
  'WTFPL',
  'Watcom-1.0',
  'Widget-Workshop',
  'Wsuipa',
  'X11',
  'X11-distribute-modifications-variant',
  'X11-swapped',
  'XFree86-1.1',
  'XSkat',
  'Xdebug-1.03',
  'Xerox',
  'Xfig',
  'Xnet',
  'YPL-1.0',
  'YPL-1.1',
  'ZPL-1.1',
  'ZPL-2.0',
  'ZPL-2.1',
  'Zed',
  'Zeeff',
  'Zend-2.0',
  'Zimbra-1.3',
  'Zimbra-1.4',
  'Zlib',
  'any-OSI',
  'any-OSI-perl-modules',
  'bcrypt-Solar-Designer',
  'blessing',
  'bzip2-1.0.6',
  'check-cvs',
  'checkmk',
  'copyleft-next-0.3.0',
  'copyleft-next-0.3.1',
  'curl',
  'cve-tou',
  'diffmark',
  'dtoa',
  'dvipdfm',
  'eGenix',
  'etalab-2.0',
  'fwlw',
  'gSOAP-1.3b',
  'generic-xts',
  'gnuplot',
  'gtkbook',
  'hdparm',
  'iMatix',
  'libpng-2.0',
  'libselinux-1.0',
  'libtiff',
  'libutil-David-Nugent',
  'lsof',
  'magaz',
  'mailprio',
  'metamail',
  'mpi-permissive',
  'mpich2',
  'mplus',
  'pkgconf',
  'pnmstitch',
  'psfrag',
  'psutils',
  'python-ldap',
  'radvd',
  'snprintf',
  'softSurfer',
  'ssh-keyscan',
  'swrule',
  'threeparttable',
  'ulem',
  'w3m',
  'wwl',
  'xinetd',
  'xkeyboard-config-Zinoviev',
  'xlock',
  'xpp',
  'xzoom',
  'zlib-acknowledgement'
]

const require$$1 = [
  'AGPL-1.0',
  'AGPL-3.0',
  'BSD-2-Clause-FreeBSD',
  'BSD-2-Clause-NetBSD',
  'GFDL-1.1',
  'GFDL-1.2',
  'GFDL-1.3',
  'GPL-1.0',
  'GPL-2.0',
  'GPL-2.0-with-GCC-exception',
  'GPL-2.0-with-autoconf-exception',
  'GPL-2.0-with-bison-exception',
  'GPL-2.0-with-classpath-exception',
  'GPL-2.0-with-font-exception',
  'GPL-3.0',
  'GPL-3.0-with-GCC-exception',
  'GPL-3.0-with-autoconf-exception',
  'LGPL-2.0',
  'LGPL-2.1',
  'LGPL-3.0',
  'Net-SNMP',
  'Nunit',
  'StandardML-NJ',
  'bzip2-1.0.5',
  'eCos-2.0',
  'wxWindows'
]

const require$$2 = [
  '389-exception',
  'Asterisk-exception',
  'Autoconf-exception-2.0',
  'Autoconf-exception-3.0',
  'Autoconf-exception-generic',
  'Autoconf-exception-generic-3.0',
  'Autoconf-exception-macro',
  'Bison-exception-1.24',
  'Bison-exception-2.2',
  'Bootloader-exception',
  'Classpath-exception-2.0',
  'CLISP-exception-2.0',
  'cryptsetup-OpenSSL-exception',
  'DigiRule-FOSS-exception',
  'eCos-exception-2.0',
  'Fawkes-Runtime-exception',
  'FLTK-exception',
  'fmt-exception',
  'Font-exception-2.0',
  'freertos-exception-2.0',
  'GCC-exception-2.0',
  'GCC-exception-2.0-note',
  'GCC-exception-3.1',
  'Gmsh-exception',
  'GNAT-exception',
  'GNOME-examples-exception',
  'GNU-compiler-exception',
  'gnu-javamail-exception',
  'GPL-3.0-interface-exception',
  'GPL-3.0-linking-exception',
  'GPL-3.0-linking-source-exception',
  'GPL-CC-1.0',
  'GStreamer-exception-2005',
  'GStreamer-exception-2008',
  'i2p-gpl-java-exception',
  'KiCad-libraries-exception',
  'LGPL-3.0-linking-exception',
  'libpri-OpenH323-exception',
  'Libtool-exception',
  'Linux-syscall-note',
  'LLGPL',
  'LLVM-exception',
  'LZMA-exception',
  'mif-exception',
  'OCaml-LGPL-linking-exception',
  'OCCT-exception-1.0',
  'OpenJDK-assembly-exception-1.0',
  'openvpn-openssl-exception',
  'PS-or-PDF-font-exception-20170817',
  'QPL-1.0-INRIA-2004-exception',
  'Qt-GPL-exception-1.0',
  'Qt-LGPL-exception-1.1',
  'Qwt-exception-1.0',
  'SANE-exception',
  'SHL-2.0',
  'SHL-2.1',
  'stunnel-exception',
  'SWI-exception',
  'Swift-exception',
  'Texinfo-exception',
  'u-boot-exception-2.0',
  'UBDL-exception',
  'Universal-FOSS-exception-1.0',
  'vsftpd-openssl-exception',
  'WxWindows-exception-3.1',
  'x11vnc-openssl-exception'
]

let scan$1
let hasRequiredScan$1
function requireScan$1() {
  if (hasRequiredScan$1) {
    return scan$1
  }
  hasRequiredScan$1 = 1
  const licenses = [].concat(require$$1$1).concat(require$$1)
  const exceptions = require$$2
  scan$1 = function (source) {
    let index = 0
    function hasMore() {
      return index < source.length
    }

    // `value` can be a regexp or a string.
    // If it is recognized, the matching source string is returned and
    // the index is incremented. Otherwise `undefined` is returned.
    function read(value) {
      if (value instanceof RegExp) {
        const chars = source.slice(index)
        const match = chars.match(value)
        if (match) {
          index += match[0].length
          return match[0]
        }
      } else {
        if (source.indexOf(value, index) === index) {
          index += value.length
          return value
        }
      }
    }
    function skipWhitespace() {
      read(/[ ]*/)
    }
    function operator() {
      let string
      const possibilities = ['WITH', 'AND', 'OR', '(', ')', ':', '+']
      for (let i = 0; i < possibilities.length; i++) {
        string = read(possibilities[i])
        if (string) {
          break
        }
      }
      if (string === '+' && index > 1 && source[index - 2] === ' ') {
        throw new Error('Space before `+`')
      }
      return (
        string && {
          type: 'OPERATOR',
          string: string
        }
      )
    }
    function idstring() {
      return read(/[A-Za-z0-9-.]+/)
    }
    function expectIdstring() {
      const string = idstring()
      if (!string) {
        throw new Error('Expected idstring at offset ' + index)
      }
      return string
    }
    function documentRef() {
      if (read('DocumentRef-')) {
        const string = expectIdstring()
        return {
          type: 'DOCUMENTREF',
          string: string
        }
      }
    }
    function licenseRef() {
      if (read('LicenseRef-')) {
        const string = expectIdstring()
        return {
          type: 'LICENSEREF',
          string: string
        }
      }
    }
    function identifier() {
      const begin = index
      const string = idstring()
      if (licenses.indexOf(string) !== -1) {
        return {
          type: 'LICENSE',
          string: string
        }
      } else if (exceptions.indexOf(string) !== -1) {
        return {
          type: 'EXCEPTION',
          string: string
        }
      }
      index = begin
    }

    // Tries to read the next token. Returns `undefined` if no token is
    // recognized.
    function parseToken() {
      // Ordering matters
      return operator() || documentRef() || licenseRef() || identifier()
    }
    const tokens = []
    while (hasMore()) {
      skipWhitespace()
      if (!hasMore()) {
        break
      }
      const token = parseToken()
      if (!token) {
        throw new Error('Unexpected `' + source[index] + '` at offset ' + index)
      }
      tokens.push(token)
    }
    return tokens
  }
  return scan$1
}

let parse$1
let hasRequiredParse$1
function requireParse$1() {
  if (hasRequiredParse$1) {
    return parse$1
  }
  hasRequiredParse$1 = 1

  // The ABNF grammar in the spec is totally ambiguous.
  //
  // This parser follows the operator precedence defined in the
  // `Order of Precedence and Parentheses` section.

  parse$1 = function (tokens) {
    let index = 0
    function hasMore() {
      return index < tokens.length
    }
    function token() {
      return hasMore() ? tokens[index] : null
    }
    function next() {
      if (!hasMore()) {
        throw new Error()
      }
      index++
    }
    function parseOperator(operator) {
      const t = token()
      if (t && t.type === 'OPERATOR' && operator === t.string) {
        next()
        return t.string
      }
    }
    function parseWith() {
      if (parseOperator('WITH')) {
        const t = token()
        if (t && t.type === 'EXCEPTION') {
          next()
          return t.string
        }
        throw new Error('Expected exception after `WITH`')
      }
    }
    function parseLicenseRef() {
      // TODO: Actually, everything is concatenated into one string
      // for backward-compatibility but it could be better to return
      // a nice structure.
      const begin = index
      let string = ''
      let t = token()
      if (t.type === 'DOCUMENTREF') {
        next()
        string += 'DocumentRef-' + t.string + ':'
        if (!parseOperator(':')) {
          throw new Error('Expected `:` after `DocumentRef-...`')
        }
      }
      t = token()
      if (t.type === 'LICENSEREF') {
        next()
        string += 'LicenseRef-' + t.string
        return {
          license: string
        }
      }
      index = begin
    }
    function parseLicense() {
      const t = token()
      if (t && t.type === 'LICENSE') {
        next()
        const node = {
          license: t.string
        }
        if (parseOperator('+')) {
          node.plus = true
        }
        const exception = parseWith()
        if (exception) {
          node.exception = exception
        }
        return node
      }
    }
    function parseParenthesizedExpression() {
      const left = parseOperator('(')
      if (!left) {
        return
      }
      const expr = parseExpression()
      if (!parseOperator(')')) {
        throw new Error('Expected `)`')
      }
      return expr
    }
    function parseAtom() {
      return (
        parseParenthesizedExpression() || parseLicenseRef() || parseLicense()
      )
    }
    function makeBinaryOpParser(operator, nextParser) {
      return function parseBinaryOp() {
        const left = nextParser()
        if (!left) {
          return
        }
        if (!parseOperator(operator)) {
          return left
        }
        const right = parseBinaryOp()
        if (!right) {
          throw new Error('Expected expression')
        }
        return {
          left: left,
          conjunction: operator.toLowerCase(),
          right: right
        }
      }
    }
    const parseAnd = makeBinaryOpParser('AND', parseAtom)
    const parseExpression = makeBinaryOpParser('OR', parseAnd)
    const node = parseExpression()
    if (!node || hasMore()) {
      throw new Error('Syntax error')
    }
    return node
  }
  return parse$1
}

let spdxExpressionParse$1
let hasRequiredSpdxExpressionParse$1
function requireSpdxExpressionParse$1() {
  if (hasRequiredSpdxExpressionParse$1) {
    return spdxExpressionParse$1
  }
  hasRequiredSpdxExpressionParse$1 = 1
  const scan = requireScan$1()
  const parse = requireParse$1()
  spdxExpressionParse$1 = function (source) {
    return parse(scan(source))
  }
  return spdxExpressionParse$1
}

let scan
let hasRequiredScan
function requireScan() {
  if (hasRequiredScan) {
    return scan
  }
  hasRequiredScan = 1
  const licenses = [].concat(require$$1$1).concat(require$$1)
  const exceptions = require$$2
  scan = function (source) {
    let index = 0
    function hasMore() {
      return index < source.length
    }

    // `value` can be a regexp or a string.
    // If it is recognized, the matching source string is returned and
    // the index is incremented. Otherwise `undefined` is returned.
    function read(value) {
      if (value instanceof RegExp) {
        const chars = source.slice(index)
        const match = chars.match(value)
        if (match) {
          index += match[0].length
          return match[0]
        }
      } else {
        if (source.indexOf(value, index) === index) {
          index += value.length
          return value
        }
      }
    }
    function skipWhitespace() {
      read(/[ ]*/)
    }
    function operator() {
      let string
      const possibilities = ['WITH', 'AND', 'OR', '(', ')', ':', '+']
      for (let i = 0; i < possibilities.length; i++) {
        string = read(possibilities[i])
        if (string) {
          break
        }
      }
      if (string === '+' && index > 1 && source[index - 2] === ' ') {
        throw new Error('Space before `+`')
      }
      return (
        string && {
          type: 'OPERATOR',
          string: string
        }
      )
    }
    function idstring() {
      return read(/[A-Za-z0-9-.]+/)
    }
    function expectIdstring() {
      const string = idstring()
      if (!string) {
        throw new Error('Expected idstring at offset ' + index)
      }
      return string
    }
    function documentRef() {
      if (read('DocumentRef-')) {
        const string = expectIdstring()
        return {
          type: 'DOCUMENTREF',
          string: string
        }
      }
    }
    function licenseRef() {
      if (read('LicenseRef-')) {
        const string = expectIdstring()
        return {
          type: 'LICENSEREF',
          string: string
        }
      }
    }
    function identifier() {
      const begin = index
      const string = idstring()
      if (licenses.indexOf(string) !== -1) {
        return {
          type: 'LICENSE',
          string: string
        }
      } else if (exceptions.indexOf(string) !== -1) {
        return {
          type: 'EXCEPTION',
          string: string
        }
      }
      index = begin
    }

    // Tries to read the next token. Returns `undefined` if no token is
    // recognized.
    function parseToken() {
      // Ordering matters
      return operator() || documentRef() || licenseRef() || identifier()
    }
    const tokens = []
    while (hasMore()) {
      skipWhitespace()
      if (!hasMore()) {
        break
      }
      const token = parseToken()
      if (!token) {
        throw new Error('Unexpected `' + source[index] + '` at offset ' + index)
      }
      tokens.push(token)
    }
    return tokens
  }
  return scan
}

let parse
let hasRequiredParse
function requireParse() {
  if (hasRequiredParse) {
    return parse
  }
  hasRequiredParse = 1

  // The ABNF grammar in the spec is totally ambiguous.
  //
  // This parser follows the operator precedence defined in the
  // `Order of Precedence and Parentheses` section.

  parse = function (tokens) {
    let index = 0
    function hasMore() {
      return index < tokens.length
    }
    function token() {
      return hasMore() ? tokens[index] : null
    }
    function next() {
      if (!hasMore()) {
        throw new Error()
      }
      index++
    }
    function parseOperator(operator) {
      const t = token()
      if (t && t.type === 'OPERATOR' && operator === t.string) {
        next()
        return t.string
      }
    }
    function parseWith() {
      if (parseOperator('WITH')) {
        const t = token()
        if (t && t.type === 'EXCEPTION') {
          next()
          return t.string
        }
        throw new Error('Expected exception after `WITH`')
      }
    }
    function parseLicenseRef() {
      // TODO: Actually, everything is concatenated into one string
      // for backward-compatibility but it could be better to return
      // a nice structure.
      const begin = index
      let string = ''
      let t = token()
      if (t.type === 'DOCUMENTREF') {
        next()
        string += 'DocumentRef-' + t.string + ':'
        if (!parseOperator(':')) {
          throw new Error('Expected `:` after `DocumentRef-...`')
        }
      }
      t = token()
      if (t.type === 'LICENSEREF') {
        next()
        string += 'LicenseRef-' + t.string
        return {
          license: string
        }
      }
      index = begin
    }
    function parseLicense() {
      const t = token()
      if (t && t.type === 'LICENSE') {
        next()
        const node = {
          license: t.string
        }
        if (parseOperator('+')) {
          node.plus = true
        }
        const exception = parseWith()
        if (exception) {
          node.exception = exception
        }
        return node
      }
    }
    function parseParenthesizedExpression() {
      const left = parseOperator('(')
      if (!left) {
        return
      }
      const expr = parseExpression()
      if (!parseOperator(')')) {
        throw new Error('Expected `)`')
      }
      return expr
    }
    function parseAtom() {
      return (
        parseParenthesizedExpression() || parseLicenseRef() || parseLicense()
      )
    }
    function makeBinaryOpParser(operator, nextParser) {
      return function parseBinaryOp() {
        const left = nextParser()
        if (!left) {
          return
        }
        if (!parseOperator(operator)) {
          return left
        }
        const right = parseBinaryOp()
        if (!right) {
          throw new Error('Expected expression')
        }
        return {
          left: left,
          conjunction: operator.toLowerCase(),
          right: right
        }
      }
    }
    const parseAnd = makeBinaryOpParser('AND', parseAtom)
    const parseExpression = makeBinaryOpParser('OR', parseAnd)
    const node = parseExpression()
    if (!node || hasMore()) {
      throw new Error('Syntax error')
    }
    return node
  }
  return parse
}

let spdxExpressionParse
let hasRequiredSpdxExpressionParse
function requireSpdxExpressionParse() {
  if (hasRequiredSpdxExpressionParse) {
    return spdxExpressionParse
  }
  hasRequiredSpdxExpressionParse = 1
  const scan = requireScan()
  const parse = requireParse()
  spdxExpressionParse = function (source) {
    return parse(scan(source))
  }
  return spdxExpressionParse
}

/*
Copyright spdx-correct.js contributors

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/
let spdxCorrect
let hasRequiredSpdxCorrect
function requireSpdxCorrect() {
  if (hasRequiredSpdxCorrect) {
    return spdxCorrect
  }
  hasRequiredSpdxCorrect = 1
  const parse = requireSpdxExpressionParse()
  const spdxLicenseIds = require$$1$1
  function valid(string) {
    try {
      parse(string)
      return true
    } catch (error) {
      return false
    }
  }

  // Sorting function that orders the given array of transpositions such
  // that a transposition with the longer pattern comes before a transposition
  // with a shorter pattern. This is to prevent e.g. the transposition
  // ["General Public License", "GPL"] from matching to "Lesser General Public License"
  // before a longer and more accurate transposition ["Lesser General Public License", "LGPL"]
  // has a chance to be recognized.
  function sortTranspositions(a, b) {
    const length = b[0].length - a[0].length
    if (length !== 0) {
      return length
    }
    return a[0].toUpperCase().localeCompare(b[0].toUpperCase())
  }

  // Common transpositions of license identifier acronyms
  const transpositions = [
    ['APGL', 'AGPL'],
    ['Gpl', 'GPL'],
    ['GLP', 'GPL'],
    ['APL', 'Apache'],
    ['ISD', 'ISC'],
    ['GLP', 'GPL'],
    ['IST', 'ISC'],
    ['Claude', 'Clause'],
    [' or later', '+'],
    [' International', ''],
    ['GNU', 'GPL'],
    ['GUN', 'GPL'],
    ['+', ''],
    ['GNU GPL', 'GPL'],
    ['GNU LGPL', 'LGPL'],
    ['GNU/GPL', 'GPL'],
    ['GNU GLP', 'GPL'],
    ['GNU LESSER GENERAL PUBLIC LICENSE', 'LGPL'],
    ['GNU Lesser General Public License', 'LGPL'],
    ['GNU LESSER GENERAL PUBLIC LICENSE', 'LGPL-2.1'],
    ['GNU Lesser General Public License', 'LGPL-2.1'],
    ['LESSER GENERAL PUBLIC LICENSE', 'LGPL'],
    ['Lesser General Public License', 'LGPL'],
    ['LESSER GENERAL PUBLIC LICENSE', 'LGPL-2.1'],
    ['Lesser General Public License', 'LGPL-2.1'],
    ['GNU General Public License', 'GPL'],
    ['Gnu public license', 'GPL'],
    ['GNU Public License', 'GPL'],
    ['GNU GENERAL PUBLIC LICENSE', 'GPL'],
    ['MTI', 'MIT'],
    ['Mozilla Public License', 'MPL'],
    ['Universal Permissive License', 'UPL'],
    ['WTH', 'WTF'],
    ['WTFGPL', 'WTFPL'],
    ['-License', '']
  ].sort(sortTranspositions)
  const TRANSPOSED = 0
  const CORRECT = 1

  // Simple corrections to nearly valid identifiers.
  const transforms = [
    // e.g. 'mit'
    function (argument) {
      return argument.toUpperCase()
    },
    // e.g. 'MIT '
    function (argument) {
      return argument.trim()
    },
    // e.g. 'M.I.T.'
    function (argument) {
      return argument.replace(/\./g, '')
    },
    // e.g. 'Apache- 2.0'
    function (argument) {
      return argument.replace(/\s+/g, '')
    },
    // e.g. 'CC BY 4.0''
    function (argument) {
      return argument.replace(/\s+/g, '-')
    },
    // e.g. 'LGPLv2.1'
    function (argument) {
      return argument.replace('v', '-')
    },
    // e.g. 'Apache 2.0'
    function (argument) {
      return argument.replace(/,?\s*(\d)/, '-$1')
    },
    // e.g. 'GPL 2'
    function (argument) {
      return argument.replace(/,?\s*(\d)/, '-$1.0')
    },
    // e.g. 'Apache Version 2.0'
    function (argument) {
      return argument.replace(
        /,?\s*(V\.|v\.|V|v|Version|version)\s*(\d)/,
        '-$2'
      )
    },
    // e.g. 'Apache Version 2'
    function (argument) {
      return argument.replace(
        /,?\s*(V\.|v\.|V|v|Version|version)\s*(\d)/,
        '-$2.0'
      )
    },
    // e.g. 'ZLIB'
    function (argument) {
      return argument[0].toUpperCase() + argument.slice(1)
    },
    // e.g. 'MPL/2.0'
    function (argument) {
      return argument.replace('/', '-')
    },
    // e.g. 'Apache 2'
    function (argument) {
      return argument.replace(/\s*V\s*(\d)/, '-$1').replace(/(\d)$/, '$1.0')
    },
    // e.g. 'GPL-2.0', 'GPL-3.0'
    function (argument) {
      if (argument.indexOf('3.0') !== -1) {
        return argument + '-or-later'
      } else {
        return argument + '-only'
      }
    },
    // e.g. 'GPL-2.0-'
    function (argument) {
      return argument + 'only'
    },
    // e.g. 'GPL2'
    function (argument) {
      return argument.replace(/(\d)$/, '-$1.0')
    },
    // e.g. 'BSD 3'
    function (argument) {
      return argument.replace(/(-| )?(\d)$/, '-$2-Clause')
    },
    // e.g. 'BSD clause 3'
    function (argument) {
      return argument.replace(/(-| )clause(-| )(\d)/, '-$3-Clause')
    },
    // e.g. 'New BSD license'
    function (argument) {
      return argument.replace(
        /\b(Modified|New|Revised)(-| )?BSD((-| )License)?/i,
        'BSD-3-Clause'
      )
    },
    // e.g. 'Simplified BSD license'
    function (argument) {
      return argument.replace(
        /\bSimplified(-| )?BSD((-| )License)?/i,
        'BSD-2-Clause'
      )
    },
    // e.g. 'Free BSD license'
    function (argument) {
      return argument.replace(
        /\b(Free|Net)(-| )?BSD((-| )License)?/i,
        'BSD-2-Clause-$1BSD'
      )
    },
    // e.g. 'Clear BSD license'
    function (argument) {
      return argument.replace(
        /\bClear(-| )?BSD((-| )License)?/i,
        'BSD-3-Clause-Clear'
      )
    },
    // e.g. 'Old BSD License'
    function (argument) {
      return argument.replace(
        /\b(Old|Original)(-| )?BSD((-| )License)?/i,
        'BSD-4-Clause'
      )
    },
    // e.g. 'BY-NC-4.0'
    function (argument) {
      return 'CC-' + argument
    },
    // e.g. 'BY-NC'
    function (argument) {
      return 'CC-' + argument + '-4.0'
    },
    // e.g. 'Attribution-NonCommercial'
    function (argument) {
      return argument
        .replace('Attribution', 'BY')
        .replace('NonCommercial', 'NC')
        .replace('NoDerivatives', 'ND')
        .replace(/ (\d)/, '-$1')
        .replace(/ ?International/, '')
    },
    // e.g. 'Attribution-NonCommercial'
    function (argument) {
      return (
        'CC-' +
        argument
          .replace('Attribution', 'BY')
          .replace('NonCommercial', 'NC')
          .replace('NoDerivatives', 'ND')
          .replace(/ (\d)/, '-$1')
          .replace(/ ?International/, '') +
        '-4.0'
      )
    }
  ]
  let licensesWithVersions = spdxLicenseIds
    .map(function (id) {
      const match = /^(.*)-\d+\.\d+$/.exec(id)
      return match ? [match[0], match[1]] : [id, null]
    })
    .reduce(function (objectMap, item) {
      const key = item[1]
      objectMap[key] = objectMap[key] || []
      objectMap[key].push(item[0])
      return objectMap
    }, {})
  const licensesWithOneVersion = Object.keys(licensesWithVersions)
    .map(function makeEntries(key) {
      return [key, licensesWithVersions[key]]
    })
    .filter(function identifySoleVersions(item) {
      return (
        // Licenses has just one valid version suffix.
        item[1].length === 1 &&
        item[0] !== null &&
        // APL will be considered Apache, rather than APL-1.0
        item[0] !== 'APL'
      )
    })
    .map(function createLastResorts(item) {
      return [item[0], item[1][0]]
    })
  licensesWithVersions = undefined

  // If all else fails, guess that strings containing certain substrings
  // meant to identify certain licenses.
  const lastResorts = [
    ['UNLI', 'Unlicense'],
    ['WTF', 'WTFPL'],
    ['2 CLAUSE', 'BSD-2-Clause'],
    ['2-CLAUSE', 'BSD-2-Clause'],
    ['3 CLAUSE', 'BSD-3-Clause'],
    ['3-CLAUSE', 'BSD-3-Clause'],
    ['AFFERO', 'AGPL-3.0-or-later'],
    ['AGPL', 'AGPL-3.0-or-later'],
    ['APACHE', 'Apache-2.0'],
    ['ARTISTIC', 'Artistic-2.0'],
    ['Affero', 'AGPL-3.0-or-later'],
    ['BEER', 'Beerware'],
    ['BOOST', 'BSL-1.0'],
    ['BSD', 'BSD-2-Clause'],
    ['CDDL', 'CDDL-1.1'],
    ['ECLIPSE', 'EPL-1.0'],
    ['FUCK', 'WTFPL'],
    ['GNU', 'GPL-3.0-or-later'],
    ['LGPL', 'LGPL-3.0-or-later'],
    ['GPLV1', 'GPL-1.0-only'],
    ['GPL-1', 'GPL-1.0-only'],
    ['GPLV2', 'GPL-2.0-only'],
    ['GPL-2', 'GPL-2.0-only'],
    ['GPL', 'GPL-3.0-or-later'],
    ['MIT +NO-FALSE-ATTRIBS', 'MITNFA'],
    ['MIT', 'MIT'],
    ['MPL', 'MPL-2.0'],
    ['X11', 'X11'],
    ['ZLIB', 'Zlib']
  ]
    .concat(licensesWithOneVersion)
    .sort(sortTranspositions)
  const SUBSTRING = 0
  const IDENTIFIER = 1
  const validTransformation = function (identifier) {
    for (let i = 0; i < transforms.length; i++) {
      const transformed = transforms[i](identifier).trim()
      if (transformed !== identifier && valid(transformed)) {
        return transformed
      }
    }
    return null
  }
  const validLastResort = function (identifier) {
    const upperCased = identifier.toUpperCase()
    for (let i = 0; i < lastResorts.length; i++) {
      const lastResort = lastResorts[i]
      if (upperCased.indexOf(lastResort[SUBSTRING]) > -1) {
        return lastResort[IDENTIFIER]
      }
    }
    return null
  }
  const anyCorrection = function (identifier, check) {
    for (let i = 0; i < transpositions.length; i++) {
      const transposition = transpositions[i]
      const transposed = transposition[TRANSPOSED]
      if (identifier.indexOf(transposed) > -1) {
        const corrected = identifier.replace(transposed, transposition[CORRECT])
        const checked = check(corrected)
        if (checked !== null) {
          return checked
        }
      }
    }
    return null
  }
  spdxCorrect = function (identifier, options) {
    options = options || {}
    const upgrade = options.upgrade === undefined ? true : !!options.upgrade
    function postprocess(value) {
      return upgrade ? upgradeGPLs(value) : value
    }
    const validArugment =
      typeof identifier === 'string' && identifier.trim().length !== 0
    if (!validArugment) {
      throw Error('Invalid argument. Expected non-empty string.')
    }
    identifier = identifier.trim()
    if (valid(identifier)) {
      return postprocess(identifier)
    }
    const noPlus = identifier.replace(/\+$/, '').trim()
    if (valid(noPlus)) {
      return postprocess(noPlus)
    }
    let transformed = validTransformation(identifier)
    if (transformed !== null) {
      return postprocess(transformed)
    }
    transformed = anyCorrection(identifier, function (argument) {
      if (valid(argument)) {
        return argument
      }
      return validTransformation(argument)
    })
    if (transformed !== null) {
      return postprocess(transformed)
    }
    transformed = validLastResort(identifier)
    if (transformed !== null) {
      return postprocess(transformed)
    }
    transformed = anyCorrection(identifier, validLastResort)
    if (transformed !== null) {
      return postprocess(transformed)
    }
    return null
  }
  function upgradeGPLs(value) {
    if (
      [
        'GPL-1.0',
        'LGPL-1.0',
        'AGPL-1.0',
        'GPL-2.0',
        'LGPL-2.0',
        'AGPL-2.0',
        'LGPL-2.1'
      ].indexOf(value) !== -1
    ) {
      return value + '-only'
    } else if (
      [
        'GPL-1.0+',
        'GPL-2.0+',
        'GPL-3.0+',
        'LGPL-2.0+',
        'LGPL-2.1+',
        'LGPL-3.0+',
        'AGPL-1.0+',
        'AGPL-3.0+'
      ].indexOf(value) !== -1
    ) {
      return value.replace(/\+$/, '-or-later')
    } else if (['GPL-3.0', 'LGPL-3.0', 'AGPL-3.0'].indexOf(value) !== -1) {
      return value + '-or-later'
    } else {
      return value
    }
  }
  return spdxCorrect
}

let validateNpmPackageLicense
let hasRequiredValidateNpmPackageLicense
function requireValidateNpmPackageLicense() {
  if (hasRequiredValidateNpmPackageLicense) {
    return validateNpmPackageLicense
  }
  hasRequiredValidateNpmPackageLicense = 1
  const parse = requireSpdxExpressionParse$1()
  const correct = requireSpdxCorrect()
  const genericWarning =
    'license should be ' +
    'a valid SPDX license expression (without "LicenseRef"), ' +
    '"UNLICENSED", or ' +
    '"SEE LICENSE IN <filename>"'
  const fileReferenceRE = /^SEE LICEN[CS]E IN (.+)$/
  function startsWith(prefix, string) {
    return string.slice(0, prefix.length) === prefix
  }
  function usesLicenseRef(ast) {
    if (ast.hasOwnProperty('license')) {
      const license = ast.license
      return (
        startsWith('LicenseRef', license) || startsWith('DocumentRef', license)
      )
    } else {
      return usesLicenseRef(ast.left) || usesLicenseRef(ast.right)
    }
  }
  validateNpmPackageLicense = function (argument) {
    let ast
    try {
      ast = parse(argument)
    } catch (e) {
      let match
      if (argument === 'UNLICENSED' || argument === 'UNLICENCED') {
        return {
          validForOldPackages: true,
          validForNewPackages: true,
          unlicensed: true
        }
      } else if ((match = fileReferenceRE.exec(argument))) {
        return {
          validForOldPackages: true,
          validForNewPackages: true,
          inFile: match[1]
        }
      } else {
        const result = {
          validForOldPackages: false,
          validForNewPackages: false,
          warnings: [genericWarning]
        }
        if (argument.trim().length !== 0) {
          const corrected = correct(argument)
          if (corrected) {
            result.warnings.push(
              'license is similar to the valid expression "' + corrected + '"'
            )
          }
        }
        return result
      }
    }
    if (usesLicenseRef(ast)) {
      return {
        validForNewPackages: false,
        validForOldPackages: false,
        spdx: true,
        warnings: [genericWarning]
      }
    } else {
      return {
        validForNewPackages: true,
        validForOldPackages: true,
        spdx: true
      }
    }
  }
  return validateNpmPackageLicense
}

let normalizeData_1
let hasRequiredNormalizeData
function requireNormalizeData() {
  if (hasRequiredNormalizeData) {
    return normalizeData_1
  }
  hasRequiredNormalizeData = 1
  const hostedGitInfo = requireLib$8()
  const validateLicense = requireValidateNpmPackageLicense()
  const typos = {
    dependancies: 'dependencies',
    dependecies: 'dependencies',
    depdenencies: 'dependencies',
    devEependencies: 'devDependencies',
    depends: 'dependencies',
    'dev-dependencies': 'devDependencies',
    devDependences: 'devDependencies',
    devDepenencies: 'devDependencies',
    devdependencies: 'devDependencies',
    repostitory: 'repository',
    repo: 'repository',
    prefereGlobal: 'preferGlobal',
    hompage: 'homepage',
    hampage: 'homepage',
    autohr: 'author',
    autor: 'author',
    contributers: 'contributors',
    publicationConfig: 'publishConfig',
    script: 'scripts'
  }
  const isEmail = str =>
    str.includes('@') && str.indexOf('@') < str.lastIndexOf('.')

  // Extracts description from contents of a readme file in markdown format
  function extractDescription(description) {
    // the first block of text before the first heading that isn't the first line heading
    const lines = description.trim().split('\n')
    let start = 0
    // skip initial empty lines and lines that start with #
    while (lines[start]?.trim().match(/^(#|$)/)) {
      start++
    }
    let end = start + 1
    // keep going till we get to the end or an empty line
    while (end < lines.length && lines[end].trim()) {
      end++
    }
    return lines.slice(start, end).join(' ').trim()
  }
  function stringifyPerson(person) {
    if (typeof person !== 'string') {
      const name = person.name || ''
      const u = person.url || person.web
      const wrappedUrl = u ? ' (' + u + ')' : ''
      const e = person.email || person.mail
      const wrappedEmail = e ? ' <' + e + '>' : ''
      person = name + wrappedEmail + wrappedUrl
    }
    const matchedName = person.match(/^([^(<]+)/)
    const matchedUrl = person.match(/\(([^()]+)\)/)
    const matchedEmail = person.match(/<([^<>]+)>/)
    const parsed = {}
    if (matchedName?.[0].trim()) {
      parsed.name = matchedName[0].trim()
    }
    if (matchedEmail) {
      parsed.email = matchedEmail[1]
    }
    if (matchedUrl) {
      parsed.url = matchedUrl[1]
    }
    return parsed
  }
  function normalizeData(data, changes) {
    // fixDescriptionField
    if (data.description && typeof data.description !== 'string') {
      changes?.push(`'description' field should be a string`)
      delete data.description
    }
    if (
      data.readme &&
      !data.description &&
      data.readme !== 'ERROR: No README data found!'
    ) {
      data.description = extractDescription(data.readme)
    }
    if (data.description === undefined) {
      delete data.description
    }
    if (!data.description) {
      changes?.push('No description')
    }

    // fixModulesField
    if (data.modules) {
      changes?.push(`modules field is deprecated`)
      delete data.modules
    }

    // fixFilesField
    const files = data.files
    if (files && !Array.isArray(files)) {
      changes?.push(`Invalid 'files' member`)
      delete data.files
    } else if (data.files) {
      data.files = data.files.filter(function (file) {
        if (!file || typeof file !== 'string') {
          changes?.push(`Invalid filename in 'files' list: ${file}`)
          return false
        } else {
          return true
        }
      })
    }

    // fixManField
    if (data.man && typeof data.man === 'string') {
      data.man = [data.man]
    }

    // fixBugsField
    if (!data.bugs && data.repository?.url) {
      const hosted = hostedGitInfo.fromUrl(data.repository.url)
      if (hosted && hosted.bugs()) {
        data.bugs = {
          url: hosted.bugs()
        }
      }
    } else if (data.bugs) {
      if (typeof data.bugs === 'string') {
        if (isEmail(data.bugs)) {
          data.bugs = {
            email: data.bugs
          }
          /* eslint-disable-next-line node/no-deprecated-api */
        } else if (new URL(data.bugs).protocol) {
          data.bugs = {
            url: data.bugs
          }
        } else {
          changes?.push(`Bug string field must be url, email, or {email,url}`)
        }
      } else {
        for (const k in data.bugs) {
          if (['web', 'name'].includes(k)) {
            changes?.push(`bugs['${k}'] should probably be bugs['url'].`)
            data.bugs.url = data.bugs[k]
            delete data.bugs[k]
          }
        }
        const oldBugs = data.bugs
        data.bugs = {}
        if (oldBugs.url) {
          /* eslint-disable-next-line node/no-deprecated-api */
          if (
            typeof oldBugs.url === 'string' &&
            new URL(oldBugs.url).protocol
          ) {
            data.bugs.url = oldBugs.url
          } else {
            changes?.push('bugs.url field must be a string url. Deleted.')
          }
        }
        if (oldBugs.email) {
          if (typeof oldBugs.email === 'string' && isEmail(oldBugs.email)) {
            data.bugs.email = oldBugs.email
          } else {
            changes?.push('bugs.email field must be a string email. Deleted.')
          }
        }
      }
      if (!data.bugs.email && !data.bugs.url) {
        delete data.bugs
        changes?.push(
          'Normalized value of bugs field is an empty object. Deleted.'
        )
      }
    }
    // fixKeywordsField
    if (typeof data.keywords === 'string') {
      data.keywords = data.keywords.split(/,\s+/)
    }
    if (data.keywords && !Array.isArray(data.keywords)) {
      delete data.keywords
      changes?.push(`keywords should be an array of strings`)
    } else if (data.keywords) {
      data.keywords = data.keywords.filter(function (kw) {
        if (typeof kw !== 'string' || !kw) {
          changes?.push(`keywords should be an array of strings`)
          return false
        } else {
          return true
        }
      })
    }
    // fixBundleDependenciesField
    const bdd = 'bundledDependencies'
    const bd = 'bundleDependencies'
    if (data[bdd] && !data[bd]) {
      data[bd] = data[bdd]
      delete data[bdd]
    }
    if (data[bd] && !Array.isArray(data[bd])) {
      changes?.push(
        `Invalid 'bundleDependencies' list. Must be array of package names`
      )
      delete data[bd]
    } else if (data[bd]) {
      data[bd] = data[bd].filter(function (filtered) {
        if (!filtered || typeof filtered !== 'string') {
          changes?.push(`Invalid bundleDependencies member: ${filtered}`)
          return false
        } else {
          if (!data.dependencies) {
            data.dependencies = {}
          }
          if (
            !Object.prototype.hasOwnProperty.call(data.dependencies, filtered)
          ) {
            changes?.push(`Non-dependency in bundleDependencies: ${filtered}`)
            data.dependencies[filtered] = '*'
          }
          return true
        }
      })
    }
    // fixHomepageField
    if (!data.homepage && data.repository && data.repository.url) {
      const hosted = hostedGitInfo.fromUrl(data.repository.url)
      if (hosted) {
        data.homepage = hosted.docs()
      }
    }
    if (data.homepage) {
      if (typeof data.homepage !== 'string') {
        changes?.push('homepage field must be a string url. Deleted.')
        delete data.homepage
      } else {
        /* eslint-disable-next-line node/no-deprecated-api */
        if (!new URL(data.homepage).protocol) {
          data.homepage = 'http://' + data.homepage
        }
      }
    }
    // fixReadmeField
    if (!data.readme) {
      changes?.push('No README data')
      data.readme = 'ERROR: No README data found!'
    }
    // fixLicenseField
    const license = data.license || data.licence
    if (!license) {
      changes?.push('No license field.')
    } else if (
      typeof license !== 'string' ||
      license.length < 1 ||
      license.trim() === ''
    ) {
      changes?.push('license should be a valid SPDX license expression')
    } else if (!validateLicense(license).validForNewPackages) {
      changes?.push('license should be a valid SPDX license expression')
    }
    // fixPeople
    if (data.author) {
      data.author = stringifyPerson(data.author)
    }
    ;['maintainers', 'contributors'].forEach(function (set) {
      if (!Array.isArray(data[set])) {
        return
      }
      data[set] = data[set].map(stringifyPerson)
    })
    // fixTypos
    for (const d in typos) {
      if (Object.prototype.hasOwnProperty.call(data, d)) {
        changes?.push(`${d} should probably be ${typos[d]}.`)
      }
    }
  }
  normalizeData_1 = {
    normalizeData
  }
  return normalizeData_1
}

let normalize_1
let hasRequiredNormalize
function requireNormalize() {
  if (hasRequiredNormalize) {
    return normalize_1
  }
  hasRequiredNormalize = 1
  const valid = requireValid$1()
  const clean = requireClean()
  const fs = require$$5
  const path = require$$2$2
  const { log } = requireLib$9()
  const moduleBuiltin = require$$5$1

  /**
   * @type {import('hosted-git-info')}
   */
  let _hostedGitInfo
  function lazyHostedGitInfo() {
    if (!_hostedGitInfo) {
      _hostedGitInfo = requireLib$8()
    }
    return _hostedGitInfo
  }

  /**
   * @type {import('glob').glob}
   */
  let _glob
  function lazyLoadGlob() {
    if (!_glob) {
      _glob = requireCommonjs().glob
    }
    return _glob
  }

  // used to be npm-normalize-package-bin
  function normalizePackageBin(pkg, changes) {
    if (pkg.bin) {
      if (typeof pkg.bin === 'string' && pkg.name) {
        changes?.push('"bin" was converted to an object')
        pkg.bin = {
          [pkg.name]: pkg.bin
        }
      } else if (Array.isArray(pkg.bin)) {
        changes?.push('"bin" was converted to an object')
        pkg.bin = pkg.bin.reduce((acc, k) => {
          acc[path.basename(k)] = k
          return acc
        }, {})
      }
      if (typeof pkg.bin === 'object') {
        for (const binKey in pkg.bin) {
          if (typeof pkg.bin[binKey] !== 'string') {
            delete pkg.bin[binKey]
            changes?.push(`removed invalid "bin[${binKey}]"`)
            continue
          }
          const base = path.basename(secureAndUnixifyPath(binKey))
          if (!base) {
            delete pkg.bin[binKey]
            changes?.push(`removed invalid "bin[${binKey}]"`)
            continue
          }
          const binTarget = secureAndUnixifyPath(pkg.bin[binKey])
          if (!binTarget) {
            delete pkg.bin[binKey]
            changes?.push(`removed invalid "bin[${binKey}]"`)
            continue
          }
          if (base !== binKey) {
            delete pkg.bin[binKey]
            changes?.push(`"bin[${binKey}]" was renamed to "bin[${base}]"`)
          }
          if (binTarget !== pkg.bin[binKey]) {
            changes?.push(`"bin[${base}]" script name was cleaned`)
          }
          pkg.bin[base] = binTarget
        }
        if (Object.keys(pkg.bin).length === 0) {
          changes?.push('empty "bin" was removed')
          delete pkg.bin
        }
        return pkg
      }
    }
    delete pkg.bin
  }
  function normalizePackageMan(pkg, changes) {
    if (pkg.man) {
      const mans = []
      for (const man of Array.isArray(pkg.man) ? pkg.man : [pkg.man]) {
        if (typeof man !== 'string') {
          changes?.push(`removed invalid "man [${man}]"`)
        } else {
          mans.push(secureAndUnixifyPath(man))
        }
      }
      if (!mans.length) {
        changes?.push('empty "man" was removed')
      } else {
        pkg.man = mans
        return pkg
      }
    }
    delete pkg.man
  }
  function isCorrectlyEncodedName(spec) {
    return !spec.match(/[/@\s+%:]/) && spec === encodeURIComponent(spec)
  }
  function isValidScopedPackageName(spec) {
    if (spec.charAt(0) !== '@') {
      return false
    }
    const rest = spec.slice(1).split('/')
    if (rest.length !== 2) {
      return false
    }
    return (
      rest[0] &&
      rest[1] &&
      rest[0] === encodeURIComponent(rest[0]) &&
      rest[1] === encodeURIComponent(rest[1])
    )
  }
  function unixifyPath(ref) {
    return ref.replace(/\\|:/g, '/')
  }
  function secureAndUnixifyPath(ref) {
    const secured = unixifyPath(
      path.join('.', path.join('/', unixifyPath(ref)))
    )
    return secured.startsWith('./') ? '' : secured
  }

  // We don't want the `changes` array in here by default because this is a hot
  // path for parsing packuments during install.  So the calling method passes it
  // in if it wants to track changes.
  const normalize = async (
    pkg,
    { strict, steps, root, changes, allowLegacyCase }
  ) => {
    if (!pkg.content) {
      throw new Error('Can not normalize without content')
    }
    const data = pkg.content
    const scripts = data.scripts || {}
    const pkgId = `${data.name ?? ''}@${data.version ?? ''}`

    // name and version are load bearing so we have to clean them up first
    if (
      steps.includes('fixName') ||
      steps.includes('fixNameField') ||
      steps.includes('normalizeData')
    ) {
      if (!data.name && !strict) {
        changes?.push('Missing "name" field was set to an empty string')
        data.name = ''
      } else {
        if (typeof data.name !== 'string') {
          throw new Error('name field must be a string.')
        }
        if (!strict) {
          const name = data.name.trim()
          if (data.name !== name) {
            changes?.push(`Whitespace was trimmed from "name"`)
            data.name = name
          }
        }
        if (
          data.name.startsWith('.') ||
          !(
            isValidScopedPackageName(data.name) ||
            isCorrectlyEncodedName(data.name)
          ) ||
          (strict &&
            !allowLegacyCase &&
            data.name !== data.name.toLowerCase()) ||
          data.name.toLowerCase() === 'node_modules' ||
          data.name.toLowerCase() === 'favicon.ico'
        ) {
          throw new Error('Invalid name: ' + JSON.stringify(data.name))
        }
      }
    }
    if (steps.includes('fixName')) {
      // Check for conflicts with builtin modules
      if (moduleBuiltin.builtinModules.includes(data.name)) {
        log.warn(
          'package-json',
          pkgId,
          `Package name "${data.name}" conflicts with a Node.js built-in module name`
        )
      }
    }
    if (steps.includes('fixVersionField') || steps.includes('normalizeData')) {
      // allow "loose" semver 1.0 versions in non-strict mode
      // enforce strict semver 2.0 compliance in strict mode
      const loose = !strict
      if (!data.version) {
        data.version = ''
      } else {
        if (!valid(data.version, loose)) {
          throw new Error(`Invalid version: "${data.version}"`)
        }
        const version = clean(data.version, loose)
        if (version !== data.version) {
          changes?.push(`"version" was cleaned and set to "${version}"`)
          data.version = version
        }
      }
    }
    // remove attributes that start with "_"
    if (steps.includes('_attributes')) {
      for (const key in data) {
        if (key.startsWith('_')) {
          changes?.push(`"${key}" was removed`)
          delete pkg.content[key]
        }
      }
    }

    // build the "_id" attribute
    if (steps.includes('_id')) {
      if (data.name && data.version) {
        changes?.push(`"_id" was set to ${pkgId}`)
        data._id = pkgId
      }
    }

    // fix bundledDependencies typo
    // normalize bundleDependencies
    if (steps.includes('bundledDependencies')) {
      if (
        data.bundleDependencies === undefined &&
        data.bundledDependencies !== undefined
      ) {
        data.bundleDependencies = data.bundledDependencies
      }
      changes?.push(`Deleted incorrect "bundledDependencies"`)
      delete data.bundledDependencies
    }
    // expand "bundleDependencies: true or translate from object"
    if (steps.includes('bundleDependencies')) {
      const bd = data.bundleDependencies
      if (bd === false && !steps.includes('bundleDependenciesDeleteFalse')) {
        changes?.push(`"bundleDependencies" was changed from "false" to "[]"`)
        data.bundleDependencies = []
      } else if (bd === true) {
        changes?.push(
          `"bundleDependencies" was auto-populated from "dependencies"`
        )
        data.bundleDependencies = Object.keys(data.dependencies || {})
      } else if (bd && typeof bd === 'object') {
        if (!Array.isArray(bd)) {
          changes?.push(
            `"bundleDependencies" was changed from an object to an array`
          )
          data.bundleDependencies = Object.keys(bd)
        }
      } else if ('bundleDependencies' in data) {
        changes?.push(`"bundleDependencies" was removed`)
        delete data.bundleDependencies
      }
    }

    // it was once common practice to list deps both in optionalDependencies and
    // in dependencies, to support npm versions that did not know about
    // optionalDependencies.  This is no longer a relevant need, so duplicating
    // the deps in two places is unnecessary and excessive.
    if (steps.includes('optionalDedupe')) {
      if (
        data.dependencies &&
        data.optionalDependencies &&
        typeof data.optionalDependencies === 'object'
      ) {
        for (const name in data.optionalDependencies) {
          changes?.push(`optionalDependencies."${name}" was removed`)
          delete data.dependencies[name]
        }
        if (!Object.keys(data.dependencies).length) {
          changes?.push(`Empty "optionalDependencies" was removed`)
          delete data.dependencies
        }
      }
    }

    // add "install" attribute if any "*.gyp" files exist
    if (steps.includes('gypfile')) {
      if (!scripts.install && !scripts.preinstall && data.gypfile !== false) {
        const files = await lazyLoadGlob()('*.gyp', {
          cwd: pkg.path
        })
        if (files.length) {
          scripts.install = 'node-gyp rebuild'
          data.scripts = scripts
          data.gypfile = true
          changes?.push(`"scripts.install" was set to "node-gyp rebuild"`)
          changes?.push(`"gypfile" was set to "true"`)
        }
      }
    }

    // add "start" attribute if "server.js" exists
    if (steps.includes('serverjs') && !scripts.start) {
      try {
        await fs.access(path.join(pkg.path, 'server.js'))
        scripts.start = 'node server.js'
        data.scripts = scripts
        changes?.push('"scripts.start" was set to "node server.js"')
      } catch {
        // do nothing
      }
    }

    // strip "node_modules/.bin" from scripts entries
    // remove invalid scripts entries (non-strings)
    if (
      (steps.includes('scripts') || steps.includes('scriptpath')) &&
      data.scripts !== undefined
    ) {
      const spre = /^(\.[/\\])?node_modules[/\\].bin[\\/]/
      if (typeof data.scripts === 'object') {
        for (const name in data.scripts) {
          if (typeof data.scripts[name] !== 'string') {
            delete data.scripts[name]
            changes?.push(`Invalid scripts."${name}" was removed`)
          } else if (
            steps.includes('scriptpath') &&
            spre.test(data.scripts[name])
          ) {
            data.scripts[name] = data.scripts[name].replace(spre, '')
            changes?.push(
              `scripts entry "${name}" was fixed to remove node_modules/.bin reference`
            )
          }
        }
      } else {
        changes?.push(`Removed invalid "scripts"`)
        delete data.scripts
      }
    }
    if (steps.includes('funding')) {
      if (data.funding && typeof data.funding === 'string') {
        data.funding = {
          url: data.funding
        }
        changes?.push(`"funding" was changed to an object with a url attribute`)
      }
    }

    // populate "authors" attribute
    if (steps.includes('authors') && !data.contributors) {
      try {
        const authorData = await fs.readFile(
          path.join(pkg.path, 'AUTHORS'),
          'utf8'
        )
        const authors = authorData
          .split(/\r?\n/g)
          .map(line => line.replace(/^\s*#.*$/, '').trim())
          .filter(line => line)
        data.contributors = authors
        changes?.push(
          '"contributors" was auto-populated with the contents of the "AUTHORS" file'
        )
      } catch {
        // do nothing
      }
    }

    // populate "readme" attribute
    if (steps.includes('readme') && !data.readme) {
      const mdre = /\.m?a?r?k?d?o?w?n?$/i
      const files = await lazyLoadGlob()('{README,README.*}', {
        cwd: pkg.path,
        nocase: true,
        mark: true
      })
      let readmeFile
      for (const file of files) {
        // don't accept directories.
        if (!file.endsWith(path.sep)) {
          if (file.match(mdre)) {
            readmeFile = file
            break
          }
          if (file.endsWith('README')) {
            readmeFile = file
          }
        }
      }
      if (readmeFile) {
        const readmeData = await fs.readFile(
          path.join(pkg.path, readmeFile),
          'utf8'
        )
        data.readme = readmeData
        data.readmeFilename = readmeFile
        changes?.push(`"readme" was set to the contents of ${readmeFile}`)
        changes?.push(`"readmeFilename" was set to ${readmeFile}`)
      }
      if (!data.readme) {
        data.readme = 'ERROR: No README data found!'
      }
    }

    // expand directories.man
    if (steps.includes('mans')) {
      if (data.directories?.man && !data.man) {
        const manDir = secureAndUnixifyPath(data.directories.man)
        const cwd = path.resolve(pkg.path, manDir)
        const files = await lazyLoadGlob()('**/*.[0-9]', {
          cwd
        })
        data.man = files.map(man =>
          path.relative(pkg.path, path.join(cwd, man)).split(path.sep).join('/')
        )
      }
      normalizePackageMan(data, changes)
    }
    if (
      steps.includes('bin') ||
      steps.includes('binDir') ||
      steps.includes('binRefs')
    ) {
      normalizePackageBin(data, changes)
    }

    // expand "directories.bin"
    if (steps.includes('binDir') && data.directories?.bin && !data.bin) {
      const binsDir = path.resolve(
        pkg.path,
        secureAndUnixifyPath(data.directories.bin)
      )
      const bins = await lazyLoadGlob()('**', {
        cwd: binsDir
      })
      data.bin = bins.reduce((acc, binFile) => {
        if (binFile && !binFile.startsWith('.')) {
          const binName = path.basename(binFile)
          acc[binName] = path.join(data.directories.bin, binFile)
        }
        return acc
      }, {})
      // *sigh*
      normalizePackageBin(data, changes)
    }

    // populate "gitHead" attribute
    if (steps.includes('gitHead') && !data.gitHead) {
      const git = requireLib$1()
      const gitRoot = await git.find({
        cwd: pkg.path,
        root
      })
      let head
      if (gitRoot) {
        try {
          head = await fs.readFile(path.resolve(gitRoot, '.git/HEAD'), 'utf8')
        } catch (err) {
          // do nothing
        }
      }
      let headData
      if (head) {
        if (head.startsWith('ref: ')) {
          const headRef = head.replace(/^ref: /, '').trim()
          const headFile = path.resolve(gitRoot, '.git', headRef)
          try {
            headData = await fs.readFile(headFile, 'utf8')
            headData = headData.replace(/^ref: /, '').trim()
          } catch (err) {
            // do nothing
          }
          if (!headData) {
            const packFile = path.resolve(gitRoot, '.git/packed-refs')
            try {
              let refs = await fs.readFile(packFile, 'utf8')
              if (refs) {
                refs = refs.split('\n')
                for (let i = 0; i < refs.length; i++) {
                  const match = refs[i].match(/^([0-9a-f]{40}) (.+)$/)
                  if (match && match[2].trim() === headRef) {
                    headData = match[1]
                    break
                  }
                }
              }
            } catch {
              // do nothing
            }
          }
        } else {
          headData = head.trim()
        }
      }
      if (headData) {
        data.gitHead = headData
      }
    }

    // populate "types" attribute
    if (steps.includes('fillTypes')) {
      const index = data.main || 'index.js'
      if (typeof index !== 'string') {
        throw new TypeError('The "main" attribute must be of type string.')
      }

      // TODO exports is much more complicated than this in verbose format
      // We need to support for instance

      // "exports": {
      //   ".": [
      //     {
      //       "default": "./lib/npm.js"
      //     },
      //     "./lib/npm.js"
      //   ],
      //   "./package.json": "./package.json"
      // },
      // as well as conditional exports

      // if (data.exports && typeof data.exports === 'string') {
      //   index = data.exports
      // }

      // if (data.exports && data.exports['.']) {
      //   index = data.exports['.']
      //   if (typeof index !== 'string') {
      //   }
      // }
      const extless = path.join(
        path.dirname(index),
        path.basename(index, path.extname(index))
      )
      const dts = `./${extless}.d.ts`
      const hasDTSFields = 'types' in data || 'typings' in data
      if (!hasDTSFields) {
        try {
          await fs.access(path.join(pkg.path, dts))
          data.types = dts.split(path.sep).join('/')
        } catch {
          // do nothing
        }
      }
    }

    // "normalizeData" from "read-package-json", which was just a call through to
    // "normalize-package-data".  We only call the "fixer" functions because
    // outside of that it was also clobbering _id (which we already conditionally
    // do) and also adding the gypfile script (which we also already
    // conditionally do)

    // Some steps are isolated so we can do a limited subset of these in `fix`
    if (
      steps.includes('fixRepositoryField') ||
      steps.includes('normalizeData')
    ) {
      if (data.repositories) {
        changes?.push(
          `"repository" was set to the first entry in "repositories" (${data.repository})`
        )
        data.repository = data.repositories[0]
      }
      if (data.repository) {
        if (typeof data.repository === 'string') {
          changes?.push('"repository" was changed from a string to an object')
          data.repository = {
            type: 'git',
            url: data.repository
          }
        }
        if (data.repository.url) {
          const hosted = lazyHostedGitInfo().fromUrl(data.repository.url)
          let r
          if (hosted) {
            if (hosted.getDefaultRepresentation() === 'shortcut') {
              r = hosted.https()
            } else {
              r = hosted.toString()
            }
            if (r !== data.repository.url) {
              changes?.push(`"repository.url" was normalized to "${r}"`)
              data.repository.url = r
            }
          }
        }
      }
    }
    if (steps.includes('fixDependencies') || steps.includes('normalizeData')) {
      // peerDependencies?
      // devDependencies is meaningless here, it's ignored on an installed package
      for (const type of [
        'dependencies',
        'devDependencies',
        'optionalDependencies'
      ]) {
        if (data[type]) {
          let secondWarning = true
          if (typeof data[type] === 'string') {
            changes?.push(
              `"${type}" was converted from a string into an object`
            )
            data[type] = data[type].trim().split(/[\n\r\s\t ,]+/)
            secondWarning = false
          }
          if (Array.isArray(data[type])) {
            if (secondWarning) {
              changes?.push(
                `"${type}" was converted from an array into an object`
              )
            }
            const o = {}
            for (const d of data[type]) {
              if (typeof d === 'string') {
                const dep = d.trim().split(/(:?[@\s><=])/)
                const dn = dep.shift()
                const dv = dep.join('').replace(/^@/, '').trim()
                o[dn] = dv
              }
            }
            data[type] = o
          }
        }
      }
      // normalize-package-data used to put optional dependencies BACK into
      // dependencies here, we no longer do this

      for (const deps of ['dependencies', 'devDependencies']) {
        if (deps in data) {
          if (!data[deps] || typeof data[deps] !== 'object') {
            changes?.push(`Removed invalid "${deps}"`)
            delete data[deps]
          } else {
            for (const d in data[deps]) {
              const r = data[deps][d]
              if (typeof r !== 'string') {
                changes?.push(`Removed invalid "${deps}.${d}"`)
                delete data[deps][d]
              }
              const hosted = lazyHostedGitInfo()
                .fromUrl(data[deps][d])
                ?.toString()
              if (hosted && hosted !== data[deps][d]) {
                changes?.push(`Normalized git reference to "${deps}.${d}"`)
                data[deps][d] = hosted.toString()
              }
            }
          }
        }
      }
    }

    // TODO some of this is duplicated in other steps here, a future breaking change may be able to remove the duplicates involved in this step
    if (steps.includes('normalizeData')) {
      const { normalizeData } = requireNormalizeData()
      normalizeData(data, changes)
    }

    // Warn if the bin references don't point to anything.  This might be better
    // in normalize-package-data if it had access to the file path.
    if (steps.includes('binRefs') && data.bin instanceof Object) {
      for (const key in data.bin) {
        try {
          await fs.access(path.resolve(pkg.path, data.bin[key]))
        } catch {
          log.warn(
            'package-json',
            pkgId,
            `No bin file found at ${data.bin[key]}`
          )
          // XXX: should a future breaking change delete bin entries that cannot be accessed?
        }
      }
    }
  }
  normalize_1 = normalize
  return normalize_1
}

let readPackage_1
let hasRequiredReadPackage
function requireReadPackage() {
  if (hasRequiredReadPackage) {
    return readPackage_1
  }
  hasRequiredReadPackage = 1
  // This is JUST the code needed to open a package.json file and parse it.
  // It's isolated out so that code needing to parse a package.json file can do so in the same way as this module does, without needing to require the whole module, or needing to require the underlying parsing library.

  const { readFile } = require$$1$3
  const parseJSON = requireLib$a()
  async function read(filename) {
    try {
      const data = await readFile(filename, 'utf8')
      return data
    } catch (err) {
      err.message = `Could not read package.json: ${err}`
      throw err
    }
  }
  function parse(data) {
    try {
      const content = parseJSON(data)
      return content
    } catch (err) {
      err.message = `Invalid package.json: ${err}`
      throw err
    }
  }

  // This is what most external libs will use.
  // PackageJson will call read and parse separately
  async function readPackage(filename) {
    const data = await read(filename)
    const content = parse(data)
    return content
  }
  readPackage_1 = {
    read,
    parse,
    readPackage
  }
  return readPackage_1
}

/**
 * arbitrary sort order for package.json largely pulled from:
 * https://github.com/keithamus/sort-package-json/blob/main/defaultRules.md
 *
 * cross checked with:
 * https://github.com/npm/types/blob/main/types/index.d.ts#L104
 * https://docs.npmjs.com/cli/configuring-npm/package-json
 */
let sort
let hasRequiredSort
function requireSort() {
  if (hasRequiredSort) {
    return sort
  }
  hasRequiredSort = 1
  function packageSort(json) {
    const {
      name,
      version,
      private: isPrivate,
      description,
      keywords,
      homepage,
      bugs,
      repository,
      funding,
      license,
      author,
      maintainers,
      contributors,
      type,
      imports,
      exports,
      main,
      browser,
      types,
      bin,
      man,
      directories,
      files,
      workspaces,
      scripts,
      config,
      dependencies,
      devDependencies,
      peerDependencies,
      peerDependenciesMeta,
      optionalDependencies,
      bundledDependencies,
      bundleDependencies,
      engines,
      os,
      cpu,
      publishConfig,
      devEngines,
      licenses,
      overrides,
      ...rest
    } = json
    return {
      ...(typeof name !== 'undefined'
        ? {
            name
          }
        : {}),
      ...(typeof version !== 'undefined'
        ? {
            version
          }
        : {}),
      ...(typeof isPrivate !== 'undefined'
        ? {
            private: isPrivate
          }
        : {}),
      ...(typeof description !== 'undefined'
        ? {
            description
          }
        : {}),
      ...(typeof keywords !== 'undefined'
        ? {
            keywords
          }
        : {}),
      ...(typeof homepage !== 'undefined'
        ? {
            homepage
          }
        : {}),
      ...(typeof bugs !== 'undefined'
        ? {
            bugs
          }
        : {}),
      ...(typeof repository !== 'undefined'
        ? {
            repository
          }
        : {}),
      ...(typeof funding !== 'undefined'
        ? {
            funding
          }
        : {}),
      ...(typeof license !== 'undefined'
        ? {
            license
          }
        : {}),
      ...(typeof author !== 'undefined'
        ? {
            author
          }
        : {}),
      ...(typeof maintainers !== 'undefined'
        ? {
            maintainers
          }
        : {}),
      ...(typeof contributors !== 'undefined'
        ? {
            contributors
          }
        : {}),
      ...(typeof type !== 'undefined'
        ? {
            type
          }
        : {}),
      ...(typeof imports !== 'undefined'
        ? {
            imports
          }
        : {}),
      ...(typeof exports !== 'undefined'
        ? {
            exports
          }
        : {}),
      ...(typeof main !== 'undefined'
        ? {
            main
          }
        : {}),
      ...(typeof browser !== 'undefined'
        ? {
            browser
          }
        : {}),
      ...(typeof types !== 'undefined'
        ? {
            types
          }
        : {}),
      ...(typeof bin !== 'undefined'
        ? {
            bin
          }
        : {}),
      ...(typeof man !== 'undefined'
        ? {
            man
          }
        : {}),
      ...(typeof directories !== 'undefined'
        ? {
            directories
          }
        : {}),
      ...(typeof files !== 'undefined'
        ? {
            files
          }
        : {}),
      ...(typeof workspaces !== 'undefined'
        ? {
            workspaces
          }
        : {}),
      ...(typeof scripts !== 'undefined'
        ? {
            scripts
          }
        : {}),
      ...(typeof config !== 'undefined'
        ? {
            config
          }
        : {}),
      ...(typeof dependencies !== 'undefined'
        ? {
            dependencies
          }
        : {}),
      ...(typeof devDependencies !== 'undefined'
        ? {
            devDependencies
          }
        : {}),
      ...(typeof peerDependencies !== 'undefined'
        ? {
            peerDependencies
          }
        : {}),
      ...(typeof peerDependenciesMeta !== 'undefined'
        ? {
            peerDependenciesMeta
          }
        : {}),
      ...(typeof optionalDependencies !== 'undefined'
        ? {
            optionalDependencies
          }
        : {}),
      ...(typeof bundledDependencies !== 'undefined'
        ? {
            bundledDependencies
          }
        : {}),
      ...(typeof bundleDependencies !== 'undefined'
        ? {
            bundleDependencies
          }
        : {}),
      ...(typeof engines !== 'undefined'
        ? {
            engines
          }
        : {}),
      ...(typeof os !== 'undefined'
        ? {
            os
          }
        : {}),
      ...(typeof cpu !== 'undefined'
        ? {
            cpu
          }
        : {}),
      ...(typeof publishConfig !== 'undefined'
        ? {
            publishConfig
          }
        : {}),
      ...(typeof devEngines !== 'undefined'
        ? {
            devEngines
          }
        : {}),
      ...(typeof licenses !== 'undefined'
        ? {
            licenses
          }
        : {}),
      ...(typeof overrides !== 'undefined'
        ? {
            overrides
          }
        : {}),
      ...rest
    }
  }
  sort = {
    packageSort
  }
  return sort
}

let lib
let hasRequiredLib
function requireLib() {
  if (hasRequiredLib) {
    return lib
  }
  hasRequiredLib = 1
  const { readFile, writeFile } = require$$5
  const { resolve } = require$$2$2
  const parseJSON = requireLib$a()
  const updateDeps = requireUpdateDependencies()
  const updateScripts = requireUpdateScripts()
  const updateWorkspaces = requireUpdateWorkspaces()
  const normalize = requireNormalize()
  const { read, parse } = requireReadPackage()
  const { packageSort } = requireSort()

  // a list of handy specialized helper functions that take
  // care of special cases that are handled by the npm cli
  const knownSteps = new Set([updateDeps, updateScripts, updateWorkspaces])

  // list of all keys that are handled by "knownSteps" helpers
  const knownKeys = new Set([...updateDeps.knownKeys, 'scripts', 'workspaces'])
  class PackageJson {
    static normalizeSteps = Object.freeze([
      '_id',
      '_attributes',
      'bundledDependencies',
      'bundleDependencies',
      'optionalDedupe',
      'scripts',
      'funding',
      'bin'
    ])

    // npm pkg fix
    static fixSteps = Object.freeze([
      'binRefs',
      'bundleDependencies',
      'bundleDependenciesFalse',
      'fixName',
      'fixNameField',
      'fixVersionField',
      'fixRepositoryField',
      'fixDependencies',
      'devDependencies',
      'scriptpath'
    ])
    static prepareSteps = Object.freeze([
      '_id',
      '_attributes',
      'bundledDependencies',
      'bundleDependencies',
      'bundleDependenciesDeleteFalse',
      'gypfile',
      'serverjs',
      'scriptpath',
      'authors',
      'readme',
      'mans',
      'binDir',
      'gitHead',
      'fillTypes',
      'normalizeData',
      'binRefs'
    ])

    // create a new empty package.json, so we can save at the given path even
    // though we didn't start from a parsed file
    static async create(path, opts = {}) {
      const p = new PackageJson()
      await p.create(path)
      if (opts.data) {
        return p.update(opts.data)
      }
      return p
    }

    // Loads a package.json at given path and JSON parses
    static async load(path, opts = {}) {
      const p = new PackageJson()
      // Avoid try/catch if we aren't going to create
      if (!opts.create) {
        return p.load(path)
      }
      try {
        return await p.load(path)
      } catch (err) {
        if (!err.message.startsWith('Could not read package.json')) {
          throw err
        }
        return await p.create(path)
      }
    }

    // npm pkg fix
    static async fix(path, opts) {
      const p = new PackageJson()
      await p.load(path, true)
      return p.fix(opts)
    }

    // read-package-json compatible behavior
    static async prepare(path, opts) {
      const p = new PackageJson()
      await p.load(path, true)
      return p.prepare(opts)
    }

    // read-package-json-fast compatible behavior
    static async normalize(path, opts) {
      const p = new PackageJson()
      await p.load(path)
      return p.normalize(opts)
    }
    #path
    #manifest
    #readFileContent = ''
    #canSave = true

    // Load content from given path
    async load(path, parseIndex) {
      this.#path = path
      let parseErr
      try {
        this.#readFileContent = await read(this.filename)
      } catch (err) {
        if (!parseIndex) {
          throw err
        }
        parseErr = err
      }
      if (parseErr) {
        const indexFile = resolve(this.path, 'index.js')
        let indexFileContent
        try {
          indexFileContent = await readFile(indexFile, 'utf8')
        } catch (err) {
          throw parseErr
        }
        try {
          this.fromComment(indexFileContent)
        } catch (err) {
          throw parseErr
        }
        // This wasn't a package.json so prevent saving
        this.#canSave = false
        return this
      }
      return this.fromJSON(this.#readFileContent)
    }

    // Load data from a JSON string/buffer
    fromJSON(data) {
      this.#manifest = parse(data)
      return this
    }
    fromContent(data) {
      this.#manifest = data
      this.#canSave = false
      return this
    }

    // Load data from a comment
    // /**package { "name": "foo", "version": "1.2.3", ... } **/
    fromComment(data) {
      data = data.split(/^\/\*\*package(?:\s|$)/m)
      if (data.length < 2) {
        throw new Error('File has no package in comments')
      }
      data = data[1]
      data = data.split(/\*\*\/$/m)
      if (data.length < 2) {
        throw new Error('File has no package in comments')
      }
      data = data[0]
      data = data.replace(/^\s*\*/gm, '')
      this.#manifest = parseJSON(data)
      return this
    }
    get content() {
      return this.#manifest
    }
    get path() {
      return this.#path
    }
    get filename() {
      if (this.path) {
        return resolve(this.path, 'package.json')
      }
      return undefined
    }
    create(path) {
      this.#path = path
      this.#manifest = {}
      return this
    }

    // This should be the ONLY way to set content in the manifest
    update(content) {
      if (!this.content) {
        throw new Error(
          'Can not update without content.  Please `load` or `create`'
        )
      }
      for (const step of knownSteps) {
        this.#manifest = step({
          content,
          originalContent: this.content
        })
      }

      // unknown properties will just be overwitten
      for (const [key, value] of Object.entries(content)) {
        if (!knownKeys.has(key)) {
          this.content[key] = value
        }
      }
      return this
    }
    async save({ sort } = {}) {
      if (!this.#canSave) {
        throw new Error('No package.json to save to')
      }
      const {
        [Symbol.for('indent')]: indent,
        [Symbol.for('newline')]: newline,
        ...rest
      } = this.content
      const format = indent === undefined ? '  ' : indent
      const eol = newline === undefined ? '\n' : newline
      const content = sort ? packageSort(rest) : rest
      const fileContent = `${JSON.stringify(content, null, format)}\n`.replace(
        /\n/g,
        eol
      )
      if (fileContent.trim() !== this.#readFileContent.trim()) {
        const written = await writeFile(this.filename, fileContent)
        this.#readFileContent = fileContent
        return written
      }
    }
    async normalize(opts = {}) {
      if (!opts.steps) {
        opts.steps = this.constructor.normalizeSteps
      }
      await normalize(this, opts)
      return this
    }
    async prepare(opts = {}) {
      if (!opts.steps) {
        opts.steps = this.constructor.prepareSteps
      }
      await normalize(this, opts)
      return this
    }
    async fix(opts = {}) {
      // This one is not overridable
      opts.steps = this.constructor.fixSteps
      await normalize(this, opts)
      return this
    }
  }
  lib = PackageJson
  return lib
}

const libExports = requireLib()

module.exports = libExports
